{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c4f817",
   "metadata": {},
   "source": [
    "## Slide 1 — Title & Motivation\n",
    "\n",
    "- **Project**: LLM-based Recommender for Amazon Kindle_Store\n",
    "- **Predictive Task**: Next-item prediction from user purchase/reading sequences\n",
    "- **Baselines**: BPR, FPMC, SASRec\n",
    "- **Proposed**: Single-stage LLM with soft-token injection and dot-product scoring\n",
    "- **Impact**: Better personalization and ranking quality; improved catalog coverage\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af518ade",
   "metadata": {},
   "source": [
    "## Section 1 — Predictive Task, Evaluation, Baselines, Validity\n",
    "\n",
    "- **Task**: Given user \\(u\\) and sequence \\(S_u=[i_1,\\ldots,i_T]\\), rank items to predict next \\(y_u\\).\n",
    "- **Evaluation**: Candidate set per user = 1 positive + 100 negatives (exclude history); report HR@K, NDCG@K, MRR; deterministic negatives in eval for fairness.\n",
    "- **Baselines**: BPR-MF, FPMC, SASRec; this notebook includes complete BPR and FPMC implementations + training and evaluation.\n",
    "- **Validity**: Temporal splits, no leakage, multiple seeds (where applicable), fixed eval negatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b71af3e",
   "metadata": {},
   "source": [
    "## Section 2 — Exploratory Analysis, Data, and Preprocessing\n",
    "\n",
    "- **Dataset**: Amazon Kindle_Store implicit sequences (users, items, timestamps; ~100K users, ~400K items scale).\n",
    "- **Processing**: Build `user2id`, `item2id`; leave-one-out splits; truncate/pad sequences.\n",
    "- **In this notebook**:\n",
    "  - BPR/FPMC sections load preprocessed data via `pd.read_pickle(...)` (quick start for baselines).\n",
    "  - The LLM section (later) contains full preprocessing, datasets, and dataloaders (deterministic eval negatives).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391be765",
   "metadata": {},
   "source": [
    "## Section 3 — Modeling (Where to find content in this notebook)\n",
    "\n",
    "- **BPR-MF (Baseline)**: Implementation, dataset, evaluator, training, and evaluation follow this intro.\n",
    "- **FPMC (Baseline)**: Section labeled \"Merged from: FPMC.ipynb\" — includes dataset, model, evaluator, training, and evaluation.\n",
    "- **Proposed LLM (Single-stage)**: Section labeled \"Merged from: llm_recommender.ipynb\" — includes preprocessing, data module, model, training, and evaluation.\n",
    "\n",
    "Below, proceed to BPR-MF first, then FPMC, then the Proposed LLM section.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e026ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f1e47f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/train_data.pkl')\n",
    "val_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/val_data.pkl')\n",
    "test_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/test_data.pkl')\n",
    "\n",
    "id2item = pd.read_pickle('/data/sukhanna/cse258/processed_100/id2item.pkl')\n",
    "item2id = pd.read_pickle('/data/sukhanna/cse258/processed_100/item2id.pkl')\n",
    "\n",
    "id2user = pd.read_pickle('/data/sukhanna/cse258/processed_100/id2user.pkl')\n",
    "user2id = pd.read_pickle('/data/sukhanna/cse258/processed_100/user2id.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12c0c24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': [{'item_id': 239726, 'timestamp': 1373155244.0, 'rating': 4.0},\n",
       "  {'item_id': 100927, 'timestamp': 1398238497.0, 'rating': 5.0},\n",
       "  {'item_id': 239727, 'timestamp': 1447851667.0, 'rating': 5.0}],\n",
       " 'is_autoregressive': True}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[8551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8394909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': [{'item_id': 239726, 'timestamp': 1373155244.0, 'rating': 4.0},\n",
       "  {'item_id': 100927, 'timestamp': 1398238497.0, 'rating': 5.0},\n",
       "  {'item_id': 239727, 'timestamp': 1447851667.0, 'rating': 5.0}],\n",
       " 'target': {'item_id': 239728, 'timestamp': 1448406034.0, 'rating': 4.0},\n",
       " 'is_autoregressive': False}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data[8551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e5108c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sequence': [{'item_id': 239726, 'timestamp': 1373155244.0, 'rating': 4.0},\n",
       "  {'item_id': 100927, 'timestamp': 1398238497.0, 'rating': 5.0},\n",
       "  {'item_id': 239727, 'timestamp': 1447851667.0, 'rating': 5.0},\n",
       "  {'item_id': 239728, 'timestamp': 1448406034.0, 'rating': 4.0}],\n",
       " 'target': {'item_id': 135537, 'timestamp': 1569107616.096, 'rating': 4.0},\n",
       " 'is_autoregressive': False}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[8551]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e92df65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "class BPRDataset(Dataset):\n",
    "    def __init__(self, train_data, val_data, test_data, num_items):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            train_data: List of dicts containing 'sequence' (list of dicts with 'item_id').\n",
    "            val_data: List of dicts containing 'target' ('item_id').\n",
    "            test_data: List of dicts containing 'target' ('item_id').\n",
    "            num_items: Total count of items in catalog (e.g., 349,000).\n",
    "                       Assumes IDs range from 1 to num_items.\n",
    "        \"\"\"\n",
    "        self.num_items = num_items\n",
    "        \n",
    "        # Pre-process data into simple sets for O(1) lookups\n",
    "        self.user_history = []\n",
    "        self.exclusion_sets = []\n",
    "        self.valid_user_indices = []\n",
    "\n",
    "        # Assuming train_data, val_data, test_data are aligned by list index (User ID)\n",
    "        for u_idx in range(len(train_data)):\n",
    "            # 1. Extract Train Sequence\n",
    "            # The data structure is nested: entry['sequence'] -> list of dicts -> 'item_id'\n",
    "            train_seq = [x['item_id'] for x in train_data[u_idx]['sequence']]\n",
    "            \n",
    "            # 2. Extract Validation and Test Targets\n",
    "            val_target = val_data[u_idx]['target']['item_id']\n",
    "            test_target = test_data[u_idx]['target']['item_id']\n",
    "            \n",
    "            # 3. Store Positive History for Training (only train_seq matters for BPR positive sampling)\n",
    "            # We filter out users with empty sequences to prevent errors\n",
    "            if len(train_seq) > 0:\n",
    "                self.user_history.append(train_seq)\n",
    "                \n",
    "                # 4. Build Exclusion Set (Train + Val + Test)\n",
    "                # These are items we CANNOT use as negatives\n",
    "                exclude = set(train_seq)\n",
    "                exclude.add(val_target)\n",
    "                exclude.add(test_target)\n",
    "                self.exclusion_sets.append(exclude)\n",
    "                \n",
    "                # Keep track of original user index if needed, though BPR usually learns \n",
    "                # user_id based on the row index of this dataset\n",
    "                self.valid_user_indices.append(u_idx)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_history)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns:\n",
    "            user_id: (0 to N-1)\n",
    "            pos_item: (0 to M-1)\n",
    "            neg_item: (0 to M-1)\n",
    "        \"\"\"\n",
    "        # 1. User ID (mapped to 0-index)\n",
    "        # We use the index of the dataset as the user_id for embedding lookup\n",
    "        user_id = idx \n",
    "        \n",
    "        # 2. Positive Sampling\n",
    "        # Randomly select one item from the user's training history\n",
    "        pos_id_raw = random.choice(self.user_history[idx])\n",
    "        \n",
    "        # 3. Negative Sampling with Exclusion\n",
    "        # Randomly sample until we find an item NOT in the exclusion set\n",
    "        while True:\n",
    "            # Sample from 1 to num_items (inclusive)\n",
    "            neg_id_raw = random.randint(1, self.num_items)\n",
    "            \n",
    "            if neg_id_raw not in self.exclusion_sets[idx]:\n",
    "                break\n",
    "        \n",
    "        # 4. Convert to 0-based indexing for PyTorch Embedding Layers\n",
    "        # Input IDs are 1-based, so we subtract 1.\n",
    "        return (\n",
    "            torch.tensor(user_id, dtype=torch.long),\n",
    "            torch.tensor(pos_id_raw - 1, dtype=torch.long),\n",
    "            torch.tensor(neg_id_raw - 1, dtype=torch.long)\n",
    "        )\n",
    "\n",
    "# class BPRDataset(Dataset):\n",
    "#     def __init__(self, train_data, val_data, test_data, num_items, n_neg=1): # <--- Added n_neg\n",
    "#         # ... (previous init code is same) ...\n",
    "#         self.n_neg = n_neg # Store it\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         user_id = idx \n",
    "#         pos_id_raw = random.choice(self.user_history[idx])\n",
    "        \n",
    "#         # --- MODIFIED BLOCK START ---\n",
    "#         neg_samples = []\n",
    "#         for _ in range(self.n_neg): # Loop N times\n",
    "#             while True:\n",
    "#                 neg_id_raw = random.randint(1, self.num_items)\n",
    "#                 if neg_id_raw not in self.exclusion_sets[idx]:\n",
    "#                     neg_samples.append(neg_id_raw - 1)\n",
    "#                     break\n",
    "#         # --- MODIFIED BLOCK END ---\n",
    "\n",
    "#         return (\n",
    "#             torch.tensor(user_id, dtype=torch.long),\n",
    "#             torch.tensor(pos_id_raw - 1, dtype=torch.long),\n",
    "#             torch.tensor(neg_samples, dtype=torch.long) # Shape: [n_neg]\n",
    "#         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d9f2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BPRMF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_users: Total number of unique users.\n",
    "            num_items: Total number of unique items.\n",
    "            embedding_dim: Size of the latent vectors (e.g., 32, 64, 128).\n",
    "        \"\"\"\n",
    "        super(BPRMF, self).__init__()\n",
    "        \n",
    "        # 1. User Embeddings\n",
    "        # Shape: [num_users, embedding_dim]\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        \n",
    "        # 2. Item Embeddings\n",
    "        # Shape: [num_items, embedding_dim]\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Initialization (Critical for BPR convergence)\n",
    "        # We initialize with small random values (Normal distribution)\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_embedding.weight, std=0.01)\n",
    "\n",
    "    def forward(self, user_indices, item_indices):\n",
    "        \"\"\"\n",
    "        Computes the compatibility score (dot product) between users and items.\n",
    "        \n",
    "        Args:\n",
    "            user_indices: Tensor of shape [batch_size]\n",
    "            item_indices: Tensor of shape [batch_size]\n",
    "            \n",
    "        Returns:\n",
    "            scores: Tensor of shape [batch_size]\n",
    "        \"\"\"\n",
    "        # Look up latent vectors\n",
    "        # user_vec: [batch_size, embedding_dim]\n",
    "        # item_vec: [batch_size, embedding_dim]\n",
    "        user_vec = self.user_embedding(user_indices)\n",
    "        item_vec = self.item_embedding(item_indices)\n",
    "        \n",
    "        # Compute Dot Product\n",
    "        # Multiply element-wise and sum across the embedding dimension (dim=1)\n",
    "        scores = (user_vec * item_vec).sum(dim=1)\n",
    "        \n",
    "        return scores\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "08e4a314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "class BPREvaluator:\n",
    "    def __init__(self, eval_data, exclusion_rules, num_items, k_list=[5, 10]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            eval_data: List of dicts (Validation or Test data).\n",
    "            exclusion_rules: Dict {user_idx: set(all_positive_items)}.\n",
    "            num_items: Total catalog size (for random negative sampling).\n",
    "            k_list: List of K values for metrics (e.g., [5, 10]).\n",
    "        \"\"\"\n",
    "        self.eval_data = eval_data\n",
    "        self.exclusion_rules = exclusion_rules\n",
    "        self.num_items = num_items\n",
    "        self.k_list = k_list\n",
    "    \n",
    "    def evaluate(self, model, device='cpu'):\n",
    "        model.eval()  # Switch model to evaluation mode\n",
    "        \n",
    "        # Accumulators for metrics\n",
    "        hr_results = {k: [] for k in self.k_list}\n",
    "        ndcg_results = {k: [] for k in self.k_list}\n",
    "        \n",
    "        # We iterate through each user in the evaluation set\n",
    "        with torch.no_grad():\n",
    "            for u_idx, entry in self.eval_data.items():\n",
    "                \n",
    "                # 1. Get Ground Truth (Target)\n",
    "                # Ensure we handle the 1-based indexing -> 0-based conversion\n",
    "                gt_item_raw = entry['target']['item_id']\n",
    "                gt_item = gt_item_raw - 1\n",
    "                \n",
    "                # 2. Sample 100 Negatives\n",
    "                # These must NOT be in the exclusion set (Train + Val + Test)\n",
    "                negatives = []\n",
    "                u_exclusion = self.exclusion_rules[u_idx]\n",
    "                \n",
    "                while len(negatives) < 100:\n",
    "                    neg_candidate = random.randint(1, self.num_items)\n",
    "                    \n",
    "                    # Check exclusion and duplication within the current batch of 100\n",
    "                    if (neg_candidate not in u_exclusion) and (neg_candidate - 1 != gt_item):\n",
    "                        # Add to list (converting to 0-based index)\n",
    "                        negatives.append(neg_candidate - 1)\n",
    "                \n",
    "                # 3. Prepare Batch for Model (1 GT + 100 Negatives)\n",
    "                # Candidate Items: [GT, Neg1, Neg2, ..., Neg100]\n",
    "                candidate_items = [gt_item] + negatives\n",
    "                candidate_tensor = torch.tensor(candidate_items, dtype=torch.long).to(device)\n",
    "                \n",
    "                # User Tensor: Repeat the user ID 101 times\n",
    "                user_tensor = torch.tensor([u_idx] * 101, dtype=torch.long).to(device)\n",
    "                \n",
    "                # 4. Score Items\n",
    "                scores = model(user_tensor, candidate_tensor)\n",
    "                scores = scores.cpu().numpy()\n",
    "                \n",
    "                # 5. Rank\n",
    "                # The Ground Truth is at index 0. We need to see where it lands.\n",
    "                # argsort gives indices that sort the array. \n",
    "                # We want descending sort.\n",
    "                ranked_indices = np.argsort(-scores) # \"-\" for descending\n",
    "                \n",
    "                # Find where the GT (index 0) ended up in the sorted list\n",
    "                # np.where returns a tuple, we take the first element\n",
    "                gt_rank = np.where(ranked_indices == 0)[0][0]\n",
    "                \n",
    "                # gt_rank is 0-indexed (0 means 1st place, 1 means 2nd place)\n",
    "                \n",
    "                # 6. Calculate Metrics per User\n",
    "                for k in self.k_list:\n",
    "                    # Hit Rate\n",
    "                    if gt_rank < k:\n",
    "                        hr_results[k].append(1)\n",
    "                        # NDCG: 1 / log2(rank + 2)\n",
    "                        # rank+2 because rank is 0-based. \n",
    "                        # If rank=0 (1st), log2(2)=1 -> NDCG=1.\n",
    "                        ndcg_results[k].append(1 / math.log2(gt_rank + 2))\n",
    "                    else:\n",
    "                        hr_results[k].append(0)\n",
    "                        ndcg_results[k].append(0)\n",
    "\n",
    "        # Average the results\n",
    "        avg_hr = {k: np.mean(v) for k, v in hr_results.items()}\n",
    "        avg_ndcg = {k: np.mean(v) for k, v in ndcg_results.items()}\n",
    "        \n",
    "        return avg_hr, avg_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "36cf969b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define Catalog Size\n",
    "# We need the total count to know the range for random sampling (1 to num_items)\n",
    "num_items_total = len(item2id)\n",
    "\n",
    "# 2. Create the Training Dataset\n",
    "# This will also pre-compute the 'exclusion_sets' (Train+Val+Test) for every user\n",
    "train_dataset = BPRDataset(\n",
    "    train_data=train_data, \n",
    "    val_data=val_data, \n",
    "    test_data=test_data, \n",
    "    num_items=num_items_total\n",
    ")\n",
    "\n",
    "# 3. Extract Exclusion Rules\n",
    "# We need these rules so the Evaluator doesn't accidentally sample \n",
    "# known positives (history) as \"negatives\" during the ranking test.\n",
    "exclusion_rules = train_dataset.exclusion_sets\n",
    "\n",
    "# 4. Create the Validation Evaluator\n",
    "# We use this to check HR@1 and HR@10 at the end of every epoch\n",
    "val_evaluator = BPREvaluator(\n",
    "    eval_data=val_data, \n",
    "    exclusion_rules=exclusion_rules, \n",
    "    num_items=num_items_total, \n",
    "    k_list=[1, 10]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e34116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device selected: cuda\n",
      "Starting Training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6931\n",
      "  Validation HR@1:   0.0256 | HR@10:   0.1495\n",
      "  Validation NDCG@1: 0.0256 | NDCG@10: 0.0769\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6915\n",
      "  Validation HR@1:   0.0360 | HR@10:   0.1671\n",
      "  Validation NDCG@1: 0.0360 | NDCG@10: 0.0903\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6858\n",
      "  Validation HR@1:   0.0471 | HR@10:   0.1747\n",
      "  Validation NDCG@1: 0.0471 | NDCG@10: 0.1006\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6755\n",
      "  Validation HR@1:   0.0547 | HR@10:   0.1816\n",
      "  Validation NDCG@1: 0.0547 | NDCG@10: 0.1082\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6605\n",
      "  Validation HR@1:   0.0613 | HR@10:   0.1893\n",
      "  Validation NDCG@1: 0.0613 | NDCG@10: 0.1159\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6411\n",
      "  Validation HR@1:   0.0675 | HR@10:   0.1958\n",
      "  Validation NDCG@1: 0.0675 | NDCG@10: 0.1227\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6191\n",
      "  Validation HR@1:   0.0730 | HR@10:   0.2028\n",
      "  Validation NDCG@1: 0.0730 | NDCG@10: 0.1290\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.5942\n",
      "  Validation HR@1:   0.0766 | HR@10:   0.2099\n",
      "  Validation NDCG@1: 0.0766 | NDCG@10: 0.1343\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.5674\n",
      "  Validation HR@1:   0.0797 | HR@10:   0.2152\n",
      "  Validation NDCG@1: 0.0797 | NDCG@10: 0.1387\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.5408\n",
      "  Validation HR@1:   0.0834 | HR@10:   0.2201\n",
      "  Validation NDCG@1: 0.0834 | NDCG@10: 0.1432\n",
      "============================================================\n",
      "\n",
      "Training Complete. Model saved to: /data/sukhanna/cse258/bpr_mf_model.pth\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "BATCH_SIZE = 128      # Reasonably small for 1 GPU\n",
    "LEARNING_RATE = 0.001 # Standard starting point for Adam\n",
    "NUM_EPOCHS = 10\n",
    "EMBEDDING_DIM = 64\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Device selected: {DEVICE}\")\n",
    "\n",
    "# --- Setup Model & Data ---\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "model = BPRMF(num_users=len(train_data), num_items=len(item2id), embedding_dim=EMBEDDING_DIM)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- Training Loop ---\n",
    "print(\"Starting Training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    \n",
    "    # 1. Training Phase\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Tqdm progress bar for the batch loop\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", leave=False)\n",
    "    \n",
    "    for user_ids, pos_items, neg_items in progress_bar:\n",
    "        # Move data to GPU\n",
    "        user_ids = user_ids.to(DEVICE)\n",
    "        pos_items = pos_items.to(DEVICE)\n",
    "        neg_items = neg_items.to(DEVICE)\n",
    "        \n",
    "        # Clear gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Forward Pass\n",
    "        # We calculate scores for (User, Positive) and (User, Negative)\n",
    "        pos_scores = model(user_ids, pos_items)\n",
    "        neg_scores = model(user_ids, neg_items)\n",
    "\n",
    "        # # Unpack data\n",
    "        # # neg_items shape: [Batch_Size, N_Neg]\n",
    "        # batch_size = user_ids.size(0)\n",
    "        # n_neg = neg_items.size(1) \n",
    "\n",
    "        # # 1. Flatten Negatives to fit into Model\n",
    "        # # We effectively treat these as (Batch * N) separate pairs\n",
    "        # flat_users = user_ids.repeat_interleave(n_neg) # Shape: [Batch * N]\n",
    "        # flat_negs = neg_items.view(-1)                 # Shape: [Batch * N]\n",
    "\n",
    "        # # 2. Compute Scores\n",
    "        # pos_scores = model(user_ids, pos_items)        # Shape: [Batch]\n",
    "        # flat_neg_scores = model(flat_users, flat_negs) # Shape: [Batch * N]\n",
    "\n",
    "        # # 3. Reshape Back for Loss\n",
    "        # neg_scores = flat_neg_scores.view(batch_size, n_neg) # Shape: [Batch, N]\n",
    "\n",
    "        # # 4. Calculate Loss with Broadcasting\n",
    "        # # pos_scores: [Batch] -> Unsqueeze to [Batch, 1] to broadcast against [Batch, N]\n",
    "        # loss = -torch.mean(torch.nn.functional.logsigmoid(pos_scores.unsqueeze(1) - neg_scores))\n",
    "\n",
    "\n",
    "        # BPR Loss Calculation\n",
    "        # Loss = - sum( log( sigmoid( pos_score - neg_score ) ) )\n",
    "        # We assume optimization minimizes loss, so we take negative log likelihood\n",
    "        loss = -torch.mean(torch.nn.functional.logsigmoid(pos_scores - neg_scores))\n",
    "        \n",
    "        # Backward Pass\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # 2. Evaluation Phase\n",
    "    # We evaluate on the Validation set at the end of every epoch\n",
    "    hr_metrics, ndcg_metrics = val_evaluator.evaluate(model, device=DEVICE)\n",
    "    \n",
    "    # 3. Reporting\n",
    "    print(f\"Epoch {epoch:02d} Completed\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"  Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Validation HR@1:   {hr_metrics[1]:.4f} | HR@10:   {hr_metrics[10]:.4f}\")\n",
    "    print(f\"  Validation NDCG@1: {ndcg_metrics[1]:.4f} | NDCG@10: {ndcg_metrics[10]:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# --- Save Model ---\n",
    "save_path = \"/data/sukhanna/cse258/bpr_mf_model.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"\\nTraining Complete. Model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a752cf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running Test Evaluation...\n",
      "------------------------------\n",
      "Test HR@1:   0.0691 | HR@10:   0.2007\n",
      "Test NDCG@1: 0.0691 | NDCG@10: 0.1261\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the Test Evaluator\n",
    "# We use the SAME exclusion_rules from the training dataset.\n",
    "# This ensures we don't sample the Test Target (or Train/Val items) as negatives.\n",
    "test_evaluator = BPREvaluator(\n",
    "    eval_data=test_data, \n",
    "    exclusion_rules=train_dataset.exclusion_sets, \n",
    "    num_items=len(item2id), \n",
    "    k_list=[1, 10]\n",
    ")\n",
    "\n",
    "# 2. Run Evaluation\n",
    "print(\"Running Test Evaluation...\")\n",
    "test_hr, test_ndcg = test_evaluator.evaluate(model, device=DEVICE)\n",
    "\n",
    "# 3. Report Results\n",
    "print(\"-\" * 30)\n",
    "print(f\"Test HR@1:   {test_hr[1]:.4f} | HR@10:   {test_hr[10]:.4f}\")\n",
    "print(f\"Test NDCG@1: {test_ndcg[1]:.4f} | NDCG@10: {test_ndcg[10]:.4f}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e35109d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f8307bb",
   "metadata": {},
   "source": [
    "# FPMC\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845f1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/train_data.pkl')\n",
    "val_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/val_data.pkl')\n",
    "test_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/test_data.pkl')\n",
    "\n",
    "id2item = pd.read_pickle('/data/sukhanna/cse258/processed_100/id2item.pkl')\n",
    "item2id = pd.read_pickle('/data/sukhanna/cse258/processed_100/item2id.pkl')\n",
    "\n",
    "id2user = pd.read_pickle('/data/sukhanna/cse258/processed_100/id2user.pkl')\n",
    "user2id = pd.read_pickle('/data/sukhanna/cse258/processed_100/user2id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a771b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class FPMCDataset(Dataset):\n",
    "    def __init__(self, train_data, val_data, test_data, num_items, n_neg=1):\n",
    "        self.num_items = num_items\n",
    "        self.n_neg = n_neg\n",
    "        \n",
    "        # 1. Prepare Storage for Transitions\n",
    "        # Format: (user_idx, last_item_idx, current_item_idx)\n",
    "        self.samples = []\n",
    "        \n",
    "        # 2. Prepare Exclusion Sets (Same as BPR)\n",
    "        self.exclusion_rules = {}\n",
    "\n",
    "        for u_idx in range(len(train_data)):\n",
    "            # Extract sequence\n",
    "            seq = [x['item_id'] for x in train_data[u_idx]['sequence']]\n",
    "            val_target = val_data[u_idx]['target']['item_id']\n",
    "            test_target = test_data[u_idx]['target']['item_id']\n",
    "            \n",
    "            # Build Exclusion Set (Train + Val + Test)\n",
    "            full_history = set(seq)\n",
    "            full_history.add(val_target)\n",
    "            full_history.add(test_target)\n",
    "            self.exclusion_rules[u_idx] = full_history\n",
    "            \n",
    "            # 3. Generate Sequential Transitions\n",
    "            # We need at least 2 items to form a transition (A -> B)\n",
    "            if len(seq) > 1:\n",
    "                # Iterate from 0 to Length-2\n",
    "                for i in range(len(seq) - 1):\n",
    "                    last_item = seq[i]\n",
    "                    curr_item = seq[i+1]\n",
    "                    \n",
    "                    self.samples.append((u_idx, last_item, curr_item))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u_id, last_item_raw, pos_item_raw = self.samples[idx]\n",
    "        \n",
    "        # Negative Sampling\n",
    "        # We sample 'n_neg' items that are NOT in the user's full history\n",
    "        neg_samples = []\n",
    "        for _ in range(self.n_neg):\n",
    "            while True:\n",
    "                neg_id_raw = random.randint(1, self.num_items)\n",
    "                if neg_id_raw not in self.exclusion_rules[u_id]:\n",
    "                    neg_samples.append(neg_id_raw - 1)\n",
    "                    break\n",
    "        \n",
    "        # Return 0-indexed tensors\n",
    "        # Note: We subtract 1 because input IDs are 1-based\n",
    "        return (\n",
    "            torch.tensor(u_id, dtype=torch.long),\n",
    "            torch.tensor(last_item_raw - 1, dtype=torch.long),\n",
    "            torch.tensor(pos_item_raw - 1, dtype=torch.long),\n",
    "            torch.tensor(neg_samples, dtype=torch.long) # Shape: [n_neg]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f77e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FPMC(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_users: Total unique users.\n",
    "            num_items: Total unique items.\n",
    "            embedding_dim: Latent vector size.\n",
    "        \"\"\"\n",
    "        super(FPMC, self).__init__()\n",
    "        \n",
    "        # 1. User Embedding (Long-term preference)\n",
    "        # Represents 'u' in the formula\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        \n",
    "        # 2. Item Context Embedding (The 'Previous' Item)\n",
    "        # Represents 'c_l' (Source/Context role)\n",
    "        self.item_context_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # 3. Item Target Embedding (The 'Next' Item)\n",
    "        # Represents 'v_i' (Destination/Target role)\n",
    "        # Used for both the MF part and the MC part\n",
    "        self.item_target_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Initialization\n",
    "        # FPMC is sensitive to initialization. We use small random values.\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_context_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_target_embedding.weight, std=0.01)\n",
    "\n",
    "    def forward(self, user_indices, last_item_indices, curr_item_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_indices: [Batch_Size]\n",
    "            last_item_indices: [Batch_Size]\n",
    "            curr_item_indices: [Batch_Size]\n",
    "            \n",
    "        Returns:\n",
    "            scores: [Batch_Size]\n",
    "        \"\"\"\n",
    "        # 1. Lookup Embeddings\n",
    "        # Shapes: [Batch, Dim]\n",
    "        u = self.user_embedding(user_indices)\n",
    "        c = self.item_context_embedding(last_item_indices)\n",
    "        v = self.item_target_embedding(curr_item_indices)\n",
    "        \n",
    "        # 2. Compute Score\n",
    "        # Formula: (User + Context) dot Target\n",
    "        # This efficiently calculates (User dot Target) + (Context dot Target)\n",
    "        interaction_vector = u + c\n",
    "        scores = (interaction_vector * v).sum(dim=1)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eea2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "class FPMCEvaluator:\n",
    "    def __init__(self, eval_data, exclusion_rules, num_items, k_list=[1, 10]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            eval_data: List/Dict containing 'sequence' (for context) and 'target' (ground truth).\n",
    "            exclusion_rules: Dict {user_idx: set(all_positive_items)}.\n",
    "            num_items: Catalog size.\n",
    "            k_list: Metrics to calculate.\n",
    "        \"\"\"\n",
    "        self.eval_data = eval_data\n",
    "        self.exclusion_rules = exclusion_rules\n",
    "        self.num_items = num_items\n",
    "        self.k_list = k_list\n",
    "    \n",
    "    def evaluate(self, model, device='cpu'):\n",
    "        model.eval()\n",
    "        \n",
    "        hr_results = {k: [] for k in self.k_list}\n",
    "        ndcg_results = {k: [] for k in self.k_list}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Iterate using .items() if it's a dict, or enumerate if list\n",
    "            # Handling both based on your previous data snippets\n",
    "            iterator = self.eval_data.items() if isinstance(self.eval_data, dict) else enumerate(self.eval_data)\n",
    "            \n",
    "            for u_idx, entry in iterator:\n",
    "                \n",
    "                # 1. Get Context (The Last Item user interacted with)\n",
    "                # This is the \"Markov\" state\n",
    "                seq = entry['sequence']\n",
    "                if len(seq) == 0:\n",
    "                    continue # Skip empty users\n",
    "                \n",
    "                last_item_raw = seq[-1]['item_id']\n",
    "                last_item = last_item_raw - 1\n",
    "                \n",
    "                # 2. Get Ground Truth (Target)\n",
    "                gt_item_raw = entry['target']['item_id']\n",
    "                gt_item = gt_item_raw - 1\n",
    "                \n",
    "                # 3. Sample 100 Negatives\n",
    "                negatives = []\n",
    "                u_exclusion = self.exclusion_rules[u_idx]\n",
    "                \n",
    "                while len(negatives) < 100:\n",
    "                    neg_candidate = random.randint(1, self.num_items)\n",
    "                    # Exclude history AND target\n",
    "                    if (neg_candidate not in u_exclusion) and (neg_candidate - 1 != gt_item):\n",
    "                        negatives.append(neg_candidate - 1)\n",
    "                \n",
    "                # 4. Prepare Batch (101 Items)\n",
    "                candidate_items = [gt_item] + negatives\n",
    "                \n",
    "                # Create Tensors\n",
    "                # User: Repeated 101 times\n",
    "                user_tensor = torch.tensor([u_idx] * 101, dtype=torch.long).to(device)\n",
    "                \n",
    "                # Last Item: Repeated 101 times (Context is constant for this prediction)\n",
    "                last_item_tensor = torch.tensor([last_item] * 101, dtype=torch.long).to(device)\n",
    "                \n",
    "                # Current Items: The 101 candidates\n",
    "                curr_item_tensor = torch.tensor(candidate_items, dtype=torch.long).to(device)\n",
    "                \n",
    "                # 5. Score\n",
    "                # Model takes (u, last, curr)\n",
    "                scores = model(user_tensor, last_item_tensor, curr_item_tensor)\n",
    "                scores = scores.cpu().numpy()\n",
    "                \n",
    "                # 6. Rank\n",
    "                ranked_indices = np.argsort(-scores) # Descending\n",
    "                gt_rank = np.where(ranked_indices == 0)[0][0]\n",
    "                \n",
    "                # 7. Metrics\n",
    "                for k in self.k_list:\n",
    "                    if gt_rank < k:\n",
    "                        hr_results[k].append(1)\n",
    "                        ndcg_results[k].append(1 / math.log2(gt_rank + 2))\n",
    "                    else:\n",
    "                        hr_results[k].append(0)\n",
    "                        ndcg_results[k].append(0)\n",
    "\n",
    "        avg_hr = {k: np.mean(v) for k, v in hr_results.items()}\n",
    "        avg_ndcg = {k: np.mean(v) for k, v in ndcg_results.items()}\n",
    "        \n",
    "        return avg_hr, avg_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec81375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device selected: cuda\n",
      "Starting FPMC Training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6503\n",
      "  Validation HR@1:   0.2125 | HR@10:   0.4518\n",
      "  Validation NDCG@1: 0.2125 | NDCG@10: 0.3246\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.4144\n",
      "  Validation HR@1:   0.2432 | HR@10:   0.5234\n",
      "  Validation NDCG@1: 0.2432 | NDCG@10: 0.3734\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.2258\n",
      "  Validation HR@1:   0.2582 | HR@10:   0.5459\n",
      "  Validation NDCG@1: 0.2582 | NDCG@10: 0.3918\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.1197\n",
      "  Validation HR@1:   0.2660 | HR@10:   0.5562\n",
      "  Validation NDCG@1: 0.2660 | NDCG@10: 0.4013\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0659\n",
      "  Validation HR@1:   0.2707 | HR@10:   0.5634\n",
      "  Validation NDCG@1: 0.2707 | NDCG@10: 0.4078\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0403\n",
      "  Validation HR@1:   0.2771 | HR@10:   0.5673\n",
      "  Validation NDCG@1: 0.2771 | NDCG@10: 0.4131\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0263\n",
      "  Validation HR@1:   0.2808 | HR@10:   0.5690\n",
      "  Validation NDCG@1: 0.2808 | NDCG@10: 0.4164\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0195\n",
      "  Validation HR@1:   0.2824 | HR@10:   0.5713\n",
      "  Validation NDCG@1: 0.2824 | NDCG@10: 0.4183\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0148\n",
      "  Validation HR@1:   0.2865 | HR@10:   0.5705\n",
      "  Validation NDCG@1: 0.2865 | NDCG@10: 0.4203\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0123\n",
      "  Validation HR@1:   0.2889 | HR@10:   0.5724\n",
      "  Validation NDCG@1: 0.2889 | NDCG@10: 0.4221\n",
      "============================================================\n",
      "\n",
      "FPMC Training Complete. Model saved to: /data/sukhanna/cse258/fpmc_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "EMBEDDING_DIM = 64\n",
    "N_NEG = 1  # Start with 1 as discussed\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Device selected: {DEVICE}\")\n",
    "\n",
    "# --- 1. Setup Data & Model ---\n",
    "# Ensure item2id and data dicts are available in your scope\n",
    "num_items_total = len(item2id)\n",
    "\n",
    "# Dataset\n",
    "train_dataset_fpmc = FPMCDataset(\n",
    "    train_data, val_data, test_data, \n",
    "    num_items=num_items_total, \n",
    "    n_neg=N_NEG\n",
    ")\n",
    "\n",
    "# Evaluator\n",
    "# Uses the same exclusion rules logic\n",
    "val_evaluator_fpmc = FPMCEvaluator(\n",
    "    val_data, \n",
    "    train_dataset_fpmc.exclusion_rules, \n",
    "    num_items=num_items_total, \n",
    "    k_list=[1, 10]\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset_fpmc, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Model\n",
    "model = FPMC(num_users=len(train_data), num_items=num_items_total, embedding_dim=EMBEDDING_DIM)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 2. Training Loop ---\n",
    "print(\"Starting FPMC Training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Progress Bar\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", leave=False)\n",
    "    \n",
    "    for u, last_item, pos_item, neg_items in progress_bar:\n",
    "        # Move to Device\n",
    "        u = u.to(DEVICE)                  # [Batch]\n",
    "        last_item = last_item.to(DEVICE)  # [Batch]\n",
    "        pos_item = pos_item.to(DEVICE)    # [Batch]\n",
    "        neg_items = neg_items.to(DEVICE)  # [Batch, N_Neg]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --- A. Positive Scores ---\n",
    "        # Shape: [Batch]\n",
    "        pos_scores = model(u, last_item, pos_item)\n",
    "        \n",
    "        # --- B. Negative Scores (Handling N_Neg) ---\n",
    "        # We must flatten the batch to process (Batch * N_Neg) items at once\n",
    "        \n",
    "        # 1. Flatten Negatives: [Batch, N_Neg] -> [Batch * N_Neg]\n",
    "        neg_items_flat = neg_items.view(-1)\n",
    "        \n",
    "        # 2. Repeat User and Last Item to match the flattened negatives\n",
    "        # [Batch] -> [Batch * N_Neg]\n",
    "        u_flat = u.repeat_interleave(N_NEG)\n",
    "        last_item_flat = last_item.repeat_interleave(N_NEG)\n",
    "        \n",
    "        # 3. Compute Scores\n",
    "        neg_scores_flat = model(u_flat, last_item_flat, neg_items_flat)\n",
    "        \n",
    "        # 4. Reshape back to [Batch, N_Neg]\n",
    "        neg_scores = neg_scores_flat.view(-1, N_NEG)\n",
    "        \n",
    "        # --- C. BPR Loss ---\n",
    "        # pos_scores: [Batch] -> [Batch, 1] for broadcasting\n",
    "        # neg_scores: [Batch, N_Neg]\n",
    "        # Loss: -log_sigmoid(pos - neg)\n",
    "        loss = -torch.mean(torch.nn.functional.logsigmoid(pos_scores.unsqueeze(1) - neg_scores))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # --- 3. Evaluation ---\n",
    "    hr, ndcg = val_evaluator_fpmc.evaluate(model, device=DEVICE)\n",
    "    \n",
    "    # --- 4. Logging ---\n",
    "    print(f\"Epoch {epoch:02d} Completed\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"  Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Validation HR@1:   {hr[1]:.4f} | HR@10:   {hr[10]:.4f}\")\n",
    "    print(f\"  Validation NDCG@1: {ndcg[1]:.4f} | NDCG@10: {ndcg[10]:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# --- 5. Save Model ---\n",
    "save_path = \"/data/sukhanna/cse258/fpmc_model.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"\\nFPMC Training Complete. Model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61acda9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FPMC Test Evaluation...\n",
      "------------------------------\n",
      "Test HR@1:   0.2674 | HR@10:   0.5477\n",
      "Test NDCG@1: 0.2674 | NDCG@10: 0.3986\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the Test Evaluator\n",
    "# We reuse the exclusion_rules from the training dataset.\n",
    "# This ensures that for every user, we exclude (Train History + Val Target + Test Target)\n",
    "# from the pool of 100 negative samples.\n",
    "test_evaluator_fpmc = FPMCEvaluator(\n",
    "    eval_data=test_data, \n",
    "    exclusion_rules=train_dataset_fpmc.exclusion_rules, \n",
    "    num_items=len(item2id), \n",
    "    k_list=[1, 10]\n",
    ")\n",
    "\n",
    "# 2. Run Evaluation\n",
    "# Ensure the model is in eval mode (handled inside the class, but good practice)\n",
    "print(\"Running FPMC Test Evaluation...\")\n",
    "test_hr, test_ndcg = test_evaluator_fpmc.evaluate(model, device=DEVICE)\n",
    "\n",
    "# 3. Report Results\n",
    "print(\"-\" * 30)\n",
    "print(f\"Test HR@1:   {test_hr[1]:.4f} | HR@10:   {test_hr[10]:.4f}\")\n",
    "print(f\"Test NDCG@1: {test_ndcg[1]:.4f} | NDCG@10: {test_ndcg[10]:.4f}\")\n",
    "print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b2e83a",
   "metadata": {},
   "source": [
    "# LLM-based Recommender System - Proposed Methodology\n",
    "\n",
    "\n",
    "## Overview\n",
    "- **Stage A**: Pretrains user/item embeddings using collaborative filtering losses with a full-finetuned LLM backbone\n",
    "- Uses embeddings as soft tokens injected into the LLM\n",
    "- Efficient dot-product scoring for next-item prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jsawant/.conda/envs/jay2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# IMPORTS AND SETUP\n",
    "# ============================================================================\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import gzip\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional, Any\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.amp import autocast, GradScaler\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import yaml\n",
    "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set your configuration here. You can modify these values to customize training and prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ============================================================================\n",
    "# CONFIGURATION\n",
    "# ============================================================================\n",
    "\n",
    "# Data paths\n",
    "USER_SEQUENCES_PATH = \"/space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/dataset/filtered_user_sequences.jsonl.gz\"\n",
    "ITEM_METADATA_PATH = \"/space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/dataset/filtered_Kindle_Store.jsonl.gz\"\n",
    "DATA_OUTPUT_DIR = \"./data/processed_notebook\"\n",
    "\n",
    "# Model configuration\n",
    "CONFIG = {\n",
    "  \"data\": {\n",
    "        'user_sequences_path': USER_SEQUENCES_PATH,\n",
    "        'item_metadata_path': ITEM_METADATA_PATH,\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"min_sequence_length\": 3,\n",
    "    \"max_sequence_length\": 50,\n",
    "    \"seed\": 42,\n",
    "    \"max_train_sequences\": 100000\n",
    "  },\n",
    "  \"model\": {\n",
    "    \"base_llm\": \"gpt2\",\n",
    "    \"embedding_dim\": 128,\n",
    "    \"freeze_llm_stage_a\": False,\n",
    "    \"freeze_llm_stage_b\": False,\n",
    "    \"random_init_stage_a_llm\": False,\n",
    "    \"use_lora\": False,\n",
    "    \"lora_r\": 16,\n",
    "    \"lora_alpha\": 32,\n",
    "    \"lora_dropout\": 0.05,\n",
    "    \"use_embedding_fusion\": False,\n",
    "    \"fusion_weight\": 0.7\n",
    "  },\n",
    "  \"embeddings\": {\n",
    "    \"lambda_c\": 0.001,\n",
    "    \"lambda_t\": 0.001,\n",
    "    \"temperature\": 0.07\n",
    "  },\n",
    "  \"stage_a\": {\n",
    "    \"epochs\": 10,\n",
    "    \"batch_size\": 64,\n",
    "    \"learning_rate\": 0.0005,\n",
    "    \"weight_decay\": 0.001,\n",
    "    \"max_grad_norm\": 1.0,\n",
    "    \"loss_weights\": {\n",
    "      \"collaborative\": 1.0,\n",
    "      \"content\": 0.0,\n",
    "      \"contrastive\": 0.0,\n",
    "      \"cf_bpr\": 0.2,\n",
    "      \"regularization\": 0.0\n",
    "    },\n",
    "    \"collaborative\": {\n",
    "      \"negative_samples\": 30,\n",
    "      \"use_bpr_loss\": True\n",
    "    },\n",
    "    \"content\": {\n",
    "      \"max_text_length\": 128\n",
    "    }\n",
    "  },\n",
    "  \"training\": {\n",
    "    \"device\": str(device),\n",
    "    \"mixed_precision\": \"no\",\n",
    "    \"logging_steps\": 500,\n",
    "    \"eval_steps\": 10000,\n",
    "    \"save_steps\": 10000\n",
    "  }\n",
    "}\n",
    "\n",
    "# Output directories\n",
    "CHECKPOINT_DIR = \"./checkpoints/notebook_training\"\n",
    "Path(CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(DATA_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Configuration loaded!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Functions and Classes\n",
    "\n",
    "All the core classes and functions from the codebase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataPreprocessor class defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "class DataPreprocessor:\n",
    "    \"\"\"Preprocesses user sequences and item metadata for LLM-based recommendation.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        user_sequences_path: str,\n",
    "        item_metadata_path: Optional[str] = None,\n",
    "        min_sequence_length: int = 5,\n",
    "        max_sequence_length: int = 50,\n",
    "        train_ratio: float = 0.8,\n",
    "        val_ratio: float = 0.1,\n",
    "        seed: int = 42,\n",
    "        max_train_sequences: Optional[int] = None\n",
    "    ):\n",
    "        self.user_sequences_path = user_sequences_path\n",
    "        self.item_metadata_path = item_metadata_path\n",
    "        self.min_sequence_length = min_sequence_length\n",
    "        self.max_sequence_length = max_sequence_length\n",
    "        self.train_ratio = train_ratio\n",
    "        self.val_ratio = val_ratio\n",
    "        self.test_ratio = 1.0 - train_ratio - val_ratio\n",
    "        self.seed = seed\n",
    "        self.max_train_sequences = max_train_sequences\n",
    "        \n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        # Mappings\n",
    "        self.user2id: Dict[str, int] = {}\n",
    "        self.item2id: Dict[str, int] = {}\n",
    "        self.id2user: Dict[int, str] = {}\n",
    "        self.id2item: Dict[int, str] = {}\n",
    "        \n",
    "        # Data\n",
    "        self.user_sequences: Dict[int, List[Dict]] = {}\n",
    "        self.item_metadata: Dict[int, Dict] = {}\n",
    "        \n",
    "    def load_and_preprocess(self) -> Tuple[Dict, Dict, Dict]:\n",
    "        \"\"\"Load and preprocess all data.\"\"\"\n",
    "        print(\"Loading user sequences...\")\n",
    "        self._load_user_sequences()\n",
    "        \n",
    "        if self.item_metadata_path:\n",
    "            print(\"Loading item metadata...\")\n",
    "            self._load_item_metadata()\n",
    "        \n",
    "        # Truncate user sequences first if requested\n",
    "        if self.max_train_sequences is not None:\n",
    "            print(f\"\\nTruncating to {self.max_train_sequences} sequences...\")\n",
    "            self._truncate_user_sequences(self.max_train_sequences)\n",
    "        \n",
    "        print(\"Creating train/val/test splits...\")\n",
    "        train_data, val_data, test_data = self._create_splits()\n",
    "        \n",
    "        # Remap item IDs to be compact (1-indexed, 0 for padding)\n",
    "        if self.max_train_sequences is not None:\n",
    "            print(\"\\nRemapping item IDs to compact range...\")\n",
    "            train_data, val_data, test_data = self._remap_item_ids(\n",
    "                train_data, val_data, test_data\n",
    "            )\n",
    "        \n",
    "        stats = self._compute_statistics()\n",
    "        print(f\"\\nDataset Statistics:\")\n",
    "        print(f\"  Users: {stats['num_users']}\")\n",
    "        print(f\"  Items: {stats['num_items']}\")\n",
    "        print(f\"  Interactions: {stats['num_interactions']}\")\n",
    "        print(f\"  Avg sequence length: {stats['avg_seq_length']:.2f}\")\n",
    "        print(f\"  Train sequences: {len(train_data)}\")\n",
    "        print(f\"  Val sequences: {len(val_data)}\")\n",
    "        print(f\"  Test sequences: {len(test_data)}\")\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "    \n",
    "    def _load_user_sequences(self):\n",
    "        \"\"\"Load user interaction sequences from JSONL file.\"\"\"\n",
    "        user_idx = 0\n",
    "        item_idx = 1  # Start from 1, reserve 0 for padding\n",
    "        \n",
    "        with gzip.open(self.user_sequences_path, 'rt', encoding='utf-8') as f:\n",
    "            for line in tqdm(f, desc=\"Loading sequences\"):\n",
    "                data = json.loads(line.strip())\n",
    "                user_id_str = data['user_id']\n",
    "                sequence = data['sequence']\n",
    "                \n",
    "                # Filter by sequence length\n",
    "                if len(sequence) < self.min_sequence_length:\n",
    "                    continue\n",
    "                \n",
    "                # Map user ID\n",
    "                if user_id_str not in self.user2id:\n",
    "                    self.user2id[user_id_str] = user_idx\n",
    "                    self.id2user[user_idx] = user_id_str\n",
    "                    user_idx += 1\n",
    "                \n",
    "                user_id = self.user2id[user_id_str]\n",
    "                \n",
    "                # Map item IDs and process sequence\n",
    "                processed_sequence = []\n",
    "                for interaction in sequence:\n",
    "                    item_id_str = interaction['asin']\n",
    "                    \n",
    "                    if item_id_str not in self.item2id:\n",
    "                        self.item2id[item_id_str] = item_idx\n",
    "                        self.id2item[item_idx] = item_id_str\n",
    "                        item_idx += 1\n",
    "                    \n",
    "                    item_id = self.item2id[item_id_str]\n",
    "                    \n",
    "                    processed_sequence.append({\n",
    "                        'item_id': item_id,\n",
    "                        'timestamp': interaction['ts'],\n",
    "                        'rating': interaction.get('rating', 0.0)\n",
    "                    })\n",
    "                \n",
    "                # Sort by timestamp\n",
    "                processed_sequence = sorted(processed_sequence, key=lambda x: x['timestamp'])\n",
    "                \n",
    "                # Truncate if too long\n",
    "                if len(processed_sequence) > self.max_sequence_length:\n",
    "                    processed_sequence = processed_sequence[-self.max_sequence_length:]\n",
    "                \n",
    "                self.user_sequences[user_id] = processed_sequence\n",
    "    \n",
    "    def _load_item_metadata(self):\n",
    "        \"\"\"Load item metadata (titles, descriptions, etc.).\"\"\"\n",
    "        with gzip.open(self.item_metadata_path, 'rt', encoding='utf-8') as f:\n",
    "            for line in tqdm(f, desc=\"Loading metadata\"):\n",
    "                data = json.loads(line.strip())\n",
    "                item_id_str = data.get('parent_asin') or data.get('asin')\n",
    "                \n",
    "                if item_id_str in self.item2id:\n",
    "                    item_id = self.item2id[item_id_str]\n",
    "                    \n",
    "                    # Extract relevant metadata\n",
    "                    self.item_metadata[item_id] = {\n",
    "                        'title': data.get('title', ''),\n",
    "                        'description': ' '.join(data.get('description', [])) if isinstance(data.get('description'), list) else data.get('description', ''),\n",
    "                        'categories': data.get('categories', []),\n",
    "                        'price': data.get('price', 0.0),\n",
    "                        'average_rating': data.get('average_rating', 0.0)\n",
    "                    }\n",
    "    \n",
    "    def _create_splits(self) -> Tuple[Dict, Dict, Dict]:\n",
    "        \"\"\"Create train/validation/test splits using leave-one-out strategy.\"\"\"\n",
    "        train_data = {}\n",
    "        val_data = {}\n",
    "        test_data = {}\n",
    "        \n",
    "        for user_id, sequence in self.user_sequences.items():\n",
    "            seq_len = len(sequence)\n",
    "            \n",
    "            if seq_len < 3:\n",
    "                continue\n",
    "            \n",
    "            # Leave-one-out split: last item for test, second-to-last for val\n",
    "            train_seq = sequence[:-2]  # All items up to T-2\n",
    "            val_item = sequence[-2]     # Item at T-1\n",
    "            test_item = sequence[-1]    # Item at T\n",
    "            \n",
    "            if len(train_seq) >= self.min_sequence_length - 1:\n",
    "                # Training: Full sequence for autoregressive training\n",
    "                train_data[user_id] = {\n",
    "                    'sequence': train_seq,\n",
    "                    'is_autoregressive': True\n",
    "                }\n",
    "                \n",
    "                # Validation: Predict single next item\n",
    "                val_data[user_id] = {\n",
    "                    'sequence': train_seq,\n",
    "                    'target': val_item,\n",
    "                    'is_autoregressive': False\n",
    "                }\n",
    "                \n",
    "                # Test: Predict single next item\n",
    "                test_data[user_id] = {\n",
    "                    'sequence': sequence[:-1],  # Include validation item\n",
    "                    'target': test_item,\n",
    "                    'is_autoregressive': False\n",
    "                }\n",
    "        \n",
    "        return train_data, val_data, test_data\n",
    "    \n",
    "    def _truncate_user_sequences(self, max_sequences: int):\n",
    "        \"\"\"Truncate user_sequences to max_sequences before creating splits.\"\"\"\n",
    "        user_ids = list(self.user_sequences.keys())\n",
    "        if len(user_ids) > max_sequences:\n",
    "            np.random.shuffle(user_ids)\n",
    "            user_ids = user_ids[:max_sequences]\n",
    "            self.user_sequences = {uid: self.user_sequences[uid] for uid in user_ids}\n",
    "            print(f\"  Truncated to {len(self.user_sequences)} user sequences\")\n",
    "            \n",
    "            # Update user mappings\n",
    "            kept_user_ids = set(user_ids)\n",
    "            new_user2id = {}\n",
    "            new_id2user = {}\n",
    "            new_user_idx = 0\n",
    "            \n",
    "            for old_user_id in sorted(kept_user_ids):\n",
    "                old_user_str = self.id2user[old_user_id]\n",
    "                new_user2id[old_user_str] = new_user_idx\n",
    "                new_id2user[new_user_idx] = old_user_str\n",
    "                new_user_idx += 1\n",
    "            \n",
    "            # Remap user IDs in sequences\n",
    "            remapped_sequences = {}\n",
    "            for old_user_id, sequence in self.user_sequences.items():\n",
    "                old_user_str = self.id2user[old_user_id]\n",
    "                new_user_id = new_user2id[old_user_str]\n",
    "                remapped_sequences[new_user_id] = sequence\n",
    "            \n",
    "            self.user_sequences = remapped_sequences\n",
    "            self.user2id = new_user2id\n",
    "            self.id2user = new_id2user\n",
    "    \n",
    "    def _remap_item_ids(\n",
    "        self,\n",
    "        train_data: Dict,\n",
    "        val_data: Dict,\n",
    "        test_data: Dict\n",
    "    ) -> Tuple[Dict, Dict, Dict]:\n",
    "        \"\"\"Remap item IDs to compact range (1-indexed, 0 reserved for padding).\"\"\"\n",
    "        # Collect all items that appear in final dataset\n",
    "        all_items = set()\n",
    "        \n",
    "        for user_data in train_data.values():\n",
    "            for item in user_data['sequence']:\n",
    "                all_items.add(item['item_id'])\n",
    "        \n",
    "        for user_data in val_data.values():\n",
    "            for item in user_data['sequence']:\n",
    "                all_items.add(item['item_id'])\n",
    "            all_items.add(user_data['target']['item_id'])\n",
    "        \n",
    "        for user_data in test_data.values():\n",
    "            for item in user_data['sequence']:\n",
    "                all_items.add(item['item_id'])\n",
    "            all_items.add(user_data['target']['item_id'])\n",
    "        \n",
    "        print(f\"  Found {len(all_items)} unique items in final dataset\")\n",
    "        \n",
    "        # Create mapping: old_item_id -> new_item_id\n",
    "        old_to_new_item = {}\n",
    "        new_item_idx = 1  # Start from 1, reserve 0 for padding\n",
    "        \n",
    "        sorted_items = sorted(all_items)\n",
    "        for old_item_id in sorted_items:\n",
    "            old_to_new_item[old_item_id] = new_item_idx\n",
    "            new_item_idx += 1\n",
    "        \n",
    "        # Update item2id and id2item mappings\n",
    "        new_item2id = {}\n",
    "        new_id2item = {}\n",
    "        for old_item_id, new_item_id in old_to_new_item.items():\n",
    "            old_item_str = self.id2item[old_item_id]\n",
    "            new_item2id[old_item_str] = new_item_id\n",
    "            new_id2item[new_item_id] = old_item_str\n",
    "        \n",
    "        self.item2id = new_item2id\n",
    "        self.id2item = new_id2item\n",
    "        \n",
    "        # Remap item IDs in all data\n",
    "        def remap_sequence(sequence):\n",
    "            return [{\n",
    "                **item,\n",
    "                'item_id': old_to_new_item[item['item_id']]\n",
    "            } for item in sequence]\n",
    "        \n",
    "        def remap_target(target):\n",
    "            return {\n",
    "                **target,\n",
    "                'item_id': old_to_new_item[target['item_id']]\n",
    "            }\n",
    "        \n",
    "        remapped_train_data = {}\n",
    "        for user_id, user_data in train_data.items():\n",
    "            remapped_train_data[user_id] = {\n",
    "                'sequence': remap_sequence(user_data['sequence']),\n",
    "                'is_autoregressive': user_data['is_autoregressive']\n",
    "            }\n",
    "        \n",
    "        remapped_val_data = {}\n",
    "        for user_id, user_data in val_data.items():\n",
    "            remapped_val_data[user_id] = {\n",
    "                'sequence': remap_sequence(user_data['sequence']),\n",
    "                'target': remap_target(user_data['target']),\n",
    "                'is_autoregressive': user_data['is_autoregressive']\n",
    "            }\n",
    "        \n",
    "        remapped_test_data = {}\n",
    "        for user_id, user_data in test_data.items():\n",
    "            remapped_test_data[user_id] = {\n",
    "                'sequence': remap_sequence(user_data['sequence']),\n",
    "                'target': remap_target(user_data['target']),\n",
    "                'is_autoregressive': user_data['is_autoregressive']\n",
    "            }\n",
    "        \n",
    "        # Update item_metadata\n",
    "        remapped_item_metadata = {}\n",
    "        for old_item_id, new_item_id in old_to_new_item.items():\n",
    "            if old_item_id in self.item_metadata:\n",
    "                remapped_item_metadata[new_item_id] = self.item_metadata[old_item_id]\n",
    "        \n",
    "        self.item_metadata = remapped_item_metadata\n",
    "        \n",
    "        print(f\"  Remapped {len(old_to_new_item)} items to new IDs (1-{len(old_to_new_item)})\")\n",
    "        print(f\"  Updated item metadata: {len(self.item_metadata)} items\")\n",
    "        \n",
    "        return remapped_train_data, remapped_val_data, remapped_test_data\n",
    "    \n",
    "    def _compute_statistics(self) -> Dict:\n",
    "        \"\"\"Compute dataset statistics.\"\"\"\n",
    "        num_users = len(self.user2id)\n",
    "        num_items = len(self.item2id)\n",
    "        num_interactions = sum(len(seq) for seq in self.user_sequences.values())\n",
    "        avg_seq_length = num_interactions / num_users if num_users > 0 else 0\n",
    "        \n",
    "        return {\n",
    "            'num_users': num_users,\n",
    "            'num_items': num_items,\n",
    "            'num_interactions': num_interactions,\n",
    "            'avg_seq_length': avg_seq_length\n",
    "        }\n",
    "    \n",
    "    def save_mappings(self, save_dir: str):\n",
    "        \"\"\"Save user/item mappings to disk.\"\"\"\n",
    "        save_path = Path(save_dir)\n",
    "        save_path.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        with open(save_path / 'user2id.pkl', 'wb') as f:\n",
    "            pickle.dump(self.user2id, f)\n",
    "        \n",
    "        with open(save_path / 'item2id.pkl', 'wb') as f:\n",
    "            pickle.dump(self.item2id, f)\n",
    "        \n",
    "        with open(save_path / 'id2user.pkl', 'wb') as f:\n",
    "            pickle.dump(self.id2user, f)\n",
    "        \n",
    "        with open(save_path / 'id2item.pkl', 'wb') as f:\n",
    "            pickle.dump(self.id2item, f)\n",
    "        \n",
    "        with open(save_path / 'item_metadata.pkl', 'wb') as f:\n",
    "            pickle.dump(self.item_metadata, f)\n",
    "        \n",
    "        print(f\"Mappings saved to {save_path}\")\n",
    "\n",
    "print(\"DataPreprocessor class defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset classes defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATASET CLASSES\n",
    "# ============================================================================\n",
    "\n",
    "class RecDataset(Dataset):\n",
    "    \"\"\"Dataset for LLM-based recommendation.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data: Dict[int, Dict],\n",
    "        item_metadata: Dict[int, Dict],\n",
    "        num_items: int,\n",
    "        mode: str = 'train',\n",
    "        negative_samples: int = 5,\n",
    "        max_seq_length: int = 50,\n",
    "        eval_negatives: int = 100,\n",
    "        eval_seed: int = 42\n",
    "    ):\n",
    "        self.data = data\n",
    "        self.item_metadata = item_metadata\n",
    "        self.num_items = num_items\n",
    "        self.mode = mode\n",
    "        self.negative_samples = negative_samples\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.eval_negatives = eval_negatives\n",
    "        self.eval_seed = eval_seed\n",
    "        \n",
    "        self.user_ids = list(data.keys())\n",
    "        \n",
    "        # Precompute negative samples for val/test (SASRec protocol: 100 negatives per user)\n",
    "        if self.mode in ['val', 'test']:\n",
    "            self.eval_negative_samples = {}\n",
    "            np.random.seed(eval_seed)\n",
    "            \n",
    "            all_items = np.arange(1, self.num_items, dtype=np.int32)\n",
    "            item_mask = np.ones(self.num_items, dtype=bool)\n",
    "            item_mask[0] = False\n",
    "            \n",
    "            for user_id in tqdm(self.user_ids, desc=\"Precomputing negative samples\"):\n",
    "                user_data = self.data[user_id]\n",
    "                sequence = user_data['sequence']\n",
    "                target = user_data.get('target', {})\n",
    "                \n",
    "                user_items_list = [item['item_id'] for item in sequence]\n",
    "                if target and 'item_id' in target:\n",
    "                    user_items_list.append(target['item_id'])\n",
    "                \n",
    "                item_mask.fill(True)\n",
    "                item_mask[0] = False\n",
    "                \n",
    "                if user_items_list:\n",
    "                    user_items_arr = np.array(user_items_list, dtype=np.int32)\n",
    "                    valid_mask = (user_items_arr > 0) & (user_items_arr < self.num_items)\n",
    "                    item_mask[user_items_arr[valid_mask]] = False\n",
    "                \n",
    "                neg_candidates = all_items[item_mask[1:]]\n",
    "                \n",
    "                if len(neg_candidates) >= self.eval_negatives:\n",
    "                    self.eval_negative_samples[user_id] = np.random.choice(\n",
    "                        neg_candidates, \n",
    "                        size=self.eval_negatives, \n",
    "                        replace=False\n",
    "                    ).tolist()\n",
    "                else:\n",
    "                    self.eval_negative_samples[user_id] = (\n",
    "                        neg_candidates.tolist() + \n",
    "                        np.random.choice(\n",
    "                            neg_candidates,\n",
    "                            size=self.eval_negatives - len(neg_candidates),\n",
    "                            replace=True\n",
    "                        ).tolist()\n",
    "                    )\n",
    "        \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.user_ids)\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> Dict:\n",
    "        user_id = self.user_ids[idx]\n",
    "        user_data = self.data[user_id]\n",
    "        \n",
    "        sequence = user_data['sequence']\n",
    "        is_autoregressive = user_data.get('is_autoregressive', False)\n",
    "        \n",
    "        item_ids = [item['item_id'] for item in sequence]\n",
    "        ratings = [item['rating'] for item in sequence]\n",
    "        \n",
    "        if len(item_ids) > self.max_seq_length:\n",
    "            item_ids = item_ids[-self.max_seq_length:]\n",
    "            ratings = ratings[-self.max_seq_length:]\n",
    "        \n",
    "        seq_length = len(item_ids)\n",
    "        \n",
    "        if is_autoregressive:\n",
    "            target_item_id = None\n",
    "            target_item_ids = item_ids[1:] + [0]\n",
    "        else:\n",
    "            target = user_data['target']\n",
    "            target_item_id = target['item_id']\n",
    "            target_item_ids = None\n",
    "        \n",
    "        negative_items = []\n",
    "        if self.mode == 'train':\n",
    "            if is_autoregressive:\n",
    "                user_items = set(item_ids)\n",
    "            else:\n",
    "                user_items = set(item_ids + [target_item_id])\n",
    "            \n",
    "            neg_candidates = list(set(range(1, self.num_items)) - user_items)\n",
    "            \n",
    "            if len(neg_candidates) >= self.negative_samples:\n",
    "                negative_items = random.sample(neg_candidates, self.negative_samples)\n",
    "            else:\n",
    "                negative_items = neg_candidates + random.choices(\n",
    "                    neg_candidates, \n",
    "                    k=self.negative_samples - len(neg_candidates)\n",
    "                )\n",
    "        elif self.mode in ['val', 'test']:\n",
    "            negative_items = self.eval_negative_samples[user_id]\n",
    "        \n",
    "        return {\n",
    "            'user_id': user_id,\n",
    "            'item_ids': item_ids,\n",
    "            'ratings': ratings,\n",
    "            'seq_length': seq_length,\n",
    "            'target_item_id': target_item_id,\n",
    "            'target_item_ids': target_item_ids,\n",
    "            'negative_items': negative_items,\n",
    "            'is_autoregressive': is_autoregressive\n",
    "        }\n",
    "\n",
    "\n",
    "class RecDataModule:\n",
    "    \"\"\"Data module for handling train/val/test data loaders.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        train_data: Dict,\n",
    "        val_data: Dict,\n",
    "        test_data: Dict,\n",
    "        item_metadata: Dict,\n",
    "        num_items: int,\n",
    "        tokenizer = None,\n",
    "        batch_size: int = 32,\n",
    "        num_workers: int = 4,\n",
    "        negative_samples: int = 5,\n",
    "        max_seq_length: int = 50,\n",
    "        max_text_length: int = 128,\n",
    "        eval_seed: int = 42\n",
    "    ):\n",
    "        self.train_data = train_data\n",
    "        self.val_data = val_data\n",
    "        self.test_data = test_data\n",
    "        self.item_metadata = item_metadata\n",
    "        self.num_items = num_items\n",
    "        self.tokenizer = tokenizer\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.negative_samples = negative_samples\n",
    "        self.max_seq_length = max_seq_length\n",
    "        self.max_text_length = max_text_length\n",
    "        self.eval_seed = eval_seed\n",
    "        \n",
    "        self.train_dataset = RecDataset(\n",
    "            train_data, item_metadata, num_items, \n",
    "            mode='train', \n",
    "            negative_samples=negative_samples,\n",
    "            max_seq_length=max_seq_length,\n",
    "            eval_seed=eval_seed\n",
    "        )\n",
    "        \n",
    "        self.val_dataset = RecDataset(\n",
    "            val_data, item_metadata, num_items, \n",
    "            mode='val',\n",
    "            max_seq_length=max_seq_length,\n",
    "            eval_seed=eval_seed\n",
    "        )\n",
    "        \n",
    "        self.test_dataset = RecDataset(\n",
    "            test_data, item_metadata, num_items, \n",
    "            mode='test',\n",
    "            max_seq_length=max_seq_length,\n",
    "            eval_seed=eval_seed\n",
    "        )\n",
    "    \n",
    "    def collate_fn(self, batch: List[Dict]) -> Dict:\n",
    "        \"\"\"Collate function for batching.\"\"\"\n",
    "        user_ids = [item['user_id'] for item in batch]\n",
    "        seq_lengths = [item['seq_length'] for item in batch]\n",
    "        is_autoregressive = batch[0]['is_autoregressive']\n",
    "        \n",
    "        max_len = max(seq_lengths)\n",
    "        \n",
    "        item_ids_padded = []\n",
    "        ratings_padded = []\n",
    "        attention_mask = []\n",
    "        target_item_ids_padded = []\n",
    "        \n",
    "        for item in batch:\n",
    "            item_ids = item['item_ids']\n",
    "            ratings = item['ratings']\n",
    "            pad_len = max_len - len(item_ids)\n",
    "            \n",
    "            item_ids_padded.append(item_ids + [0] * pad_len)\n",
    "            ratings_padded.append(ratings + [0.0] * pad_len)\n",
    "            attention_mask.append([1] * len(item_ids) + [0] * pad_len)\n",
    "            \n",
    "            if is_autoregressive:\n",
    "                target_ids = item['target_item_ids']\n",
    "                target_item_ids_padded.append(target_ids + [0] * pad_len)\n",
    "        \n",
    "        if is_autoregressive:\n",
    "            target_item_ids = torch.LongTensor(target_item_ids_padded)\n",
    "        else:\n",
    "            target_item_ids = torch.LongTensor([item['target_item_id'] for item in batch])\n",
    "        \n",
    "        negative_items = []\n",
    "        if batch[0]['negative_items']:\n",
    "            negative_items = [item['negative_items'] for item in batch]\n",
    "        \n",
    "        return {\n",
    "            'user_ids': torch.LongTensor(user_ids),\n",
    "            'item_ids': torch.LongTensor(item_ids_padded),\n",
    "            'ratings': torch.FloatTensor(ratings_padded),\n",
    "            'attention_mask': torch.LongTensor(attention_mask),\n",
    "            'target_item_ids': target_item_ids,\n",
    "            'negative_items': torch.LongTensor(negative_items) if negative_items else None,\n",
    "            'seq_lengths': torch.LongTensor(seq_lengths),\n",
    "            'is_autoregressive': is_autoregressive\n",
    "        }\n",
    "    \n",
    "    def train_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.collate_fn,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def val_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.val_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.collate_fn,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self) -> DataLoader:\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=self.collate_fn,\n",
    "            pin_memory=True\n",
    "        )\n",
    "\n",
    "print(\"Dataset classes defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding classes defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODEL CLASSES - EMBEDDINGS\n",
    "# ============================================================================\n",
    "\n",
    "class CollaborativeEmbedding(nn.Module):\n",
    "    \"\"\"Collaborative embeddings for users and items with projection to LLM hidden space.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        embedding_dim: int,\n",
    "        llm_hidden_size: int,\n",
    "        lambda_c: float = 0.01,\n",
    "        init_method: str = 'normal'\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.llm_hidden_size = llm_hidden_size\n",
    "        self.lambda_c = lambda_c\n",
    "        \n",
    "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embeddings = nn.Embedding(num_items, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        self.user_proj = nn.Linear(embedding_dim, llm_hidden_size, bias=False)\n",
    "        self.item_proj = nn.Linear(embedding_dim, llm_hidden_size, bias=False)\n",
    "        \n",
    "        self._initialize_embeddings(init_method)\n",
    "    \n",
    "    def _initialize_embeddings(self, method: str):\n",
    "        if method == 'normal':\n",
    "            std = (1.0 / self.lambda_c) ** 0.5\n",
    "            nn.init.normal_(self.user_embeddings.weight, mean=0, std=std)\n",
    "            nn.init.normal_(self.item_embeddings.weight, mean=0, std=std)\n",
    "        elif method == 'xavier':\n",
    "            nn.init.xavier_uniform_(self.user_embeddings.weight)\n",
    "            nn.init.xavier_uniform_(self.item_embeddings.weight)\n",
    "        \n",
    "        nn.init.xavier_uniform_(self.user_proj.weight)\n",
    "        nn.init.xavier_uniform_(self.item_proj.weight)\n",
    "    \n",
    "    def get_user_embeddings(self, user_ids: torch.Tensor) -> tuple:\n",
    "        raw_embeds = self.user_embeddings(user_ids)\n",
    "        proj_embeds = self.user_proj(raw_embeds)\n",
    "        return raw_embeds, proj_embeds\n",
    "    \n",
    "    def get_item_embeddings(self, item_ids: torch.Tensor) -> tuple:\n",
    "        raw_embeds = self.item_embeddings(item_ids)\n",
    "        proj_embeds = self.item_proj(raw_embeds)\n",
    "        return raw_embeds, proj_embeds\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        user_ids: Optional[torch.Tensor] = None,\n",
    "        item_ids: Optional[torch.Tensor] = None,\n",
    "        project: bool = True\n",
    "    ) -> tuple:\n",
    "        user_embeds = None\n",
    "        item_embeds = None\n",
    "        \n",
    "        if user_ids is not None:\n",
    "            if project:\n",
    "                _, user_embeds = self.get_user_embeddings(user_ids)\n",
    "            else:\n",
    "                user_embeds, _ = self.get_user_embeddings(user_ids)\n",
    "        \n",
    "        if item_ids is not None:\n",
    "            if project:\n",
    "                _, item_embeds = self.get_item_embeddings(item_ids)\n",
    "            else:\n",
    "                item_embeds, _ = self.get_item_embeddings(item_ids)\n",
    "        \n",
    "        return user_embeds, item_embeds\n",
    "    \n",
    "    def get_all_item_embeddings(self, project: bool = False) -> torch.Tensor:\n",
    "        if project:\n",
    "            return self.item_proj(self.item_embeddings.weight)\n",
    "        return self.item_embeddings.weight\n",
    "    \n",
    "    def regularization_loss(self) -> torch.Tensor:\n",
    "        user_reg = (self.user_embeddings.weight ** 2).mean()\n",
    "        item_reg = (self.item_embeddings.weight ** 2).mean()\n",
    "        return self.lambda_c * (user_reg + item_reg) / 2\n",
    "\n",
    "\n",
    "class ItemScoringHead(nn.Module):\n",
    "    \"\"\"Scoring head for next-item prediction.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        llm_hidden_size: int,\n",
    "        item_embedding_module: nn.Module,\n",
    "        content_embedding_module: Optional[nn.Module] = None,\n",
    "        fusion_weight: float = 0.5,\n",
    "        use_bias: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.llm_hidden_size = llm_hidden_size\n",
    "        self.item_embedding_module = item_embedding_module\n",
    "        self.content_embedding_module = content_embedding_module\n",
    "        self.fusion_weight = fusion_weight\n",
    "        \n",
    "        self.output_proj = nn.Linear(llm_hidden_size, item_embedding_module.embedding_dim, bias=use_bias)\n",
    "        nn.init.xavier_uniform_(self.output_proj.weight)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        llm_output: torch.Tensor,\n",
    "        candidate_items: Optional[torch.Tensor] = None,\n",
    "        use_fusion: bool = True\n",
    "    ) -> torch.Tensor:\n",
    "        query = self.output_proj(llm_output)\n",
    "        \n",
    "        if candidate_items is not None:\n",
    "            item_embeds_collab, _ = self.item_embedding_module.get_item_embeddings(candidate_items)\n",
    "            \n",
    "            if use_fusion and self.content_embedding_module is not None:\n",
    "                item_embeds_content, _ = self.content_embedding_module.get_item_embeddings(candidate_items)\n",
    "                item_embeds = (self.fusion_weight * item_embeds_collab + \n",
    "                             (1 - self.fusion_weight) * item_embeds_content)\n",
    "            else:\n",
    "                item_embeds = item_embeds_collab\n",
    "            \n",
    "            scores = torch.bmm(item_embeds, query.unsqueeze(-1)).squeeze(-1)\n",
    "        else:\n",
    "            all_item_embeds_collab = self.item_embedding_module.get_all_item_embeddings(project=False)\n",
    "            \n",
    "            if use_fusion and self.content_embedding_module is not None:\n",
    "                all_item_embeds_content = self.content_embedding_module.get_all_item_embeddings(project=False)\n",
    "                all_item_embeds = (self.fusion_weight * all_item_embeds_collab + \n",
    "                                 (1 - self.fusion_weight) * all_item_embeds_content)\n",
    "            else:\n",
    "                all_item_embeds = all_item_embeds_collab\n",
    "            \n",
    "            scores = torch.matmul(query, all_item_embeds.t())\n",
    "        \n",
    "        return scores\n",
    "\n",
    "print(\"Embedding classes defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StageAModel class defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# MODEL CLASSES - STAGE A MODEL\n",
    "# ============================================================================\n",
    "\n",
    "class StageAModel(nn.Module):\n",
    "    \"\"\"Stage A: Pretrain user/item token embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_llm_name: str,\n",
    "        num_users: int,\n",
    "        num_items: int,\n",
    "        embedding_dim: int = 64,\n",
    "        lambda_c: float = 0.01,\n",
    "        freeze_llm: bool = True,\n",
    "        use_bpr_loss: bool = True,\n",
    "        random_init_llm: bool = False\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        if random_init_llm:\n",
    "            llm_config = AutoConfig.from_pretrained(base_llm_name)\n",
    "            self.llm = AutoModel.from_config(llm_config)\n",
    "        else:\n",
    "            self.llm = AutoModel.from_pretrained(base_llm_name)\n",
    "        self.llm_hidden_size = self.llm.config.hidden_size\n",
    "        self.vocab_size = self.llm.config.vocab_size\n",
    "        \n",
    "        if freeze_llm:\n",
    "            for param in self.llm.parameters():\n",
    "                param.requires_grad = False\n",
    "        \n",
    "        self.collab_embeddings = CollaborativeEmbedding(\n",
    "            num_users=num_users,\n",
    "            num_items=num_items,\n",
    "            embedding_dim=embedding_dim,\n",
    "            llm_hidden_size=self.llm_hidden_size,\n",
    "            lambda_c=lambda_c,\n",
    "            init_method='xavier'\n",
    "        )\n",
    "        \n",
    "        self.collab_scoring_head = ItemScoringHead(\n",
    "            self.llm_hidden_size,\n",
    "            self.collab_embeddings,\n",
    "            content_embedding_module=None,\n",
    "            fusion_weight=1.0\n",
    "        )\n",
    "        \n",
    "        self.use_bpr_loss = use_bpr_loss\n",
    "    \n",
    "    def forward_collaborative(\n",
    "        self,\n",
    "        user_ids: torch.Tensor,\n",
    "        item_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        batch_size = user_ids.size(0)\n",
    "        \n",
    "        user_embeds, item_embeds = self.collab_embeddings(\n",
    "            user_ids=user_ids,\n",
    "            item_ids=item_ids,\n",
    "            project=True\n",
    "        )\n",
    "        \n",
    "        user_embeds = user_embeds.unsqueeze(1)\n",
    "        inputs_embeds = torch.cat([user_embeds, item_embeds], dim=1)\n",
    "        \n",
    "        user_mask = torch.ones(batch_size, 1, device=attention_mask.device, dtype=attention_mask.dtype)\n",
    "        full_attention_mask = torch.cat([user_mask, attention_mask], dim=1)\n",
    "        \n",
    "        outputs = self.llm(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=full_attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        last_hidden = outputs.last_hidden_state\n",
    "        seq_lengths = full_attention_mask.sum(dim=1) - 1\n",
    "        batch_indices = torch.arange(batch_size, device=last_hidden.device)\n",
    "        output_hidden = last_hidden[batch_indices, seq_lengths]\n",
    "        \n",
    "        return output_hidden\n",
    "    \n",
    "    def compute_collaborative_loss(\n",
    "        self,\n",
    "        user_ids: torch.Tensor,\n",
    "        item_ids: torch.Tensor,\n",
    "        attention_mask: torch.Tensor,\n",
    "        target_items: torch.Tensor,\n",
    "        is_autoregressive: bool = False,\n",
    "        negative_items: Optional[torch.Tensor] = None\n",
    "    ) -> Dict[str, torch.Tensor]:\n",
    "        batch_size = user_ids.size(0)\n",
    "        \n",
    "        user_embeds, item_embeds = self.collab_embeddings(\n",
    "            user_ids=user_ids,\n",
    "            item_ids=item_ids,\n",
    "            project=True\n",
    "        )\n",
    "        \n",
    "        user_embeds = user_embeds.unsqueeze(1)\n",
    "        inputs_embeds = torch.cat([user_embeds, item_embeds], dim=1)\n",
    "        \n",
    "        user_mask = torch.ones(batch_size, 1, device=attention_mask.device, dtype=attention_mask.dtype)\n",
    "        full_attention_mask = torch.cat([user_mask, attention_mask], dim=1)\n",
    "        \n",
    "        outputs = self.llm(\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            attention_mask=full_attention_mask,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        \n",
    "        last_hidden = outputs.last_hidden_state\n",
    "        \n",
    "        if is_autoregressive:\n",
    "            item_hidden = last_hidden[:, 1:, :]\n",
    "            h_query = self.collab_scoring_head.output_proj(item_hidden)\n",
    "            all_item_embeds = self.collab_embeddings.get_all_item_embeddings(project=False)\n",
    "            scores = torch.matmul(h_query, all_item_embeds.t())\n",
    "            \n",
    "            scores_flat = scores.reshape(-1, scores.size(-1))\n",
    "            targets_flat = target_items.reshape(-1)\n",
    "            \n",
    "            valid_mask = (attention_mask > 0) & (target_items > 0)\n",
    "            valid_mask_flat = valid_mask.reshape(-1)\n",
    "            num_valid = valid_mask_flat.sum()\n",
    "            \n",
    "            ce_loss = F.cross_entropy(\n",
    "                scores_flat,\n",
    "                targets_flat,\n",
    "                ignore_index=0,\n",
    "                reduction='sum'\n",
    "            )\n",
    "            ce_loss = ce_loss / num_valid.clamp(min=1)\n",
    "            \n",
    "            losses = {'collaborative_ce': ce_loss}\n",
    "            \n",
    "            if self.use_bpr_loss and negative_items is not None:\n",
    "                h_context = self.collab_scoring_head.output_proj(item_hidden)\n",
    "                _, target_embeds_raw = self.collab_embeddings(item_ids=target_items, project=False)\n",
    "                _, neg_embeds_raw = self.collab_embeddings(item_ids=negative_items, project=False)\n",
    "                \n",
    "                pos_scores_context = torch.sum(h_context * target_embeds_raw, dim=-1)\n",
    "                neg_scores_context = torch.bmm(h_context, neg_embeds_raw.transpose(1, 2))\n",
    "                \n",
    "                pos_scores_expanded = pos_scores_context.unsqueeze(-1)\n",
    "                bpr_logits_context = pos_scores_expanded - neg_scores_context\n",
    "                bpr_loss_context = -torch.log(torch.sigmoid(bpr_logits_context) + 1e-8).sum(dim=-1)\n",
    "                bpr_loss_context = (bpr_loss_context * valid_mask.float()).sum() / num_valid.clamp(min=1)\n",
    "                losses['bpr_context'] = bpr_loss_context\n",
    "                \n",
    "                user_embeds_raw, _ = self.collab_embeddings(user_ids=user_ids, project=False)\n",
    "                user_embeds_expanded = user_embeds_raw.unsqueeze(1).expand(-1, target_embeds_raw.size(1), -1)\n",
    "                \n",
    "                pos_scores_user = torch.sum(user_embeds_expanded * target_embeds_raw, dim=-1)\n",
    "                neg_scores_user = torch.bmm(user_embeds_expanded, neg_embeds_raw.transpose(1, 2))\n",
    "                \n",
    "                pos_scores_user_expanded = pos_scores_user.unsqueeze(-1)\n",
    "                bpr_logits_user = pos_scores_user_expanded - neg_scores_user\n",
    "                bpr_loss_user = -torch.log(torch.sigmoid(bpr_logits_user) + 1e-8).sum(dim=-1)\n",
    "                bpr_loss_user = (bpr_loss_user * valid_mask.float()).sum() / num_valid.clamp(min=1)\n",
    "                losses['bpr_user'] = bpr_loss_user\n",
    "                losses['bpr'] = bpr_loss_context + bpr_loss_user\n",
    "        else:\n",
    "            seq_lengths = full_attention_mask.sum(dim=1) - 1\n",
    "            batch_indices = torch.arange(batch_size, device=last_hidden.device)\n",
    "            llm_output = last_hidden[batch_indices, seq_lengths]\n",
    "            \n",
    "            scores = self.collab_scoring_head(llm_output)\n",
    "            ce_loss = F.cross_entropy(scores, target_items)\n",
    "            losses = {'collaborative_ce': ce_loss}\n",
    "            \n",
    "            if self.use_bpr_loss and negative_items is not None:\n",
    "                h_context = self.collab_scoring_head.output_proj(llm_output)\n",
    "                _, target_embeds_raw = self.collab_embeddings(item_ids=target_items, project=False)\n",
    "                _, neg_embeds_raw = self.collab_embeddings(item_ids=negative_items, project=False)\n",
    "                \n",
    "                pos_scores_context = torch.sum(h_context * target_embeds_raw, dim=-1)\n",
    "                neg_scores_context = torch.sum(h_context.unsqueeze(1) * neg_embeds_raw, dim=-1)\n",
    "                bpr_loss_context = -torch.log(torch.sigmoid(pos_scores_context.unsqueeze(1) - neg_scores_context) + 1e-8).mean()\n",
    "                losses['bpr_context'] = bpr_loss_context\n",
    "                \n",
    "                user_embeds_raw, _ = self.collab_embeddings(user_ids=user_ids, project=False)\n",
    "                pos_scores_user = torch.sum(user_embeds_raw * target_embeds_raw, dim=-1)\n",
    "                neg_scores_user = torch.sum(user_embeds_raw.unsqueeze(1) * neg_embeds_raw, dim=-1)\n",
    "                bpr_loss_user = -torch.log(torch.sigmoid(pos_scores_user.unsqueeze(1) - neg_scores_user) + 1e-8).mean()\n",
    "                losses['bpr_user'] = bpr_loss_user\n",
    "                losses['bpr'] = bpr_loss_context + bpr_loss_user\n",
    "        \n",
    "        return losses\n",
    "    \n",
    "    def compute_regularization_losses(self) -> Dict[str, torch.Tensor]:\n",
    "        collab_reg = self.collab_embeddings.regularization_loss()\n",
    "        return {'collab_regularization': collab_reg}\n",
    "\n",
    "print(\"StageAModel class defined!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics functions defined!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# METRICS\n",
    "# ============================================================================\n",
    "\n",
    "def hr_at_k_sampled(scores: torch.Tensor, targets: torch.Tensor, k: int) -> float:\n",
    "    \"\"\"Compute Hit@K for sampled candidate evaluation (SASRec-style).\"\"\"\n",
    "    topk_idx = scores.topk(k, dim=-1).indices\n",
    "    hits = (topk_idx == targets.unsqueeze(-1)).any(dim=-1).float()\n",
    "    return hits.mean().item()\n",
    "\n",
    "\n",
    "def ndcg_at_k_sampled(scores: torch.Tensor, targets: torch.Tensor, k: int) -> float:\n",
    "    \"\"\"Compute NDCG@K for sampled candidate evaluation (SASRec-style).\"\"\"\n",
    "    topk_idx = scores.topk(k, dim=-1).indices\n",
    "    hits = (topk_idx == targets.unsqueeze(-1))\n",
    "    \n",
    "    positions = torch.arange(1, k + 1, device=scores.device, dtype=torch.float32)\n",
    "    discounts = 1.0 / torch.log2(positions + 1.0)\n",
    "    \n",
    "    gains = (hits.float() * discounts.unsqueeze(0)).max(dim=-1).values\n",
    "    idcg = 1.0 / torch.log2(torch.tensor(2.0, device=scores.device))\n",
    "    ndcg = gains / idcg\n",
    "    \n",
    "    return ndcg.mean().item()\n",
    "\n",
    "\n",
    "def compute_sampled_metrics(\n",
    "    scores: torch.Tensor,\n",
    "    targets: torch.Tensor,\n",
    "    k_list: List[int] = [1, 5, 10]\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Compute SASRec-style sampled metrics.\"\"\"\n",
    "    scores = scores.to(torch.float32)\n",
    "    targets = targets.to(torch.long)\n",
    "    metrics = {}\n",
    "    \n",
    "    for k in k_list:\n",
    "        metrics[f'hit@{k}'] = hr_at_k_sampled(scores, targets, k)\n",
    "        metrics[f'ndcg@{k}'] = ndcg_at_k_sampled(scores, targets, k)\n",
    "    \n",
    "    return metrics\n",
    "\n",
    "\n",
    "def print_metrics(metrics: Dict[str, float], prefix: str = \"\"):\n",
    "    \"\"\"Print metrics in a formatted way.\"\"\"\n",
    "    print(f\"\\n{prefix}Metrics:\")\n",
    "    print(\"-\" * 50)\n",
    "    for metric_name, value in sorted(metrics.items()):\n",
    "        print(f\"  {metric_name}: {value:.4f}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "print(\"Metrics functions defined!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Preprocessing\n",
    "\n",
    "Run this cell to preprocess your data. This will create train/val/test splits and save the processed data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading user sequences...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading sequences: 761756it [00:19, 39216.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading item metadata...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading metadata: 20318771it [02:47, 121026.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Truncating to 100000 sequences...\n",
      "  Truncated to 100000 user sequences\n",
      "Creating train/val/test splits...\n",
      "\n",
      "Remapping item IDs to compact range...\n",
      "  Found 389161 unique items in final dataset\n",
      "  Remapped 389161 items to new IDs (1-389161)\n",
      "  Updated item metadata: 389161 items\n",
      "\n",
      "Dataset Statistics:\n",
      "  Users: 100000\n",
      "  Items: 389161\n",
      "  Interactions: 1319558\n",
      "  Avg sequence length: 13.20\n",
      "  Train sequences: 100000\n",
      "  Val sequences: 100000\n",
      "  Test sequences: 100000\n",
      "\n",
      "Saving processed data to ./data/processed_notebook...\n",
      "Mappings saved to data/processed_notebook\n",
      "\n",
      "Preprocessing complete! Data saved to ./data/processed_notebook\n",
      "\n",
      "Dataset info:\n",
      "  num_users: 100000\n",
      "  num_items: 389162\n",
      "  num_train: 100000\n",
      "  num_val: 100000\n",
      "  num_test: 100000\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# DATA PREPROCESSING\n",
    "# ============================================================================\n",
    "\n",
    "# Create preprocessor\n",
    "preprocessor = DataPreprocessor(\n",
    "    user_sequences_path=CONFIG['data']['user_sequences_path'],\n",
    "    item_metadata_path=CONFIG['data'].get('item_metadata_path'),\n",
    "    min_sequence_length=CONFIG['data']['min_sequence_length'],\n",
    "    max_sequence_length=CONFIG['data']['max_sequence_length'],\n",
    "    train_ratio=CONFIG['data']['train_ratio'],\n",
    "    val_ratio=CONFIG['data']['val_ratio'],\n",
    "    seed=CONFIG['data']['seed'],\n",
    "    max_train_sequences=CONFIG['data'].get('max_train_sequences')\n",
    ")\n",
    "\n",
    "# Load and preprocess data\n",
    "train_data, val_data, test_data = preprocessor.load_and_preprocess()\n",
    "\n",
    "# Save processed data\n",
    "print(f\"\\nSaving processed data to {DATA_OUTPUT_DIR}...\")\n",
    "with open(Path(DATA_OUTPUT_DIR) / 'train_data.pkl', 'wb') as f:\n",
    "    pickle.dump(train_data, f)\n",
    "with open(Path(DATA_OUTPUT_DIR) / 'val_data.pkl', 'wb') as f:\n",
    "    pickle.dump(val_data, f)\n",
    "with open(Path(DATA_OUTPUT_DIR) / 'test_data.pkl', 'wb') as f:\n",
    "    pickle.dump(test_data, f)\n",
    "\n",
    "# Save mappings\n",
    "preprocessor.save_mappings(DATA_OUTPUT_DIR)\n",
    "\n",
    "# Save dataset info\n",
    "dataset_info = {\n",
    "    'num_users': len(preprocessor.user2id),\n",
    "    'num_items': len(preprocessor.item2id) + 1,  # +1 for padding\n",
    "    'num_train': len(train_data),\n",
    "    'num_val': len(val_data),\n",
    "    'num_test': len(test_data)\n",
    "}\n",
    "\n",
    "with open(Path(DATA_OUTPUT_DIR) / 'dataset_info.pkl', 'wb') as f:\n",
    "    pickle.dump(dataset_info, f)\n",
    "\n",
    "print(f\"\\nPreprocessing complete! Data saved to {DATA_OUTPUT_DIR}\")\n",
    "print(\"\\nDataset info:\")\n",
    "for key, value in dataset_info.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Store for later use\n",
    "num_users = dataset_info['num_users']\n",
    "num_items = dataset_info['num_items']\n",
    "item_metadata = preprocessor.item_metadata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1.5: Load Preprocessed Data (Optional)\n",
    "\n",
    "If you've already preprocessed the data, you can load it directly from disk instead of running preprocessing again.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data from /space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/data/processed_notebook...\n",
      "\n",
      "Preprocessed data loaded successfully!\n",
      "  Users: 100000\n",
      "  Items: 389162\n",
      "  Train sequences: 100000\n",
      "  Val sequences: 100000\n",
      "  Test sequences: 100000\n",
      "  Item metadata: 389161 items\n",
      "\n",
      "Using data from: /space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/data/processed_notebook\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD PREPROCESSED DATA (OPTIONAL - SKIP PREPROCESSING IF DATA EXISTS)\n",
    "# ============================================================================\n",
    "\n",
    "# Path to preprocessed data\n",
    "PREPROCESSED_DATA_DIR = \"/space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/data/processed_notebook\"\n",
    "\n",
    "# Check if preprocessed data exists\n",
    "preprocessed_path = Path(PREPROCESSED_DATA_DIR)\n",
    "if preprocessed_path.exists() and (preprocessed_path / 'train_data.pkl').exists():\n",
    "    print(f\"Loading preprocessed data from {PREPROCESSED_DATA_DIR}...\")\n",
    "    \n",
    "    # Load processed data\n",
    "    with open(preprocessed_path / 'train_data.pkl', 'rb') as f:\n",
    "        train_data = pickle.load(f)\n",
    "    with open(preprocessed_path / 'val_data.pkl', 'rb') as f:\n",
    "        val_data = pickle.load(f)\n",
    "    with open(preprocessed_path / 'test_data.pkl', 'rb') as f:\n",
    "        test_data = pickle.load(f)\n",
    "    \n",
    "    # Load dataset info\n",
    "    with open(preprocessed_path / 'dataset_info.pkl', 'rb') as f:\n",
    "        dataset_info = pickle.load(f)\n",
    "    \n",
    "    # Load mappings\n",
    "    with open(preprocessed_path / 'item_metadata.pkl', 'rb') as f:\n",
    "        item_metadata = pickle.load(f)\n",
    "    \n",
    "    # Extract key info\n",
    "    num_users = dataset_info['num_users']\n",
    "    num_items = dataset_info['num_items']\n",
    "    \n",
    "    print(f\"\\nPreprocessed data loaded successfully!\")\n",
    "    print(f\"  Users: {num_users}\")\n",
    "    print(f\"  Items: {num_items}\")\n",
    "    print(f\"  Train sequences: {dataset_info['num_train']}\")\n",
    "    print(f\"  Val sequences: {dataset_info['num_val']}\")\n",
    "    print(f\"  Test sequences: {dataset_info['num_test']}\")\n",
    "    print(f\"  Item metadata: {len(item_metadata)} items\")\n",
    "    \n",
    "    # Update DATA_OUTPUT_DIR to match loaded data location\n",
    "    DATA_OUTPUT_DIR = str(preprocessed_path)\n",
    "    print(f\"\\nUsing data from: {DATA_OUTPUT_DIR}\")\n",
    "else:\n",
    "    print(f\"Preprocessed data not found at {PREPROCESSED_DATA_DIR}\")\n",
    "    print(\"Please run the preprocessing cell (Step 1) first, or update PREPROCESSED_DATA_DIR path.\")\n",
    "    print(\"Skipping data loading - you'll need to run preprocessing.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create Data Loaders\n",
    "\n",
    "Create PyTorch data loaders for training, validation, and testing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# CREATE DATA LOADERS\n",
    "# ============================================================================\n",
    "\n",
    "data_module = RecDataModule(\n",
    "    train_data=train_data,\n",
    "    val_data=val_data,\n",
    "    test_data=test_data,\n",
    "    item_metadata=item_metadata,\n",
    "    num_items=num_items,\n",
    "    tokenizer=None,  # No tokenizer needed for Stage A\n",
    "    batch_size=CONFIG['stage_a']['batch_size'],\n",
    "    num_workers=4,\n",
    "    negative_samples=CONFIG['stage_a']['collaborative']['negative_samples'],\n",
    "    max_seq_length=CONFIG['data']['max_sequence_length'],\n",
    "    max_text_length=None,\n",
    "    eval_seed=CONFIG['data']['seed']\n",
    ")\n",
    "\n",
    "train_loader = data_module.train_dataloader()\n",
    "val_loader = data_module.val_dataloader()\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Model\n",
    "\n",
    "Create and initialize the Stage A model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model parameters:\n",
      "  Total: 187,347,456\n",
      "  Trainable: 187,347,456\n",
      "\n",
      "Model and optimizer initialized!\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# INITIALIZE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "model = StageAModel(\n",
    "    base_llm_name=CONFIG['model']['base_llm'],\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    embedding_dim=CONFIG['model']['embedding_dim'],\n",
    "    lambda_c=CONFIG['embeddings']['lambda_c'],\n",
    "    freeze_llm=CONFIG['model']['freeze_llm_stage_a'],\n",
    "    use_bpr_loss=CONFIG['stage_a']['collaborative'].get('use_bpr_loss', True),\n",
    "    random_init_llm=CONFIG['model'].get('random_init_stage_a_llm', False)\n",
    ")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f\"\\nModel parameters:\")\n",
    "print(f\"  Total: {total_params:,}\")\n",
    "print(f\"  Trainable: {trainable_params:,}\")\n",
    "\n",
    "# Create optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=float(CONFIG['stage_a']['learning_rate']),\n",
    "    weight_decay=float(CONFIG['stage_a']['weight_decay'])\n",
    ")\n",
    "\n",
    "print(\"\\nModel and optimizer initialized!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Training\n",
    "\n",
    "Train the model. This includes training loop, evaluation, and checkpoint saving.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "Output directory: ./checkpoints/notebook_training\n",
      "\n",
      "============================================================\n",
      "Epoch 1/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  32%|███▏      | 500/1563 [01:54<03:27,  5.13it/s, loss=20.3124, step=500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 500] Loss: 19.6449, Avg: 20.3124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  64%|██████▍   | 1001/1563 [03:47<02:07,  4.39it/s, loss=19.9729, step=1000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1000] Loss: 19.7887, Avg: 19.9729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1:  96%|█████████▌| 1500/1563 [05:40<00:16,  3.86it/s, loss=19.7268, step=1500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 1500] Loss: 18.5041, Avg: 19.7268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 1563/1563 [05:55<00:00,  4.40it/s, loss=19.7268, step=1500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 training metrics:\n",
      "  Total loss: 19.6979\n",
      "  Collaborative CE: 12.2699\n",
      "  BPR loss: 37.1399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:36<00:00, 43.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.2062\n",
      "  hit@10: 0.5117\n",
      "  hit@20: 0.6152\n",
      "  hit@5: 0.4110\n",
      "  ndcg@1: 0.2062\n",
      "  ndcg@10: 0.3458\n",
      "  ndcg@20: 0.3719\n",
      "  ndcg@5: 0.3133\n",
      "--------------------------------------------------\n",
      "  ✓ New best model saved! Hit@10: 0.5117\n",
      "\n",
      "============================================================\n",
      "Epoch 2/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  28%|██▊       | 437/1563 [01:51<04:01,  4.67it/s, loss=17.5857, step=2000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 2000] Loss: 17.7912, Avg: 17.5857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  60%|█████▉    | 937/1563 [04:13<02:16,  4.59it/s, loss=17.4651, step=2500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 2500] Loss: 16.5026, Avg: 17.4651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2:  92%|█████████▏| 1437/1563 [06:28<00:27,  4.57it/s, loss=17.3506, step=3000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 3000] Loss: 16.9199, Avg: 17.3506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 1563/1563 [07:02<00:00,  3.70it/s, loss=17.3506, step=3000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 training metrics:\n",
      "  Total loss: 17.3251\n",
      "  Collaborative CE: 11.4308\n",
      "  BPR loss: 29.4713\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:35<00:00, 43.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.2283\n",
      "  hit@10: 0.5314\n",
      "  hit@20: 0.6364\n",
      "  hit@5: 0.4344\n",
      "  ndcg@1: 0.2283\n",
      "  ndcg@10: 0.3678\n",
      "  ndcg@20: 0.3944\n",
      "  ndcg@5: 0.3365\n",
      "--------------------------------------------------\n",
      "  ✓ New best model saved! Hit@10: 0.5314\n",
      "\n",
      "============================================================\n",
      "Epoch 3/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  24%|██▍       | 375/1563 [01:38<04:59,  3.97it/s, loss=16.1474, step=3500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 3500] Loss: 16.0578, Avg: 16.1474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  56%|█████▌    | 875/1563 [03:41<02:58,  3.85it/s, loss=16.1690, step=4000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 4000] Loss: 16.3867, Avg: 16.1690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:  88%|████████▊ | 1375/1563 [05:51<00:44,  4.27it/s, loss=16.1723, step=4500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 4500] Loss: 16.7334, Avg: 16.1723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 1563/1563 [06:40<00:00,  3.90it/s, loss=16.1723, step=4500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 training metrics:\n",
      "  Total loss: 16.1717\n",
      "  Collaborative CE: 10.9368\n",
      "  BPR loss: 26.1745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:36<00:00, 43.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.2704\n",
      "  hit@10: 0.5793\n",
      "  hit@20: 0.6699\n",
      "  hit@5: 0.4884\n",
      "  ndcg@1: 0.2704\n",
      "  ndcg@10: 0.4151\n",
      "  ndcg@20: 0.4380\n",
      "  ndcg@5: 0.3857\n",
      "--------------------------------------------------\n",
      "  ✓ New best model saved! Hit@10: 0.5793\n",
      "\n",
      "============================================================\n",
      "Epoch 4/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  20%|█▉        | 312/1563 [01:27<05:38,  3.70it/s, loss=14.3138, step=5000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 5000] Loss: 14.7591, Avg: 14.3138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  52%|█████▏    | 811/1563 [03:48<03:07,  4.00it/s, loss=14.4627, step=5500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 5500] Loss: 14.7395, Avg: 14.4627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4:  84%|████████▍ | 1311/1563 [05:58<00:56,  4.46it/s, loss=14.5596, step=6000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 6000] Loss: 14.8482, Avg: 14.5596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 1563/1563 [07:09<00:00,  3.64it/s, loss=14.5596, step=6000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 training metrics:\n",
      "  Total loss: 14.5989\n",
      "  Collaborative CE: 10.0695\n",
      "  BPR loss: 22.6470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:35<00:00, 43.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 4 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.3018\n",
      "  hit@10: 0.5942\n",
      "  hit@20: 0.6765\n",
      "  hit@5: 0.5089\n",
      "  ndcg@1: 0.3018\n",
      "  ndcg@10: 0.4393\n",
      "  ndcg@20: 0.4601\n",
      "  ndcg@5: 0.4116\n",
      "--------------------------------------------------\n",
      "  ✓ New best model saved! Hit@10: 0.5942\n",
      "\n",
      "============================================================\n",
      "Epoch 5/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  16%|█▌        | 248/1563 [01:05<04:26,  4.93it/s, loss=12.6508, step=6500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 6500] Loss: 13.0353, Avg: 12.6508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  48%|████▊     | 749/1563 [03:16<03:31,  3.85it/s, loss=12.8542, step=7000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 7000] Loss: 13.3318, Avg: 12.8542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5:  80%|███████▉  | 1248/1563 [05:28<01:05,  4.81it/s, loss=13.0008, step=7500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 7500] Loss: 13.2302, Avg: 13.0008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 1563/1563 [06:48<00:00,  3.83it/s, loss=13.0008, step=7500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 training metrics:\n",
      "  Total loss: 13.0808\n",
      "  Collaborative CE: 8.9399\n",
      "  BPR loss: 20.7047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:35<00:00, 43.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 5 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.3153\n",
      "  hit@10: 0.5986\n",
      "  hit@20: 0.6788\n",
      "  hit@5: 0.5169\n",
      "  ndcg@1: 0.3153\n",
      "  ndcg@10: 0.4491\n",
      "  ndcg@20: 0.4694\n",
      "  ndcg@5: 0.4226\n",
      "--------------------------------------------------\n",
      "  ✓ New best model saved! Hit@10: 0.5986\n",
      "\n",
      "============================================================\n",
      "Epoch 6/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  12%|█▏        | 186/1563 [00:51<07:31,  3.05it/s, loss=11.1309, step=8000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 8000] Loss: 11.1651, Avg: 11.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  44%|████▍     | 686/1563 [03:10<04:09,  3.52it/s, loss=11.3706, step=8500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 8500] Loss: 11.7324, Avg: 11.3706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6:  76%|███████▌  | 1186/1563 [05:26<01:24,  4.44it/s, loss=11.5640, step=9000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 9000] Loss: 11.8580, Avg: 11.5640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 1563/1563 [07:10<00:00,  3.63it/s, loss=11.5640, step=9000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 training metrics:\n",
      "  Total loss: 11.6859\n",
      "  Collaborative CE: 7.7187\n",
      "  BPR loss: 19.8361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:35<00:00, 43.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 6 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.3106\n",
      "  hit@10: 0.5893\n",
      "  hit@20: 0.6726\n",
      "  hit@5: 0.5090\n",
      "  ndcg@1: 0.3106\n",
      "  ndcg@10: 0.4421\n",
      "  ndcg@20: 0.4632\n",
      "  ndcg@5: 0.4161\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Epoch 7/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:   8%|▊         | 122/1563 [00:33<05:52,  4.09it/s, loss=9.7813, step=9500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 9500] Loss: 9.8506, Avg: 9.7813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:  40%|███▉      | 621/1563 [02:42<04:02,  3.89it/s, loss=10.0534, step=1e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 10000] Loss: 9.8392, Avg: 10.0534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:  40%|███▉      | 623/1563 [03:01<1:05:27,  4.18s/it, loss=10.0534, step=1e+4]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpoint saved to checkpoints/notebook_training/checkpoint-10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7:  72%|███████▏  | 1122/1563 [05:19<01:41,  4.36it/s, loss=10.2723, step=10500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 10500] Loss: 10.8323, Avg: 10.2723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 1563/1563 [07:21<00:00,  3.54it/s, loss=10.2723, step=10500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 training metrics:\n",
      "  Total loss: 10.4331\n",
      "  Collaborative CE: 6.5660\n",
      "  BPR loss: 19.3355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:35<00:00, 43.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 7 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.3085\n",
      "  hit@10: 0.5818\n",
      "  hit@20: 0.6685\n",
      "  hit@5: 0.5010\n",
      "  ndcg@1: 0.3085\n",
      "  ndcg@10: 0.4369\n",
      "  ndcg@20: 0.4587\n",
      "  ndcg@5: 0.4108\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Epoch 8/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:   4%|▍         | 60/1563 [00:17<07:01,  3.57it/s, loss=8.8379, step=11000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 11000] Loss: 9.2574, Avg: 8.8379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:  36%|███▌      | 559/1563 [02:27<03:22,  4.95it/s, loss=8.9584, step=11500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 11500] Loss: 9.1848, Avg: 8.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8:  68%|██████▊   | 1060/1563 [04:31<02:11,  3.82it/s, loss=9.1747, step=12000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 12000] Loss: 9.8955, Avg: 9.1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|█████████▉| 1560/1563 [06:41<00:00,  5.52it/s, loss=9.3571, step=12500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 12500] Loss: 10.2042, Avg: 9.3571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 1563/1563 [06:42<00:00,  3.88it/s, loss=9.3571, step=12500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 training metrics:\n",
      "  Total loss: 9.3583\n",
      "  Collaborative CE: 5.5713\n",
      "  BPR loss: 18.9347\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:35<00:00, 43.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 8 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.3042\n",
      "  hit@10: 0.5755\n",
      "  hit@20: 0.6658\n",
      "  hit@5: 0.4933\n",
      "  ndcg@1: 0.3042\n",
      "  ndcg@10: 0.4310\n",
      "  ndcg@20: 0.4538\n",
      "  ndcg@5: 0.4044\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Epoch 9/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:  32%|███▏      | 496/1563 [02:17<03:55,  4.53it/s, loss=8.0991, step=13000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 13000] Loss: 8.3694, Avg: 8.0991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:  64%|██████▎   | 996/1563 [04:35<02:05,  4.51it/s, loss=8.2997, step=13500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 13500] Loss: 8.3811, Avg: 8.2997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9:  96%|█████████▌| 1496/1563 [06:59<00:15,  4.29it/s, loss=8.4656, step=14000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 14000] Loss: 8.8146, Avg: 8.4656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 1563/1563 [07:19<00:00,  3.56it/s, loss=8.4656, step=14000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 training metrics:\n",
      "  Total loss: 8.4877\n",
      "  Collaborative CE: 4.7766\n",
      "  BPR loss: 18.5555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:35<00:00, 43.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 9 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.2901\n",
      "  hit@10: 0.5619\n",
      "  hit@20: 0.6580\n",
      "  hit@5: 0.4788\n",
      "  ndcg@1: 0.2901\n",
      "  ndcg@10: 0.4166\n",
      "  ndcg@20: 0.4408\n",
      "  ndcg@5: 0.3898\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Epoch 10/10\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  28%|██▊       | 434/1563 [01:58<05:01,  3.74it/s, loss=7.3778, step=14500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 14500] Loss: 7.3719, Avg: 7.3778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  60%|█████▉    | 934/1563 [04:17<02:33,  4.09it/s, loss=7.5659, step=15000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 15000] Loss: 8.0171, Avg: 7.5659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10:  92%|█████████▏| 1434/1563 [06:42<00:34,  3.74it/s, loss=7.7294, step=15500]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Step 15500] Loss: 7.8128, Avg: 7.7294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 1563/1563 [07:21<00:00,  3.54it/s, loss=7.7294, step=15500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 training metrics:\n",
      "  Total loss: 7.7677\n",
      "  Collaborative CE: 4.1322\n",
      "  BPR loss: 18.1777\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1563/1563 [00:35<00:00, 43.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 10 Validation Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.2834\n",
      "  hit@10: 0.5534\n",
      "  hit@20: 0.6494\n",
      "  hit@5: 0.4697\n",
      "  ndcg@1: 0.2834\n",
      "  ndcg@10: 0.4089\n",
      "  ndcg@20: 0.4331\n",
      "  ndcg@5: 0.3818\n",
      "--------------------------------------------------\n",
      "\n",
      "============================================================\n",
      "Training complete!\n",
      "Best Hit@10: 0.5986\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# TRAINING LOOP\n",
    "# ============================================================================\n",
    "\n",
    "# Training configuration\n",
    "loss_weights = CONFIG['stage_a']['loss_weights']\n",
    "max_grad_norm = CONFIG['stage_a']['max_grad_norm']\n",
    "mixed_precision = CONFIG['training']['mixed_precision']\n",
    "logging_steps = CONFIG['training']['logging_steps']\n",
    "eval_steps = CONFIG['training']['eval_steps']\n",
    "save_steps = CONFIG['training']['save_steps']\n",
    "\n",
    "# Setup mixed precision\n",
    "use_amp = mixed_precision in ['fp16', 'bf16']\n",
    "amp_dtype = torch.float16 if mixed_precision == 'fp16' else (\n",
    "    torch.bfloat16 if mixed_precision == 'bf16' else torch.float32\n",
    ")\n",
    "device_type = 'cuda' if 'cuda' in str(device) else 'cpu'\n",
    "scaler = GradScaler(device_type) if mixed_precision == 'fp16' and device_type == 'cuda' else None\n",
    "\n",
    "# Training state\n",
    "global_step = 0\n",
    "best_metric = 0.0\n",
    "epoch_history = []\n",
    "\n",
    "# Save config\n",
    "with open(Path(CHECKPOINT_DIR) / 'config.json', 'w') as f:\n",
    "    json.dump(CONFIG, f, indent=2)\n",
    "\n",
    "print(\"Starting training...\")\n",
    "print(f\"Output directory: {CHECKPOINT_DIR}\")\n",
    "\n",
    "for epoch in range(CONFIG['stage_a']['epochs']):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Epoch {epoch + 1}/{CONFIG['stage_a']['epochs']}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    component_sums = {'collab_ce': 0.0, 'bpr': 0.0, 'regularization': 0.0}\n",
    "    component_counts = {k: 0 for k in component_sums.keys()}\n",
    "    \n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                for k, v in batch.items()}\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        with autocast(device_type=device_type, enabled=use_amp, dtype=amp_dtype):\n",
    "            is_autoregressive = batch.get('is_autoregressive', False)\n",
    "            collab_losses = model.compute_collaborative_loss(\n",
    "                user_ids=batch['user_ids'],\n",
    "                item_ids=batch['item_ids'],\n",
    "                attention_mask=batch['attention_mask'],\n",
    "                target_items=batch['target_item_ids'],\n",
    "                is_autoregressive=is_autoregressive,\n",
    "                negative_items=batch.get('negative_items')\n",
    "            )\n",
    "            \n",
    "            reg_losses = model.compute_regularization_losses()\n",
    "            \n",
    "            loss = 0.0\n",
    "            loss_components = {}\n",
    "            \n",
    "            if 'collaborative_ce' in collab_losses:\n",
    "                loss += loss_weights['collaborative'] * collab_losses['collaborative_ce']\n",
    "                loss_components['collab_ce'] = collab_losses['collaborative_ce'].item()\n",
    "            \n",
    "            if 'bpr' in collab_losses:\n",
    "                loss += loss_weights.get('cf_bpr', 1.0) * collab_losses['bpr']\n",
    "                loss_components['bpr'] = collab_losses['bpr'].item()\n",
    "            \n",
    "            reg_weight = loss_weights.get('regularization', 0.0)\n",
    "            if reg_weight > 0:\n",
    "                loss += reg_weight * reg_losses['collab_regularization']\n",
    "                loss_components['regularization'] = reg_losses['collab_regularization'].item()\n",
    "            else:\n",
    "                loss_components['regularization'] = reg_losses['collab_regularization'].item()\n",
    "        \n",
    "        # Backward pass\n",
    "        if scaler is not None:\n",
    "            scaler.scale(loss).backward()\n",
    "            if max_grad_norm > 0:\n",
    "                scaler.unscale_(optimizer)\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            if max_grad_norm > 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "            optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if 'collab_ce' in loss_components:\n",
    "            component_sums['collab_ce'] += loss_components['collab_ce']\n",
    "            component_counts['collab_ce'] += 1\n",
    "        if 'bpr' in loss_components:\n",
    "            component_sums['bpr'] += loss_components['bpr']\n",
    "            component_counts['bpr'] += 1\n",
    "        if 'regularization' in loss_components:\n",
    "            component_sums['regularization'] += loss_components['regularization']\n",
    "            component_counts['regularization'] += 1\n",
    "        \n",
    "        global_step += 1\n",
    "        \n",
    "        if global_step % logging_steps == 0:\n",
    "            avg_loss = total_loss / (batch_idx + 1)\n",
    "            print(f\"\\n[Step {global_step}] Loss: {loss.item():.4f}, Avg: {avg_loss:.4f}\")\n",
    "            progress_bar.set_postfix({'loss': f'{avg_loss:.4f}', 'step': global_step})\n",
    "        \n",
    "        if global_step % save_steps == 0:\n",
    "            checkpoint_path = Path(CHECKPOINT_DIR) / f\"checkpoint-{global_step}\"\n",
    "            checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'global_step': global_step,\n",
    "                'best_metric': best_metric\n",
    "            }, checkpoint_path / 'pytorch_model.pt')\n",
    "            torch.save({\n",
    "                'collab_embeddings': model.collab_embeddings.state_dict(),\n",
    "            }, checkpoint_path / 'embeddings.pt')\n",
    "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
    "    \n",
    "    # Compute average loss components\n",
    "    avg_components = {}\n",
    "    for key in component_sums:\n",
    "        if component_counts[key] > 0:\n",
    "            avg_components[key] = component_sums[key] / component_counts[key]\n",
    "    \n",
    "    train_metrics = {\n",
    "        'loss': total_loss / len(train_loader),\n",
    "        **avg_components\n",
    "    }\n",
    "    \n",
    "    print(f\"\\nEpoch {epoch + 1} training metrics:\")\n",
    "    print(f\"  Total loss: {train_metrics.get('loss', 0):.4f}\")\n",
    "    if 'collab_ce' in train_metrics:\n",
    "        print(f\"  Collaborative CE: {train_metrics['collab_ce']:.4f}\")\n",
    "    if 'bpr' in train_metrics:\n",
    "        print(f\"  BPR loss: {train_metrics['bpr']:.4f}\")\n",
    "    \n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    all_scores = []\n",
    "    all_target_indices = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
    "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                    for k, v in batch.items()}\n",
    "            \n",
    "            pos_items = batch['target_item_ids']\n",
    "            neg_items = batch['negative_items']\n",
    "            \n",
    "            with autocast(device_type=device_type, enabled=use_amp, dtype=amp_dtype):\n",
    "                llm_output = model.forward_collaborative(\n",
    "                    user_ids=batch['user_ids'],\n",
    "                    item_ids=batch['item_ids'],\n",
    "                    attention_mask=batch['attention_mask']\n",
    "                )\n",
    "                \n",
    "                candidates = torch.cat([\n",
    "                    pos_items.unsqueeze(1),\n",
    "                    neg_items\n",
    "                ], dim=1)\n",
    "                \n",
    "                candidate_scores = model.collab_scoring_head(\n",
    "                    llm_output, \n",
    "                    candidate_items=candidates,\n",
    "                    use_fusion=True\n",
    "                )\n",
    "                \n",
    "                batch_target_idx = torch.zeros(\n",
    "                    candidate_scores.size(0),\n",
    "                    dtype=torch.long,\n",
    "                    device=candidate_scores.device\n",
    "                )\n",
    "                \n",
    "                all_scores.append(candidate_scores.cpu())\n",
    "                all_target_indices.append(batch_target_idx.cpu())\n",
    "    \n",
    "    if all_scores:\n",
    "        all_scores = torch.cat(all_scores, dim=0)\n",
    "        all_target_indices = torch.cat(all_target_indices, dim=0)\n",
    "        val_metrics = compute_sampled_metrics(all_scores, all_target_indices, k_list=[1, 5, 10, 20])\n",
    "        print_metrics(val_metrics, prefix=f\"Epoch {epoch + 1} Validation \")\n",
    "        \n",
    "        # Update best metric\n",
    "        if val_metrics['hit@10'] > best_metric:\n",
    "            best_metric = val_metrics['hit@10']\n",
    "            best_checkpoint_path = Path(CHECKPOINT_DIR) / 'best_model'\n",
    "            best_checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
    "            torch.save({\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'global_step': global_step,\n",
    "                'best_metric': best_metric\n",
    "            }, best_checkpoint_path / 'pytorch_model.pt')\n",
    "            torch.save({\n",
    "                'collab_embeddings': model.collab_embeddings.state_dict(),\n",
    "            }, best_checkpoint_path / 'embeddings.pt')\n",
    "            print(f\"  ✓ New best model saved! Hit@10: {val_metrics['hit@10']:.4f}\")\n",
    "        \n",
    "        # Save epoch metrics\n",
    "        record = {\n",
    "            \"epoch\": epoch + 1,\n",
    "            \"global_step\": float(global_step),\n",
    "        }\n",
    "        for key, value in train_metrics.items():\n",
    "            record[f\"train_{key}\"] = float(value)\n",
    "        for key, value in val_metrics.items():\n",
    "            record[f\"val_{key}\"] = float(value)\n",
    "        epoch_history.append(record)\n",
    "        \n",
    "        with open(Path(CHECKPOINT_DIR) / 'metrics.json', 'w') as f:\n",
    "            json.dump(epoch_history, f, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"Training complete!\")\n",
    "print(f\"Best Hit@10: {best_metric:.4f}\")\n",
    "print(\"=\" * 60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluation/Prediction\n",
    "\n",
    "Evaluate the trained model on test data. You can also load a previously saved checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# EVALUATION ON TEST DATA\n",
    "# ============================================================================\n",
    "\n",
    "# Option 1: Use the model from training (already loaded)\n",
    "# Option 2: Load from checkpoint (uncomment to use)\n",
    "# checkpoint_path = Path(CHECKPOINT_DIR) / 'best_model'\n",
    "# checkpoint = torch.load(checkpoint_path / 'pytorch_model.pt', map_location='cpu', weights_only=False)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "# print(f\"Loaded checkpoint from {checkpoint_path}\")\n",
    "\n",
    "model.eval()\n",
    "all_scores = []\n",
    "all_target_indices = []\n",
    "\n",
    "use_amp = mixed_precision in ['fp16', 'bf16']\n",
    "amp_dtype = torch.float16 if mixed_precision == 'fp16' else (\n",
    "    torch.bfloat16 if mixed_precision == 'bf16' else torch.float32\n",
    ")\n",
    "device_type = 'cuda' if 'cuda' in str(device) else 'cpu'\n",
    "\n",
    "print(\"Evaluating on test data...\")\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Test evaluation\"):\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                for k, v in batch.items()}\n",
    "        \n",
    "        pos_items = batch['target_item_ids']\n",
    "        neg_items = batch['negative_items']\n",
    "        \n",
    "        with autocast(device_type=device_type, enabled=use_amp, dtype=amp_dtype):\n",
    "            llm_output = model.forward_collaborative(\n",
    "                user_ids=batch['user_ids'],\n",
    "                item_ids=batch['item_ids'],\n",
    "                attention_mask=batch['attention_mask']\n",
    "            )\n",
    "            \n",
    "            candidates = torch.cat([\n",
    "                pos_items.unsqueeze(1),\n",
    "                neg_items\n",
    "            ], dim=1)\n",
    "            \n",
    "            candidate_scores = model.collab_scoring_head(\n",
    "                llm_output, \n",
    "                candidate_items=candidates,\n",
    "                use_fusion=True\n",
    "            )\n",
    "            \n",
    "            batch_target_idx = torch.zeros(\n",
    "                candidate_scores.size(0),\n",
    "                dtype=torch.long,\n",
    "                device=candidate_scores.device\n",
    "            )\n",
    "            \n",
    "            all_scores.append(candidate_scores.cpu())\n",
    "            all_target_indices.append(batch_target_idx.cpu())\n",
    "\n",
    "if all_scores:\n",
    "    all_scores = torch.cat(all_scores, dim=0)\n",
    "    all_target_indices = torch.cat(all_target_indices, dim=0)\n",
    "    test_metrics = compute_sampled_metrics(all_scores, all_target_indices, k_list=[1, 5, 10, 20])\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"Test Results:\")\n",
    "    print(\"=\" * 60)\n",
    "    print_metrics(test_metrics, prefix=\"Test \")\n",
    "    \n",
    "    # Save test metrics\n",
    "    with open(Path(CHECKPOINT_DIR) / 'test_metrics.json', 'w') as f:\n",
    "        json.dump(test_metrics, f, indent=2)\n",
    "    print(f\"\\nTest metrics saved to {Path(CHECKPOINT_DIR) / 'test_metrics.json'}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Load and Predict from Saved Checkpoint\n",
    "\n",
    "If you want to load a previously saved model and make predictions, use this cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from /space/mcdonald-syn01/1/projects/jsawant/llm_recommender/checkpoints/stage_a_100_v10/best_model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Precomputing negative samples: 0it [00:00, ?it/s]\n",
      "Precomputing negative samples: 100%|██████████| 100000/100000 [06:56<00:00, 240.00it/s]\n",
      "Evaluating: 100%|██████████| 3125/3125 [00:36<00:00, 84.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test Metrics:\n",
      "--------------------------------------------------\n",
      "  hit@1: 0.2846\n",
      "  hit@10: 0.5577\n",
      "  hit@20: 0.6436\n",
      "  hit@5: 0.4781\n",
      "  ndcg@1: 0.2846\n",
      "  ndcg@10: 0.4127\n",
      "  ndcg@20: 0.4344\n",
      "  ndcg@5: 0.3870\n",
      "--------------------------------------------------\n",
      "This cell is for loading checkpoints. Uncomment and modify the code above to use it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# LOAD CHECKPOINT AND PREDICT\n",
    "# ============================================================================\n",
    "\n",
    "# Uncomment and modify the path to load a specific checkpoint\n",
    "CHECKPOINT_TO_LOAD = \"/space/mcdonald-syn01/1/projects/jsawant/llm_recommender/checkpoints/stage_a_100_v10/best_model\"\n",
    "\n",
    "# Load data\n",
    "with open(Path(DATA_OUTPUT_DIR) / 'dataset_info.pkl', 'rb') as f:\n",
    "    dataset_info = pickle.load(f)\n",
    "with open(Path(DATA_OUTPUT_DIR) / 'test_data.pkl', 'rb') as f:\n",
    "    test_data = pickle.load(f)\n",
    "with open(Path(DATA_OUTPUT_DIR) / 'item_metadata.pkl', 'rb') as f:\n",
    "    item_metadata = pickle.load(f)\n",
    "\n",
    "num_users = dataset_info['num_users']\n",
    "num_items = dataset_info['num_items']\n",
    "\n",
    "# Load config from checkpoint or use CONFIG\n",
    "try:\n",
    "    with open(Path(CHECKPOINT_TO_LOAD).parent / 'config.json', 'r') as f:\n",
    "        loaded_config = json.load(f)\n",
    "    CONFIG = loaded_config\n",
    "except:\n",
    "    print(\"Using current CONFIG\")\n",
    "\n",
    "# Create model\n",
    "model = StageAModel(\n",
    "    base_llm_name=CONFIG['model']['base_llm'],\n",
    "    num_users=num_users,\n",
    "    num_items=num_items,\n",
    "    embedding_dim=CONFIG['model']['embedding_dim'],\n",
    "    lambda_c=CONFIG['embeddings']['lambda_c'],\n",
    "    freeze_llm=CONFIG['model']['freeze_llm_stage_a'],\n",
    "    use_bpr_loss=CONFIG['stage_a']['collaborative'].get('use_bpr_loss', True),\n",
    "    random_init_llm=CONFIG['model'].get('random_init_stage_a_llm', False)\n",
    ")\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(\n",
    "    Path(CHECKPOINT_TO_LOAD) / 'pytorch_model.pt',\n",
    "    map_location='cpu',\n",
    "    weights_only=False\n",
    ")\n",
    "model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "\n",
    "print(f\"Model loaded from {CHECKPOINT_TO_LOAD}\")\n",
    "\n",
    "# Create test data loader\n",
    "data_module = RecDataModule(\n",
    "    train_data={},\n",
    "    val_data={},\n",
    "    test_data=test_data,\n",
    "    item_metadata=item_metadata,\n",
    "    num_items=num_items,\n",
    "    tokenizer=None,\n",
    "    batch_size=32,\n",
    "    num_workers=4,\n",
    "    negative_samples=100,\n",
    "    max_seq_length=CONFIG['data']['max_sequence_length'],\n",
    "    max_text_length=None,\n",
    "    eval_seed=CONFIG['data']['seed']\n",
    ")\n",
    "test_loader = data_module.test_dataloader()\n",
    "\n",
    "# Evaluate\n",
    "all_scores = []\n",
    "all_target_indices = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
    "                for k, v in batch.items()}\n",
    "        \n",
    "        pos_items = batch['target_item_ids']\n",
    "        neg_items = batch['negative_items']\n",
    "        \n",
    "        with autocast(device_type=device_type, enabled=use_amp, dtype=amp_dtype):\n",
    "            llm_output = model.forward_collaborative(\n",
    "                user_ids=batch['user_ids'],\n",
    "                item_ids=batch['item_ids'],\n",
    "                attention_mask=batch['attention_mask']\n",
    "            )\n",
    "            \n",
    "            candidates = torch.cat([\n",
    "                pos_items.unsqueeze(1),\n",
    "                neg_items\n",
    "            ], dim=1)\n",
    "            \n",
    "            candidate_scores = model.collab_scoring_head(\n",
    "                llm_output, \n",
    "                candidate_items=candidates,\n",
    "                use_fusion=True\n",
    "            )\n",
    "            \n",
    "            batch_target_idx = torch.zeros(\n",
    "                candidate_scores.size(0),\n",
    "                dtype=torch.long,\n",
    "                device=candidate_scores.device\n",
    "            )\n",
    "            \n",
    "            all_scores.append(candidate_scores.cpu())\n",
    "            all_target_indices.append(batch_target_idx.cpu())\n",
    "\n",
    "if all_scores:\n",
    "    all_scores = torch.cat(all_scores, dim=0)\n",
    "    all_target_indices = torch.cat(all_target_indices, dim=0)\n",
    "    test_metrics = compute_sampled_metrics(all_scores, all_target_indices, k_list=[1, 5, 10, 20])\n",
    "    print_metrics(test_metrics, prefix=\"Test \")\n",
    "\n",
    "print(\"This cell is for loading checkpoints. Uncomment and modify the code above to use it.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse258_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

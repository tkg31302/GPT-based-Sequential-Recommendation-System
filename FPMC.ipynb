{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60e2a17c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "845f1492",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/train_data.pkl')\n",
    "val_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/val_data.pkl')\n",
    "test_data = pd.read_pickle('/data/sukhanna/cse258/processed_100/test_data.pkl')\n",
    "\n",
    "id2item = pd.read_pickle('/data/sukhanna/cse258/processed_100/id2item.pkl')\n",
    "item2id = pd.read_pickle('/data/sukhanna/cse258/processed_100/item2id.pkl')\n",
    "\n",
    "id2user = pd.read_pickle('/data/sukhanna/cse258/processed_100/id2user.pkl')\n",
    "user2id = pd.read_pickle('/data/sukhanna/cse258/processed_100/user2id.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9a771b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "\n",
    "class FPMCDataset(Dataset):\n",
    "    def __init__(self, train_data, val_data, test_data, num_items, n_neg=1):\n",
    "        self.num_items = num_items\n",
    "        self.n_neg = n_neg\n",
    "        \n",
    "        # 1. Prepare Storage for Transitions\n",
    "        # Format: (user_idx, last_item_idx, current_item_idx)\n",
    "        self.samples = []\n",
    "        \n",
    "        # 2. Prepare Exclusion Sets (Same as BPR)\n",
    "        self.exclusion_rules = {}\n",
    "\n",
    "        for u_idx in range(len(train_data)):\n",
    "            # Extract sequence\n",
    "            seq = [x['item_id'] for x in train_data[u_idx]['sequence']]\n",
    "            val_target = val_data[u_idx]['target']['item_id']\n",
    "            test_target = test_data[u_idx]['target']['item_id']\n",
    "            \n",
    "            # Build Exclusion Set (Train + Val + Test)\n",
    "            full_history = set(seq)\n",
    "            full_history.add(val_target)\n",
    "            full_history.add(test_target)\n",
    "            self.exclusion_rules[u_idx] = full_history\n",
    "            \n",
    "            # 3. Generate Sequential Transitions\n",
    "            # We need at least 2 items to form a transition (A -> B)\n",
    "            if len(seq) > 1:\n",
    "                # Iterate from 0 to Length-2\n",
    "                for i in range(len(seq) - 1):\n",
    "                    last_item = seq[i]\n",
    "                    curr_item = seq[i+1]\n",
    "                    \n",
    "                    self.samples.append((u_idx, last_item, curr_item))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        u_id, last_item_raw, pos_item_raw = self.samples[idx]\n",
    "        \n",
    "        # Negative Sampling\n",
    "        # We sample 'n_neg' items that are NOT in the user's full history\n",
    "        neg_samples = []\n",
    "        for _ in range(self.n_neg):\n",
    "            while True:\n",
    "                neg_id_raw = random.randint(1, self.num_items)\n",
    "                if neg_id_raw not in self.exclusion_rules[u_id]:\n",
    "                    neg_samples.append(neg_id_raw - 1)\n",
    "                    break\n",
    "        \n",
    "        # Return 0-indexed tensors\n",
    "        # Note: We subtract 1 because input IDs are 1-based\n",
    "        return (\n",
    "            torch.tensor(u_id, dtype=torch.long),\n",
    "            torch.tensor(last_item_raw - 1, dtype=torch.long),\n",
    "            torch.tensor(pos_item_raw - 1, dtype=torch.long),\n",
    "            torch.tensor(neg_samples, dtype=torch.long) # Shape: [n_neg]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9f77e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class FPMC(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=64):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            num_users: Total unique users.\n",
    "            num_items: Total unique items.\n",
    "            embedding_dim: Latent vector size.\n",
    "        \"\"\"\n",
    "        super(FPMC, self).__init__()\n",
    "        \n",
    "        # 1. User Embedding (Long-term preference)\n",
    "        # Represents 'u' in the formula\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        \n",
    "        # 2. Item Context Embedding (The 'Previous' Item)\n",
    "        # Represents 'c_l' (Source/Context role)\n",
    "        self.item_context_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # 3. Item Target Embedding (The 'Next' Item)\n",
    "        # Represents 'v_i' (Destination/Target role)\n",
    "        # Used for both the MF part and the MC part\n",
    "        self.item_target_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        \n",
    "        # Initialization\n",
    "        # FPMC is sensitive to initialization. We use small random values.\n",
    "        nn.init.normal_(self.user_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_context_embedding.weight, std=0.01)\n",
    "        nn.init.normal_(self.item_target_embedding.weight, std=0.01)\n",
    "\n",
    "    def forward(self, user_indices, last_item_indices, curr_item_indices):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            user_indices: [Batch_Size]\n",
    "            last_item_indices: [Batch_Size]\n",
    "            curr_item_indices: [Batch_Size]\n",
    "            \n",
    "        Returns:\n",
    "            scores: [Batch_Size]\n",
    "        \"\"\"\n",
    "        # 1. Lookup Embeddings\n",
    "        # Shapes: [Batch, Dim]\n",
    "        u = self.user_embedding(user_indices)\n",
    "        c = self.item_context_embedding(last_item_indices)\n",
    "        v = self.item_target_embedding(curr_item_indices)\n",
    "        \n",
    "        # 2. Compute Score\n",
    "        # Formula: (User + Context) dot Target\n",
    "        # This efficiently calculates (User dot Target) + (Context dot Target)\n",
    "        interaction_vector = u + c\n",
    "        scores = (interaction_vector * v).sum(dim=1)\n",
    "        \n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eea2714",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "class FPMCEvaluator:\n",
    "    def __init__(self, eval_data, exclusion_rules, num_items, k_list=[1, 10]):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            eval_data: List/Dict containing 'sequence' (for context) and 'target' (ground truth).\n",
    "            exclusion_rules: Dict {user_idx: set(all_positive_items)}.\n",
    "            num_items: Catalog size.\n",
    "            k_list: Metrics to calculate.\n",
    "        \"\"\"\n",
    "        self.eval_data = eval_data\n",
    "        self.exclusion_rules = exclusion_rules\n",
    "        self.num_items = num_items\n",
    "        self.k_list = k_list\n",
    "    \n",
    "    def evaluate(self, model, device='cpu'):\n",
    "        model.eval()\n",
    "        \n",
    "        hr_results = {k: [] for k in self.k_list}\n",
    "        ndcg_results = {k: [] for k in self.k_list}\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Iterate using .items() if it's a dict, or enumerate if list\n",
    "            # Handling both based on your previous data snippets\n",
    "            iterator = self.eval_data.items() if isinstance(self.eval_data, dict) else enumerate(self.eval_data)\n",
    "            \n",
    "            for u_idx, entry in iterator:\n",
    "                \n",
    "                # 1. Get Context (The Last Item user interacted with)\n",
    "                # This is the \"Markov\" state\n",
    "                seq = entry['sequence']\n",
    "                if len(seq) == 0:\n",
    "                    continue # Skip empty users\n",
    "                \n",
    "                last_item_raw = seq[-1]['item_id']\n",
    "                last_item = last_item_raw - 1\n",
    "                \n",
    "                # 2. Get Ground Truth (Target)\n",
    "                gt_item_raw = entry['target']['item_id']\n",
    "                gt_item = gt_item_raw - 1\n",
    "                \n",
    "                # 3. Sample 100 Negatives\n",
    "                negatives = []\n",
    "                u_exclusion = self.exclusion_rules[u_idx]\n",
    "                \n",
    "                while len(negatives) < 100:\n",
    "                    neg_candidate = random.randint(1, self.num_items)\n",
    "                    # Exclude history AND target\n",
    "                    if (neg_candidate not in u_exclusion) and (neg_candidate - 1 != gt_item):\n",
    "                        negatives.append(neg_candidate - 1)\n",
    "                \n",
    "                # 4. Prepare Batch (101 Items)\n",
    "                candidate_items = [gt_item] + negatives\n",
    "                \n",
    "                # Create Tensors\n",
    "                # User: Repeated 101 times\n",
    "                user_tensor = torch.tensor([u_idx] * 101, dtype=torch.long).to(device)\n",
    "                \n",
    "                # Last Item: Repeated 101 times (Context is constant for this prediction)\n",
    "                last_item_tensor = torch.tensor([last_item] * 101, dtype=torch.long).to(device)\n",
    "                \n",
    "                # Current Items: The 101 candidates\n",
    "                curr_item_tensor = torch.tensor(candidate_items, dtype=torch.long).to(device)\n",
    "                \n",
    "                # 5. Score\n",
    "                # Model takes (u, last, curr)\n",
    "                scores = model(user_tensor, last_item_tensor, curr_item_tensor)\n",
    "                scores = scores.cpu().numpy()\n",
    "                \n",
    "                # 6. Rank\n",
    "                ranked_indices = np.argsort(-scores) # Descending\n",
    "                gt_rank = np.where(ranked_indices == 0)[0][0]\n",
    "                \n",
    "                # 7. Metrics\n",
    "                for k in self.k_list:\n",
    "                    if gt_rank < k:\n",
    "                        hr_results[k].append(1)\n",
    "                        ndcg_results[k].append(1 / math.log2(gt_rank + 2))\n",
    "                    else:\n",
    "                        hr_results[k].append(0)\n",
    "                        ndcg_results[k].append(0)\n",
    "\n",
    "        avg_hr = {k: np.mean(v) for k, v in hr_results.items()}\n",
    "        avg_ndcg = {k: np.mean(v) for k, v in ndcg_results.items()}\n",
    "        \n",
    "        return avg_hr, avg_ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eec81375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device selected: cuda\n",
      "Starting FPMC Training...\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.6503\n",
      "  Validation HR@1:   0.2125 | HR@10:   0.4518\n",
      "  Validation NDCG@1: 0.2125 | NDCG@10: 0.3246\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.4144\n",
      "  Validation HR@1:   0.2432 | HR@10:   0.5234\n",
      "  Validation NDCG@1: 0.2432 | NDCG@10: 0.3734\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 03 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.2258\n",
      "  Validation HR@1:   0.2582 | HR@10:   0.5459\n",
      "  Validation NDCG@1: 0.2582 | NDCG@10: 0.3918\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 04 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.1197\n",
      "  Validation HR@1:   0.2660 | HR@10:   0.5562\n",
      "  Validation NDCG@1: 0.2660 | NDCG@10: 0.4013\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 05 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0659\n",
      "  Validation HR@1:   0.2707 | HR@10:   0.5634\n",
      "  Validation NDCG@1: 0.2707 | NDCG@10: 0.4078\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 06 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0403\n",
      "  Validation HR@1:   0.2771 | HR@10:   0.5673\n",
      "  Validation NDCG@1: 0.2771 | NDCG@10: 0.4131\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 07 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0263\n",
      "  Validation HR@1:   0.2808 | HR@10:   0.5690\n",
      "  Validation NDCG@1: 0.2808 | NDCG@10: 0.4164\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 08 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0195\n",
      "  Validation HR@1:   0.2824 | HR@10:   0.5713\n",
      "  Validation NDCG@1: 0.2824 | NDCG@10: 0.4183\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 09 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0148\n",
      "  Validation HR@1:   0.2865 | HR@10:   0.5705\n",
      "  Validation NDCG@1: 0.2865 | NDCG@10: 0.4203\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 Completed\n",
      "------------------------------\n",
      "  Training Loss: 0.0123\n",
      "  Validation HR@1:   0.2889 | HR@10:   0.5724\n",
      "  Validation NDCG@1: 0.2889 | NDCG@10: 0.4221\n",
      "============================================================\n",
      "\n",
      "FPMC Training Complete. Model saved to: /data/sukhanna/cse258/fpmc_model.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- Hyperparameters ---\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.001\n",
    "NUM_EPOCHS = 10\n",
    "EMBEDDING_DIM = 64\n",
    "N_NEG = 1  # Start with 1 as discussed\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\"Device selected: {DEVICE}\")\n",
    "\n",
    "# --- 1. Setup Data & Model ---\n",
    "# Ensure item2id and data dicts are available in your scope\n",
    "num_items_total = len(item2id)\n",
    "\n",
    "# Dataset\n",
    "train_dataset_fpmc = FPMCDataset(\n",
    "    train_data, val_data, test_data, \n",
    "    num_items=num_items_total, \n",
    "    n_neg=N_NEG\n",
    ")\n",
    "\n",
    "# Evaluator\n",
    "# Uses the same exclusion rules logic\n",
    "val_evaluator_fpmc = FPMCEvaluator(\n",
    "    val_data, \n",
    "    train_dataset_fpmc.exclusion_rules, \n",
    "    num_items=num_items_total, \n",
    "    k_list=[1, 10]\n",
    ")\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset_fpmc, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Model\n",
    "model = FPMC(num_users=len(train_data), num_items=num_items_total, embedding_dim=EMBEDDING_DIM)\n",
    "model.to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# --- 2. Training Loop ---\n",
    "print(\"Starting FPMC Training...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # Progress Bar\n",
    "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch}/{NUM_EPOCHS}\", leave=False)\n",
    "    \n",
    "    for u, last_item, pos_item, neg_items in progress_bar:\n",
    "        # Move to Device\n",
    "        u = u.to(DEVICE)                  # [Batch]\n",
    "        last_item = last_item.to(DEVICE)  # [Batch]\n",
    "        pos_item = pos_item.to(DEVICE)    # [Batch]\n",
    "        neg_items = neg_items.to(DEVICE)  # [Batch, N_Neg]\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # --- A. Positive Scores ---\n",
    "        # Shape: [Batch]\n",
    "        pos_scores = model(u, last_item, pos_item)\n",
    "        \n",
    "        # --- B. Negative Scores (Handling N_Neg) ---\n",
    "        # We must flatten the batch to process (Batch * N_Neg) items at once\n",
    "        \n",
    "        # 1. Flatten Negatives: [Batch, N_Neg] -> [Batch * N_Neg]\n",
    "        neg_items_flat = neg_items.view(-1)\n",
    "        \n",
    "        # 2. Repeat User and Last Item to match the flattened negatives\n",
    "        # [Batch] -> [Batch * N_Neg]\n",
    "        u_flat = u.repeat_interleave(N_NEG)\n",
    "        last_item_flat = last_item.repeat_interleave(N_NEG)\n",
    "        \n",
    "        # 3. Compute Scores\n",
    "        neg_scores_flat = model(u_flat, last_item_flat, neg_items_flat)\n",
    "        \n",
    "        # 4. Reshape back to [Batch, N_Neg]\n",
    "        neg_scores = neg_scores_flat.view(-1, N_NEG)\n",
    "        \n",
    "        # --- C. BPR Loss ---\n",
    "        # pos_scores: [Batch] -> [Batch, 1] for broadcasting\n",
    "        # neg_scores: [Batch, N_Neg]\n",
    "        # Loss: -log_sigmoid(pos - neg)\n",
    "        loss = -torch.mean(torch.nn.functional.logsigmoid(pos_scores.unsqueeze(1) - neg_scores))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        progress_bar.set_postfix({'loss': loss.item()})\n",
    "        \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    \n",
    "    # --- 3. Evaluation ---\n",
    "    hr, ndcg = val_evaluator_fpmc.evaluate(model, device=DEVICE)\n",
    "    \n",
    "    # --- 4. Logging ---\n",
    "    print(f\"Epoch {epoch:02d} Completed\")\n",
    "    print(\"-\" * 30)\n",
    "    print(f\"  Training Loss: {avg_loss:.4f}\")\n",
    "    print(f\"  Validation HR@1:   {hr[1]:.4f} | HR@10:   {hr[10]:.4f}\")\n",
    "    print(f\"  Validation NDCG@1: {ndcg[1]:.4f} | NDCG@10: {ndcg[10]:.4f}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "# --- 5. Save Model ---\n",
    "save_path = \"/data/sukhanna/cse258/fpmc_model.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "print(f\"\\nFPMC Training Complete. Model saved to: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "61acda9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running FPMC Test Evaluation...\n",
      "------------------------------\n",
      "Test HR@1:   0.2674 | HR@10:   0.5477\n",
      "Test NDCG@1: 0.2674 | NDCG@10: 0.3986\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "# 1. Instantiate the Test Evaluator\n",
    "# We reuse the exclusion_rules from the training dataset.\n",
    "# This ensures that for every user, we exclude (Train History + Val Target + Test Target)\n",
    "# from the pool of 100 negative samples.\n",
    "test_evaluator_fpmc = FPMCEvaluator(\n",
    "    eval_data=test_data, \n",
    "    exclusion_rules=train_dataset_fpmc.exclusion_rules, \n",
    "    num_items=len(item2id), \n",
    "    k_list=[1, 10]\n",
    ")\n",
    "\n",
    "# 2. Run Evaluation\n",
    "# Ensure the model is in eval mode (handled inside the class, but good practice)\n",
    "print(\"Running FPMC Test Evaluation...\")\n",
    "test_hr, test_ndcg = test_evaluator_fpmc.evaluate(model, device=DEVICE)\n",
    "\n",
    "# 3. Report Results\n",
    "print(\"-\" * 30)\n",
    "print(f\"Test HR@1:   {test_hr[1]:.4f} | HR@10:   {test_hr[10]:.4f}\")\n",
    "print(f\"Test NDCG@1: {test_ndcg[1]:.4f} | NDCG@10: {test_ndcg[10]:.4f}\")\n",
    "print(\"-\" * 30)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse258_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

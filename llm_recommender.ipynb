{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LLM-based Recommender System - Complete Notebook\n",
        "\n",
        "This notebook contains all the code needed to train and predict with the LLM-based recommender system.\n",
        "\n",
        "## Overview\n",
        "- **Stage A**: Pretrains user/item embeddings using collaborative filtering losses with a full-finetuned LLM backbone\n",
        "- Uses embeddings as soft tokens injected into the LLM\n",
        "- Efficient dot-product scoring for next-item prediction\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/jsawant/.conda/envs/jay2/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda:0\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# IMPORTS AND SETUP\n",
        "# ============================================================================\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import json\n",
        "import pickle\n",
        "import gzip\n",
        "import random\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "from collections import defaultdict\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.amp import autocast, GradScaler\n",
        "from torch.optim import AdamW\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "from transformers import AutoModel, AutoConfig, AutoTokenizer\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set your configuration here. You can modify these values to customize training and prediction.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Configuration loaded!\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# ============================================================================\n",
        "# CONFIGURATION\n",
        "# ============================================================================\n",
        "\n",
        "# Data paths\n",
        "USER_SEQUENCES_PATH = \"/space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/dataset/filtered_user_sequences.jsonl.gz\"\n",
        "ITEM_METADATA_PATH = \"/space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/dataset/filtered_Kindle_Store.jsonl.gz\"\n",
        "DATA_OUTPUT_DIR = \"./data/processed_notebook\"\n",
        "\n",
        "# Model configuration\n",
        "CONFIG = {\n",
        "  \"data\": {\n",
        "        'user_sequences_path': USER_SEQUENCES_PATH,\n",
        "        'item_metadata_path': ITEM_METADATA_PATH,\n",
        "    \"train_ratio\": 0.8,\n",
        "    \"val_ratio\": 0.1,\n",
        "    \"min_sequence_length\": 3,\n",
        "    \"max_sequence_length\": 50,\n",
        "    \"seed\": 42,\n",
        "    \"max_train_sequences\": 100000\n",
        "  },\n",
        "  \"model\": {\n",
        "    \"base_llm\": \"gpt2\",\n",
        "    \"embedding_dim\": 128,\n",
        "    \"freeze_llm_stage_a\": False,\n",
        "    \"freeze_llm_stage_b\": False,\n",
        "    \"random_init_stage_a_llm\": False,\n",
        "    \"use_lora\": False,\n",
        "    \"lora_r\": 16,\n",
        "    \"lora_alpha\": 32,\n",
        "    \"lora_dropout\": 0.05,\n",
        "    \"use_embedding_fusion\": False,\n",
        "    \"fusion_weight\": 0.7\n",
        "  },\n",
        "  \"embeddings\": {\n",
        "    \"lambda_c\": 0.001,\n",
        "    \"lambda_t\": 0.001,\n",
        "    \"temperature\": 0.07\n",
        "  },\n",
        "  \"stage_a\": {\n",
        "    \"epochs\": 10,\n",
        "    \"batch_size\": 64,\n",
        "    \"learning_rate\": 0.0005,\n",
        "    \"weight_decay\": 0.001,\n",
        "    \"max_grad_norm\": 1.0,\n",
        "    \"loss_weights\": {\n",
        "      \"collaborative\": 1.0,\n",
        "      \"content\": 0.0,\n",
        "      \"contrastive\": 0.0,\n",
        "      \"cf_bpr\": 0.2,\n",
        "      \"regularization\": 0.0\n",
        "    },\n",
        "    \"collaborative\": {\n",
        "      \"negative_samples\": 30,\n",
        "      \"use_bpr_loss\": True\n",
        "    },\n",
        "    \"content\": {\n",
        "      \"max_text_length\": 128\n",
        "    }\n",
        "  },\n",
        "  \"training\": {\n",
        "    \"device\": str(device),\n",
        "    \"mixed_precision\": \"no\",\n",
        "    \"logging_steps\": 500,\n",
        "    \"eval_steps\": 10000,\n",
        "    \"save_steps\": 10000\n",
        "  }\n",
        "}\n",
        "\n",
        "# Output directories\n",
        "CHECKPOINT_DIR = \"./checkpoints/notebook_training\"\n",
        "Path(CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "Path(DATA_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "print(\"Configuration loaded!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility Functions and Classes\n",
        "\n",
        "All the core classes and functions from the codebase.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DataPreprocessor class defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# DATA PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "class DataPreprocessor:\n",
        "    \"\"\"Preprocesses user sequences and item metadata for LLM-based recommendation.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        user_sequences_path: str,\n",
        "        item_metadata_path: Optional[str] = None,\n",
        "        min_sequence_length: int = 5,\n",
        "        max_sequence_length: int = 50,\n",
        "        train_ratio: float = 0.8,\n",
        "        val_ratio: float = 0.1,\n",
        "        seed: int = 42,\n",
        "        max_train_sequences: Optional[int] = None\n",
        "    ):\n",
        "        self.user_sequences_path = user_sequences_path\n",
        "        self.item_metadata_path = item_metadata_path\n",
        "        self.min_sequence_length = min_sequence_length\n",
        "        self.max_sequence_length = max_sequence_length\n",
        "        self.train_ratio = train_ratio\n",
        "        self.val_ratio = val_ratio\n",
        "        self.test_ratio = 1.0 - train_ratio - val_ratio\n",
        "        self.seed = seed\n",
        "        self.max_train_sequences = max_train_sequences\n",
        "        \n",
        "        np.random.seed(seed)\n",
        "        \n",
        "        # Mappings\n",
        "        self.user2id: Dict[str, int] = {}\n",
        "        self.item2id: Dict[str, int] = {}\n",
        "        self.id2user: Dict[int, str] = {}\n",
        "        self.id2item: Dict[int, str] = {}\n",
        "        \n",
        "        # Data\n",
        "        self.user_sequences: Dict[int, List[Dict]] = {}\n",
        "        self.item_metadata: Dict[int, Dict] = {}\n",
        "        \n",
        "    def load_and_preprocess(self) -> Tuple[Dict, Dict, Dict]:\n",
        "        \"\"\"Load and preprocess all data.\"\"\"\n",
        "        print(\"Loading user sequences...\")\n",
        "        self._load_user_sequences()\n",
        "        \n",
        "        if self.item_metadata_path:\n",
        "            print(\"Loading item metadata...\")\n",
        "            self._load_item_metadata()\n",
        "        \n",
        "        # Truncate user sequences first if requested\n",
        "        if self.max_train_sequences is not None:\n",
        "            print(f\"\\nTruncating to {self.max_train_sequences} sequences...\")\n",
        "            self._truncate_user_sequences(self.max_train_sequences)\n",
        "        \n",
        "        print(\"Creating train/val/test splits...\")\n",
        "        train_data, val_data, test_data = self._create_splits()\n",
        "        \n",
        "        # Remap item IDs to be compact (1-indexed, 0 for padding)\n",
        "        if self.max_train_sequences is not None:\n",
        "            print(\"\\nRemapping item IDs to compact range...\")\n",
        "            train_data, val_data, test_data = self._remap_item_ids(\n",
        "                train_data, val_data, test_data\n",
        "            )\n",
        "        \n",
        "        stats = self._compute_statistics()\n",
        "        print(f\"\\nDataset Statistics:\")\n",
        "        print(f\"  Users: {stats['num_users']}\")\n",
        "        print(f\"  Items: {stats['num_items']}\")\n",
        "        print(f\"  Interactions: {stats['num_interactions']}\")\n",
        "        print(f\"  Avg sequence length: {stats['avg_seq_length']:.2f}\")\n",
        "        print(f\"  Train sequences: {len(train_data)}\")\n",
        "        print(f\"  Val sequences: {len(val_data)}\")\n",
        "        print(f\"  Test sequences: {len(test_data)}\")\n",
        "        \n",
        "        return train_data, val_data, test_data\n",
        "    \n",
        "    def _load_user_sequences(self):\n",
        "        \"\"\"Load user interaction sequences from JSONL file.\"\"\"\n",
        "        user_idx = 0\n",
        "        item_idx = 1  # Start from 1, reserve 0 for padding\n",
        "        \n",
        "        with gzip.open(self.user_sequences_path, 'rt', encoding='utf-8') as f:\n",
        "            for line in tqdm(f, desc=\"Loading sequences\"):\n",
        "                data = json.loads(line.strip())\n",
        "                user_id_str = data['user_id']\n",
        "                sequence = data['sequence']\n",
        "                \n",
        "                # Filter by sequence length\n",
        "                if len(sequence) < self.min_sequence_length:\n",
        "                    continue\n",
        "                \n",
        "                # Map user ID\n",
        "                if user_id_str not in self.user2id:\n",
        "                    self.user2id[user_id_str] = user_idx\n",
        "                    self.id2user[user_idx] = user_id_str\n",
        "                    user_idx += 1\n",
        "                \n",
        "                user_id = self.user2id[user_id_str]\n",
        "                \n",
        "                # Map item IDs and process sequence\n",
        "                processed_sequence = []\n",
        "                for interaction in sequence:\n",
        "                    item_id_str = interaction['asin']\n",
        "                    \n",
        "                    if item_id_str not in self.item2id:\n",
        "                        self.item2id[item_id_str] = item_idx\n",
        "                        self.id2item[item_idx] = item_id_str\n",
        "                        item_idx += 1\n",
        "                    \n",
        "                    item_id = self.item2id[item_id_str]\n",
        "                    \n",
        "                    processed_sequence.append({\n",
        "                        'item_id': item_id,\n",
        "                        'timestamp': interaction['ts'],\n",
        "                        'rating': interaction.get('rating', 0.0)\n",
        "                    })\n",
        "                \n",
        "                # Sort by timestamp\n",
        "                processed_sequence = sorted(processed_sequence, key=lambda x: x['timestamp'])\n",
        "                \n",
        "                # Truncate if too long\n",
        "                if len(processed_sequence) > self.max_sequence_length:\n",
        "                    processed_sequence = processed_sequence[-self.max_sequence_length:]\n",
        "                \n",
        "                self.user_sequences[user_id] = processed_sequence\n",
        "    \n",
        "    def _load_item_metadata(self):\n",
        "        \"\"\"Load item metadata (titles, descriptions, etc.).\"\"\"\n",
        "        with gzip.open(self.item_metadata_path, 'rt', encoding='utf-8') as f:\n",
        "            for line in tqdm(f, desc=\"Loading metadata\"):\n",
        "                data = json.loads(line.strip())\n",
        "                item_id_str = data.get('parent_asin') or data.get('asin')\n",
        "                \n",
        "                if item_id_str in self.item2id:\n",
        "                    item_id = self.item2id[item_id_str]\n",
        "                    \n",
        "                    # Extract relevant metadata\n",
        "                    self.item_metadata[item_id] = {\n",
        "                        'title': data.get('title', ''),\n",
        "                        'description': ' '.join(data.get('description', [])) if isinstance(data.get('description'), list) else data.get('description', ''),\n",
        "                        'categories': data.get('categories', []),\n",
        "                        'price': data.get('price', 0.0),\n",
        "                        'average_rating': data.get('average_rating', 0.0)\n",
        "                    }\n",
        "    \n",
        "    def _create_splits(self) -> Tuple[Dict, Dict, Dict]:\n",
        "        \"\"\"Create train/validation/test splits using leave-one-out strategy.\"\"\"\n",
        "        train_data = {}\n",
        "        val_data = {}\n",
        "        test_data = {}\n",
        "        \n",
        "        for user_id, sequence in self.user_sequences.items():\n",
        "            seq_len = len(sequence)\n",
        "            \n",
        "            if seq_len < 3:\n",
        "                continue\n",
        "            \n",
        "            # Leave-one-out split: last item for test, second-to-last for val\n",
        "            train_seq = sequence[:-2]  # All items up to T-2\n",
        "            val_item = sequence[-2]     # Item at T-1\n",
        "            test_item = sequence[-1]    # Item at T\n",
        "            \n",
        "            if len(train_seq) >= self.min_sequence_length - 1:\n",
        "                # Training: Full sequence for autoregressive training\n",
        "                train_data[user_id] = {\n",
        "                    'sequence': train_seq,\n",
        "                    'is_autoregressive': True\n",
        "                }\n",
        "                \n",
        "                # Validation: Predict single next item\n",
        "                val_data[user_id] = {\n",
        "                    'sequence': train_seq,\n",
        "                    'target': val_item,\n",
        "                    'is_autoregressive': False\n",
        "                }\n",
        "                \n",
        "                # Test: Predict single next item\n",
        "                test_data[user_id] = {\n",
        "                    'sequence': sequence[:-1],  # Include validation item\n",
        "                    'target': test_item,\n",
        "                    'is_autoregressive': False\n",
        "                }\n",
        "        \n",
        "        return train_data, val_data, test_data\n",
        "    \n",
        "    def _truncate_user_sequences(self, max_sequences: int):\n",
        "        \"\"\"Truncate user_sequences to max_sequences before creating splits.\"\"\"\n",
        "        user_ids = list(self.user_sequences.keys())\n",
        "        if len(user_ids) > max_sequences:\n",
        "            np.random.shuffle(user_ids)\n",
        "            user_ids = user_ids[:max_sequences]\n",
        "            self.user_sequences = {uid: self.user_sequences[uid] for uid in user_ids}\n",
        "            print(f\"  Truncated to {len(self.user_sequences)} user sequences\")\n",
        "            \n",
        "            # Update user mappings\n",
        "            kept_user_ids = set(user_ids)\n",
        "            new_user2id = {}\n",
        "            new_id2user = {}\n",
        "            new_user_idx = 0\n",
        "            \n",
        "            for old_user_id in sorted(kept_user_ids):\n",
        "                old_user_str = self.id2user[old_user_id]\n",
        "                new_user2id[old_user_str] = new_user_idx\n",
        "                new_id2user[new_user_idx] = old_user_str\n",
        "                new_user_idx += 1\n",
        "            \n",
        "            # Remap user IDs in sequences\n",
        "            remapped_sequences = {}\n",
        "            for old_user_id, sequence in self.user_sequences.items():\n",
        "                old_user_str = self.id2user[old_user_id]\n",
        "                new_user_id = new_user2id[old_user_str]\n",
        "                remapped_sequences[new_user_id] = sequence\n",
        "            \n",
        "            self.user_sequences = remapped_sequences\n",
        "            self.user2id = new_user2id\n",
        "            self.id2user = new_id2user\n",
        "    \n",
        "    def _remap_item_ids(\n",
        "        self,\n",
        "        train_data: Dict,\n",
        "        val_data: Dict,\n",
        "        test_data: Dict\n",
        "    ) -> Tuple[Dict, Dict, Dict]:\n",
        "        \"\"\"Remap item IDs to compact range (1-indexed, 0 reserved for padding).\"\"\"\n",
        "        # Collect all items that appear in final dataset\n",
        "        all_items = set()\n",
        "        \n",
        "        for user_data in train_data.values():\n",
        "            for item in user_data['sequence']:\n",
        "                all_items.add(item['item_id'])\n",
        "        \n",
        "        for user_data in val_data.values():\n",
        "            for item in user_data['sequence']:\n",
        "                all_items.add(item['item_id'])\n",
        "            all_items.add(user_data['target']['item_id'])\n",
        "        \n",
        "        for user_data in test_data.values():\n",
        "            for item in user_data['sequence']:\n",
        "                all_items.add(item['item_id'])\n",
        "            all_items.add(user_data['target']['item_id'])\n",
        "        \n",
        "        print(f\"  Found {len(all_items)} unique items in final dataset\")\n",
        "        \n",
        "        # Create mapping: old_item_id -> new_item_id\n",
        "        old_to_new_item = {}\n",
        "        new_item_idx = 1  # Start from 1, reserve 0 for padding\n",
        "        \n",
        "        sorted_items = sorted(all_items)\n",
        "        for old_item_id in sorted_items:\n",
        "            old_to_new_item[old_item_id] = new_item_idx\n",
        "            new_item_idx += 1\n",
        "        \n",
        "        # Update item2id and id2item mappings\n",
        "        new_item2id = {}\n",
        "        new_id2item = {}\n",
        "        for old_item_id, new_item_id in old_to_new_item.items():\n",
        "            old_item_str = self.id2item[old_item_id]\n",
        "            new_item2id[old_item_str] = new_item_id\n",
        "            new_id2item[new_item_id] = old_item_str\n",
        "        \n",
        "        self.item2id = new_item2id\n",
        "        self.id2item = new_id2item\n",
        "        \n",
        "        # Remap item IDs in all data\n",
        "        def remap_sequence(sequence):\n",
        "            return [{\n",
        "                **item,\n",
        "                'item_id': old_to_new_item[item['item_id']]\n",
        "            } for item in sequence]\n",
        "        \n",
        "        def remap_target(target):\n",
        "            return {\n",
        "                **target,\n",
        "                'item_id': old_to_new_item[target['item_id']]\n",
        "            }\n",
        "        \n",
        "        remapped_train_data = {}\n",
        "        for user_id, user_data in train_data.items():\n",
        "            remapped_train_data[user_id] = {\n",
        "                'sequence': remap_sequence(user_data['sequence']),\n",
        "                'is_autoregressive': user_data['is_autoregressive']\n",
        "            }\n",
        "        \n",
        "        remapped_val_data = {}\n",
        "        for user_id, user_data in val_data.items():\n",
        "            remapped_val_data[user_id] = {\n",
        "                'sequence': remap_sequence(user_data['sequence']),\n",
        "                'target': remap_target(user_data['target']),\n",
        "                'is_autoregressive': user_data['is_autoregressive']\n",
        "            }\n",
        "        \n",
        "        remapped_test_data = {}\n",
        "        for user_id, user_data in test_data.items():\n",
        "            remapped_test_data[user_id] = {\n",
        "                'sequence': remap_sequence(user_data['sequence']),\n",
        "                'target': remap_target(user_data['target']),\n",
        "                'is_autoregressive': user_data['is_autoregressive']\n",
        "            }\n",
        "        \n",
        "        # Update item_metadata\n",
        "        remapped_item_metadata = {}\n",
        "        for old_item_id, new_item_id in old_to_new_item.items():\n",
        "            if old_item_id in self.item_metadata:\n",
        "                remapped_item_metadata[new_item_id] = self.item_metadata[old_item_id]\n",
        "        \n",
        "        self.item_metadata = remapped_item_metadata\n",
        "        \n",
        "        print(f\"  Remapped {len(old_to_new_item)} items to new IDs (1-{len(old_to_new_item)})\")\n",
        "        print(f\"  Updated item metadata: {len(self.item_metadata)} items\")\n",
        "        \n",
        "        return remapped_train_data, remapped_val_data, remapped_test_data\n",
        "    \n",
        "    def _compute_statistics(self) -> Dict:\n",
        "        \"\"\"Compute dataset statistics.\"\"\"\n",
        "        num_users = len(self.user2id)\n",
        "        num_items = len(self.item2id)\n",
        "        num_interactions = sum(len(seq) for seq in self.user_sequences.values())\n",
        "        avg_seq_length = num_interactions / num_users if num_users > 0 else 0\n",
        "        \n",
        "        return {\n",
        "            'num_users': num_users,\n",
        "            'num_items': num_items,\n",
        "            'num_interactions': num_interactions,\n",
        "            'avg_seq_length': avg_seq_length\n",
        "        }\n",
        "    \n",
        "    def save_mappings(self, save_dir: str):\n",
        "        \"\"\"Save user/item mappings to disk.\"\"\"\n",
        "        save_path = Path(save_dir)\n",
        "        save_path.mkdir(parents=True, exist_ok=True)\n",
        "        \n",
        "        with open(save_path / 'user2id.pkl', 'wb') as f:\n",
        "            pickle.dump(self.user2id, f)\n",
        "        \n",
        "        with open(save_path / 'item2id.pkl', 'wb') as f:\n",
        "            pickle.dump(self.item2id, f)\n",
        "        \n",
        "        with open(save_path / 'id2user.pkl', 'wb') as f:\n",
        "            pickle.dump(self.id2user, f)\n",
        "        \n",
        "        with open(save_path / 'id2item.pkl', 'wb') as f:\n",
        "            pickle.dump(self.id2item, f)\n",
        "        \n",
        "        with open(save_path / 'item_metadata.pkl', 'wb') as f:\n",
        "            pickle.dump(self.item_metadata, f)\n",
        "        \n",
        "        print(f\"Mappings saved to {save_path}\")\n",
        "\n",
        "print(\"DataPreprocessor class defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset classes defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# DATASET CLASSES\n",
        "# ============================================================================\n",
        "\n",
        "class RecDataset(Dataset):\n",
        "    \"\"\"Dataset for LLM-based recommendation.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        data: Dict[int, Dict],\n",
        "        item_metadata: Dict[int, Dict],\n",
        "        num_items: int,\n",
        "        mode: str = 'train',\n",
        "        negative_samples: int = 5,\n",
        "        max_seq_length: int = 50,\n",
        "        eval_negatives: int = 100,\n",
        "        eval_seed: int = 42\n",
        "    ):\n",
        "        self.data = data\n",
        "        self.item_metadata = item_metadata\n",
        "        self.num_items = num_items\n",
        "        self.mode = mode\n",
        "        self.negative_samples = negative_samples\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.eval_negatives = eval_negatives\n",
        "        self.eval_seed = eval_seed\n",
        "        \n",
        "        self.user_ids = list(data.keys())\n",
        "        \n",
        "        # Precompute negative samples for val/test (SASRec protocol: 100 negatives per user)\n",
        "        if self.mode in ['val', 'test']:\n",
        "            self.eval_negative_samples = {}\n",
        "            np.random.seed(eval_seed)\n",
        "            \n",
        "            all_items = np.arange(1, self.num_items, dtype=np.int32)\n",
        "            item_mask = np.ones(self.num_items, dtype=bool)\n",
        "            item_mask[0] = False\n",
        "            \n",
        "            for user_id in tqdm(self.user_ids, desc=\"Precomputing negative samples\"):\n",
        "                user_data = self.data[user_id]\n",
        "                sequence = user_data['sequence']\n",
        "                target = user_data.get('target', {})\n",
        "                \n",
        "                user_items_list = [item['item_id'] for item in sequence]\n",
        "                if target and 'item_id' in target:\n",
        "                    user_items_list.append(target['item_id'])\n",
        "                \n",
        "                item_mask.fill(True)\n",
        "                item_mask[0] = False\n",
        "                \n",
        "                if user_items_list:\n",
        "                    user_items_arr = np.array(user_items_list, dtype=np.int32)\n",
        "                    valid_mask = (user_items_arr > 0) & (user_items_arr < self.num_items)\n",
        "                    item_mask[user_items_arr[valid_mask]] = False\n",
        "                \n",
        "                neg_candidates = all_items[item_mask[1:]]\n",
        "                \n",
        "                if len(neg_candidates) >= self.eval_negatives:\n",
        "                    self.eval_negative_samples[user_id] = np.random.choice(\n",
        "                        neg_candidates, \n",
        "                        size=self.eval_negatives, \n",
        "                        replace=False\n",
        "                    ).tolist()\n",
        "                else:\n",
        "                    self.eval_negative_samples[user_id] = (\n",
        "                        neg_candidates.tolist() + \n",
        "                        np.random.choice(\n",
        "                            neg_candidates,\n",
        "                            size=self.eval_negatives - len(neg_candidates),\n",
        "                            replace=True\n",
        "                        ).tolist()\n",
        "                    )\n",
        "        \n",
        "    def __len__(self) -> int:\n",
        "        return len(self.user_ids)\n",
        "    \n",
        "    def __getitem__(self, idx: int) -> Dict:\n",
        "        user_id = self.user_ids[idx]\n",
        "        user_data = self.data[user_id]\n",
        "        \n",
        "        sequence = user_data['sequence']\n",
        "        is_autoregressive = user_data.get('is_autoregressive', False)\n",
        "        \n",
        "        item_ids = [item['item_id'] for item in sequence]\n",
        "        ratings = [item['rating'] for item in sequence]\n",
        "        \n",
        "        if len(item_ids) > self.max_seq_length:\n",
        "            item_ids = item_ids[-self.max_seq_length:]\n",
        "            ratings = ratings[-self.max_seq_length:]\n",
        "        \n",
        "        seq_length = len(item_ids)\n",
        "        \n",
        "        if is_autoregressive:\n",
        "            target_item_id = None\n",
        "            target_item_ids = item_ids[1:] + [0]\n",
        "        else:\n",
        "            target = user_data['target']\n",
        "            target_item_id = target['item_id']\n",
        "            target_item_ids = None\n",
        "        \n",
        "        negative_items = []\n",
        "        if self.mode == 'train':\n",
        "            if is_autoregressive:\n",
        "                user_items = set(item_ids)\n",
        "            else:\n",
        "                user_items = set(item_ids + [target_item_id])\n",
        "            \n",
        "            neg_candidates = list(set(range(1, self.num_items)) - user_items)\n",
        "            \n",
        "            if len(neg_candidates) >= self.negative_samples:\n",
        "                negative_items = random.sample(neg_candidates, self.negative_samples)\n",
        "            else:\n",
        "                negative_items = neg_candidates + random.choices(\n",
        "                    neg_candidates, \n",
        "                    k=self.negative_samples - len(neg_candidates)\n",
        "                )\n",
        "        elif self.mode in ['val', 'test']:\n",
        "            negative_items = self.eval_negative_samples[user_id]\n",
        "        \n",
        "        return {\n",
        "            'user_id': user_id,\n",
        "            'item_ids': item_ids,\n",
        "            'ratings': ratings,\n",
        "            'seq_length': seq_length,\n",
        "            'target_item_id': target_item_id,\n",
        "            'target_item_ids': target_item_ids,\n",
        "            'negative_items': negative_items,\n",
        "            'is_autoregressive': is_autoregressive\n",
        "        }\n",
        "\n",
        "\n",
        "class RecDataModule:\n",
        "    \"\"\"Data module for handling train/val/test data loaders.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        train_data: Dict,\n",
        "        val_data: Dict,\n",
        "        test_data: Dict,\n",
        "        item_metadata: Dict,\n",
        "        num_items: int,\n",
        "        tokenizer = None,\n",
        "        batch_size: int = 32,\n",
        "        num_workers: int = 4,\n",
        "        negative_samples: int = 5,\n",
        "        max_seq_length: int = 50,\n",
        "        max_text_length: int = 128,\n",
        "        eval_seed: int = 42\n",
        "    ):\n",
        "        self.train_data = train_data\n",
        "        self.val_data = val_data\n",
        "        self.test_data = test_data\n",
        "        self.item_metadata = item_metadata\n",
        "        self.num_items = num_items\n",
        "        self.tokenizer = tokenizer\n",
        "        self.batch_size = batch_size\n",
        "        self.num_workers = num_workers\n",
        "        self.negative_samples = negative_samples\n",
        "        self.max_seq_length = max_seq_length\n",
        "        self.max_text_length = max_text_length\n",
        "        self.eval_seed = eval_seed\n",
        "        \n",
        "        self.train_dataset = RecDataset(\n",
        "            train_data, item_metadata, num_items, \n",
        "            mode='train', \n",
        "            negative_samples=negative_samples,\n",
        "            max_seq_length=max_seq_length,\n",
        "            eval_seed=eval_seed\n",
        "        )\n",
        "        \n",
        "        self.val_dataset = RecDataset(\n",
        "            val_data, item_metadata, num_items, \n",
        "            mode='val',\n",
        "            max_seq_length=max_seq_length,\n",
        "            eval_seed=eval_seed\n",
        "        )\n",
        "        \n",
        "        self.test_dataset = RecDataset(\n",
        "            test_data, item_metadata, num_items, \n",
        "            mode='test',\n",
        "            max_seq_length=max_seq_length,\n",
        "            eval_seed=eval_seed\n",
        "        )\n",
        "    \n",
        "    def collate_fn(self, batch: List[Dict]) -> Dict:\n",
        "        \"\"\"Collate function for batching.\"\"\"\n",
        "        user_ids = [item['user_id'] for item in batch]\n",
        "        seq_lengths = [item['seq_length'] for item in batch]\n",
        "        is_autoregressive = batch[0]['is_autoregressive']\n",
        "        \n",
        "        max_len = max(seq_lengths)\n",
        "        \n",
        "        item_ids_padded = []\n",
        "        ratings_padded = []\n",
        "        attention_mask = []\n",
        "        target_item_ids_padded = []\n",
        "        \n",
        "        for item in batch:\n",
        "            item_ids = item['item_ids']\n",
        "            ratings = item['ratings']\n",
        "            pad_len = max_len - len(item_ids)\n",
        "            \n",
        "            item_ids_padded.append(item_ids + [0] * pad_len)\n",
        "            ratings_padded.append(ratings + [0.0] * pad_len)\n",
        "            attention_mask.append([1] * len(item_ids) + [0] * pad_len)\n",
        "            \n",
        "            if is_autoregressive:\n",
        "                target_ids = item['target_item_ids']\n",
        "                target_item_ids_padded.append(target_ids + [0] * pad_len)\n",
        "        \n",
        "        if is_autoregressive:\n",
        "            target_item_ids = torch.LongTensor(target_item_ids_padded)\n",
        "        else:\n",
        "            target_item_ids = torch.LongTensor([item['target_item_id'] for item in batch])\n",
        "        \n",
        "        negative_items = []\n",
        "        if batch[0]['negative_items']:\n",
        "            negative_items = [item['negative_items'] for item in batch]\n",
        "        \n",
        "        return {\n",
        "            'user_ids': torch.LongTensor(user_ids),\n",
        "            'item_ids': torch.LongTensor(item_ids_padded),\n",
        "            'ratings': torch.FloatTensor(ratings_padded),\n",
        "            'attention_mask': torch.LongTensor(attention_mask),\n",
        "            'target_item_ids': target_item_ids,\n",
        "            'negative_items': torch.LongTensor(negative_items) if negative_items else None,\n",
        "            'seq_lengths': torch.LongTensor(seq_lengths),\n",
        "            'is_autoregressive': is_autoregressive\n",
        "        }\n",
        "    \n",
        "    def train_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.train_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=True,\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.collate_fn,\n",
        "            pin_memory=True\n",
        "        )\n",
        "    \n",
        "    def val_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.val_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.collate_fn,\n",
        "            pin_memory=True\n",
        "        )\n",
        "    \n",
        "    def test_dataloader(self) -> DataLoader:\n",
        "        return DataLoader(\n",
        "            self.test_dataset,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=False,\n",
        "            num_workers=self.num_workers,\n",
        "            collate_fn=self.collate_fn,\n",
        "            pin_memory=True\n",
        "        )\n",
        "\n",
        "print(\"Dataset classes defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embedding classes defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# MODEL CLASSES - EMBEDDINGS\n",
        "# ============================================================================\n",
        "\n",
        "class CollaborativeEmbedding(nn.Module):\n",
        "    \"\"\"Collaborative embeddings for users and items with projection to LLM hidden space.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        num_users: int,\n",
        "        num_items: int,\n",
        "        embedding_dim: int,\n",
        "        llm_hidden_size: int,\n",
        "        lambda_c: float = 0.01,\n",
        "        init_method: str = 'normal'\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.num_users = num_users\n",
        "        self.num_items = num_items\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.llm_hidden_size = llm_hidden_size\n",
        "        self.lambda_c = lambda_c\n",
        "        \n",
        "        self.user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
        "        self.item_embeddings = nn.Embedding(num_items, embedding_dim, padding_idx=0)\n",
        "        \n",
        "        self.user_proj = nn.Linear(embedding_dim, llm_hidden_size, bias=False)\n",
        "        self.item_proj = nn.Linear(embedding_dim, llm_hidden_size, bias=False)\n",
        "        \n",
        "        self._initialize_embeddings(init_method)\n",
        "    \n",
        "    def _initialize_embeddings(self, method: str):\n",
        "        if method == 'normal':\n",
        "            std = (1.0 / self.lambda_c) ** 0.5\n",
        "            nn.init.normal_(self.user_embeddings.weight, mean=0, std=std)\n",
        "            nn.init.normal_(self.item_embeddings.weight, mean=0, std=std)\n",
        "        elif method == 'xavier':\n",
        "            nn.init.xavier_uniform_(self.user_embeddings.weight)\n",
        "            nn.init.xavier_uniform_(self.item_embeddings.weight)\n",
        "        \n",
        "        nn.init.xavier_uniform_(self.user_proj.weight)\n",
        "        nn.init.xavier_uniform_(self.item_proj.weight)\n",
        "    \n",
        "    def get_user_embeddings(self, user_ids: torch.Tensor) -> tuple:\n",
        "        raw_embeds = self.user_embeddings(user_ids)\n",
        "        proj_embeds = self.user_proj(raw_embeds)\n",
        "        return raw_embeds, proj_embeds\n",
        "    \n",
        "    def get_item_embeddings(self, item_ids: torch.Tensor) -> tuple:\n",
        "        raw_embeds = self.item_embeddings(item_ids)\n",
        "        proj_embeds = self.item_proj(raw_embeds)\n",
        "        return raw_embeds, proj_embeds\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        user_ids: Optional[torch.Tensor] = None,\n",
        "        item_ids: Optional[torch.Tensor] = None,\n",
        "        project: bool = True\n",
        "    ) -> tuple:\n",
        "        user_embeds = None\n",
        "        item_embeds = None\n",
        "        \n",
        "        if user_ids is not None:\n",
        "            if project:\n",
        "                _, user_embeds = self.get_user_embeddings(user_ids)\n",
        "            else:\n",
        "                user_embeds, _ = self.get_user_embeddings(user_ids)\n",
        "        \n",
        "        if item_ids is not None:\n",
        "            if project:\n",
        "                _, item_embeds = self.get_item_embeddings(item_ids)\n",
        "            else:\n",
        "                item_embeds, _ = self.get_item_embeddings(item_ids)\n",
        "        \n",
        "        return user_embeds, item_embeds\n",
        "    \n",
        "    def get_all_item_embeddings(self, project: bool = False) -> torch.Tensor:\n",
        "        if project:\n",
        "            return self.item_proj(self.item_embeddings.weight)\n",
        "        return self.item_embeddings.weight\n",
        "    \n",
        "    def regularization_loss(self) -> torch.Tensor:\n",
        "        user_reg = (self.user_embeddings.weight ** 2).mean()\n",
        "        item_reg = (self.item_embeddings.weight ** 2).mean()\n",
        "        return self.lambda_c * (user_reg + item_reg) / 2\n",
        "\n",
        "\n",
        "class ItemScoringHead(nn.Module):\n",
        "    \"\"\"Scoring head for next-item prediction.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        llm_hidden_size: int,\n",
        "        item_embedding_module: nn.Module,\n",
        "        content_embedding_module: Optional[nn.Module] = None,\n",
        "        fusion_weight: float = 0.5,\n",
        "        use_bias: bool = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.llm_hidden_size = llm_hidden_size\n",
        "        self.item_embedding_module = item_embedding_module\n",
        "        self.content_embedding_module = content_embedding_module\n",
        "        self.fusion_weight = fusion_weight\n",
        "        \n",
        "        self.output_proj = nn.Linear(llm_hidden_size, item_embedding_module.embedding_dim, bias=use_bias)\n",
        "        nn.init.xavier_uniform_(self.output_proj.weight)\n",
        "    \n",
        "    def forward(\n",
        "        self,\n",
        "        llm_output: torch.Tensor,\n",
        "        candidate_items: Optional[torch.Tensor] = None,\n",
        "        use_fusion: bool = True\n",
        "    ) -> torch.Tensor:\n",
        "        query = self.output_proj(llm_output)\n",
        "        \n",
        "        if candidate_items is not None:\n",
        "            item_embeds_collab, _ = self.item_embedding_module.get_item_embeddings(candidate_items)\n",
        "            \n",
        "            if use_fusion and self.content_embedding_module is not None:\n",
        "                item_embeds_content, _ = self.content_embedding_module.get_item_embeddings(candidate_items)\n",
        "                item_embeds = (self.fusion_weight * item_embeds_collab + \n",
        "                             (1 - self.fusion_weight) * item_embeds_content)\n",
        "            else:\n",
        "                item_embeds = item_embeds_collab\n",
        "            \n",
        "            scores = torch.bmm(item_embeds, query.unsqueeze(-1)).squeeze(-1)\n",
        "        else:\n",
        "            all_item_embeds_collab = self.item_embedding_module.get_all_item_embeddings(project=False)\n",
        "            \n",
        "            if use_fusion and self.content_embedding_module is not None:\n",
        "                all_item_embeds_content = self.content_embedding_module.get_all_item_embeddings(project=False)\n",
        "                all_item_embeds = (self.fusion_weight * all_item_embeds_collab + \n",
        "                                 (1 - self.fusion_weight) * all_item_embeds_content)\n",
        "            else:\n",
        "                all_item_embeds = all_item_embeds_collab\n",
        "            \n",
        "            scores = torch.matmul(query, all_item_embeds.t())\n",
        "        \n",
        "        return scores\n",
        "\n",
        "print(\"Embedding classes defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "StageAModel class defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# MODEL CLASSES - STAGE A MODEL\n",
        "# ============================================================================\n",
        "\n",
        "class StageAModel(nn.Module):\n",
        "    \"\"\"Stage A: Pretrain user/item token embeddings.\"\"\"\n",
        "    \n",
        "    def __init__(\n",
        "        self,\n",
        "        base_llm_name: str,\n",
        "        num_users: int,\n",
        "        num_items: int,\n",
        "        embedding_dim: int = 64,\n",
        "        lambda_c: float = 0.01,\n",
        "        freeze_llm: bool = True,\n",
        "        use_bpr_loss: bool = True,\n",
        "        random_init_llm: bool = False\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \n",
        "        if random_init_llm:\n",
        "            llm_config = AutoConfig.from_pretrained(base_llm_name)\n",
        "            self.llm = AutoModel.from_config(llm_config)\n",
        "        else:\n",
        "            self.llm = AutoModel.from_pretrained(base_llm_name)\n",
        "        self.llm_hidden_size = self.llm.config.hidden_size\n",
        "        self.vocab_size = self.llm.config.vocab_size\n",
        "        \n",
        "        if freeze_llm:\n",
        "            for param in self.llm.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "        self.collab_embeddings = CollaborativeEmbedding(\n",
        "            num_users=num_users,\n",
        "            num_items=num_items,\n",
        "            embedding_dim=embedding_dim,\n",
        "            llm_hidden_size=self.llm_hidden_size,\n",
        "            lambda_c=lambda_c,\n",
        "            init_method='xavier'\n",
        "        )\n",
        "        \n",
        "        self.collab_scoring_head = ItemScoringHead(\n",
        "            self.llm_hidden_size,\n",
        "            self.collab_embeddings,\n",
        "            content_embedding_module=None,\n",
        "            fusion_weight=1.0\n",
        "        )\n",
        "        \n",
        "        self.use_bpr_loss = use_bpr_loss\n",
        "    \n",
        "    def forward_collaborative(\n",
        "        self,\n",
        "        user_ids: torch.Tensor,\n",
        "        item_ids: torch.Tensor,\n",
        "        attention_mask: torch.Tensor\n",
        "    ) -> torch.Tensor:\n",
        "        batch_size = user_ids.size(0)\n",
        "        \n",
        "        user_embeds, item_embeds = self.collab_embeddings(\n",
        "            user_ids=user_ids,\n",
        "            item_ids=item_ids,\n",
        "            project=True\n",
        "        )\n",
        "        \n",
        "        user_embeds = user_embeds.unsqueeze(1)\n",
        "        inputs_embeds = torch.cat([user_embeds, item_embeds], dim=1)\n",
        "        \n",
        "        user_mask = torch.ones(batch_size, 1, device=attention_mask.device, dtype=attention_mask.dtype)\n",
        "        full_attention_mask = torch.cat([user_mask, attention_mask], dim=1)\n",
        "        \n",
        "        outputs = self.llm(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=full_attention_mask,\n",
        "            output_hidden_states=True\n",
        "        )\n",
        "        \n",
        "        last_hidden = outputs.last_hidden_state\n",
        "        seq_lengths = full_attention_mask.sum(dim=1) - 1\n",
        "        batch_indices = torch.arange(batch_size, device=last_hidden.device)\n",
        "        output_hidden = last_hidden[batch_indices, seq_lengths]\n",
        "        \n",
        "        return output_hidden\n",
        "    \n",
        "    def compute_collaborative_loss(\n",
        "        self,\n",
        "        user_ids: torch.Tensor,\n",
        "        item_ids: torch.Tensor,\n",
        "        attention_mask: torch.Tensor,\n",
        "        target_items: torch.Tensor,\n",
        "        is_autoregressive: bool = False,\n",
        "        negative_items: Optional[torch.Tensor] = None\n",
        "    ) -> Dict[str, torch.Tensor]:\n",
        "        batch_size = user_ids.size(0)\n",
        "        \n",
        "        user_embeds, item_embeds = self.collab_embeddings(\n",
        "            user_ids=user_ids,\n",
        "            item_ids=item_ids,\n",
        "            project=True\n",
        "        )\n",
        "        \n",
        "        user_embeds = user_embeds.unsqueeze(1)\n",
        "        inputs_embeds = torch.cat([user_embeds, item_embeds], dim=1)\n",
        "        \n",
        "        user_mask = torch.ones(batch_size, 1, device=attention_mask.device, dtype=attention_mask.dtype)\n",
        "        full_attention_mask = torch.cat([user_mask, attention_mask], dim=1)\n",
        "        \n",
        "        outputs = self.llm(\n",
        "            inputs_embeds=inputs_embeds,\n",
        "            attention_mask=full_attention_mask,\n",
        "            output_hidden_states=True\n",
        "        )\n",
        "        \n",
        "        last_hidden = outputs.last_hidden_state\n",
        "        \n",
        "        if is_autoregressive:\n",
        "            item_hidden = last_hidden[:, 1:, :]\n",
        "            h_query = self.collab_scoring_head.output_proj(item_hidden)\n",
        "            all_item_embeds = self.collab_embeddings.get_all_item_embeddings(project=False)\n",
        "            scores = torch.matmul(h_query, all_item_embeds.t())\n",
        "            \n",
        "            scores_flat = scores.reshape(-1, scores.size(-1))\n",
        "            targets_flat = target_items.reshape(-1)\n",
        "            \n",
        "            valid_mask = (attention_mask > 0) & (target_items > 0)\n",
        "            valid_mask_flat = valid_mask.reshape(-1)\n",
        "            num_valid = valid_mask_flat.sum()\n",
        "            \n",
        "            ce_loss = F.cross_entropy(\n",
        "                scores_flat,\n",
        "                targets_flat,\n",
        "                ignore_index=0,\n",
        "                reduction='sum'\n",
        "            )\n",
        "            ce_loss = ce_loss / num_valid.clamp(min=1)\n",
        "            \n",
        "            losses = {'collaborative_ce': ce_loss}\n",
        "            \n",
        "            if self.use_bpr_loss and negative_items is not None:\n",
        "                h_context = self.collab_scoring_head.output_proj(item_hidden)\n",
        "                _, target_embeds_raw = self.collab_embeddings(item_ids=target_items, project=False)\n",
        "                _, neg_embeds_raw = self.collab_embeddings(item_ids=negative_items, project=False)\n",
        "                \n",
        "                pos_scores_context = torch.sum(h_context * target_embeds_raw, dim=-1)\n",
        "                neg_scores_context = torch.bmm(h_context, neg_embeds_raw.transpose(1, 2))\n",
        "                \n",
        "                pos_scores_expanded = pos_scores_context.unsqueeze(-1)\n",
        "                bpr_logits_context = pos_scores_expanded - neg_scores_context\n",
        "                bpr_loss_context = -torch.log(torch.sigmoid(bpr_logits_context) + 1e-8).sum(dim=-1)\n",
        "                bpr_loss_context = (bpr_loss_context * valid_mask.float()).sum() / num_valid.clamp(min=1)\n",
        "                losses['bpr_context'] = bpr_loss_context\n",
        "                \n",
        "                user_embeds_raw, _ = self.collab_embeddings(user_ids=user_ids, project=False)\n",
        "                user_embeds_expanded = user_embeds_raw.unsqueeze(1).expand(-1, target_embeds_raw.size(1), -1)\n",
        "                \n",
        "                pos_scores_user = torch.sum(user_embeds_expanded * target_embeds_raw, dim=-1)\n",
        "                neg_scores_user = torch.bmm(user_embeds_expanded, neg_embeds_raw.transpose(1, 2))\n",
        "                \n",
        "                pos_scores_user_expanded = pos_scores_user.unsqueeze(-1)\n",
        "                bpr_logits_user = pos_scores_user_expanded - neg_scores_user\n",
        "                bpr_loss_user = -torch.log(torch.sigmoid(bpr_logits_user) + 1e-8).sum(dim=-1)\n",
        "                bpr_loss_user = (bpr_loss_user * valid_mask.float()).sum() / num_valid.clamp(min=1)\n",
        "                losses['bpr_user'] = bpr_loss_user\n",
        "                losses['bpr'] = bpr_loss_context + bpr_loss_user\n",
        "        else:\n",
        "            seq_lengths = full_attention_mask.sum(dim=1) - 1\n",
        "            batch_indices = torch.arange(batch_size, device=last_hidden.device)\n",
        "            llm_output = last_hidden[batch_indices, seq_lengths]\n",
        "            \n",
        "            scores = self.collab_scoring_head(llm_output)\n",
        "            ce_loss = F.cross_entropy(scores, target_items)\n",
        "            losses = {'collaborative_ce': ce_loss}\n",
        "            \n",
        "            if self.use_bpr_loss and negative_items is not None:\n",
        "                h_context = self.collab_scoring_head.output_proj(llm_output)\n",
        "                _, target_embeds_raw = self.collab_embeddings(item_ids=target_items, project=False)\n",
        "                _, neg_embeds_raw = self.collab_embeddings(item_ids=negative_items, project=False)\n",
        "                \n",
        "                pos_scores_context = torch.sum(h_context * target_embeds_raw, dim=-1)\n",
        "                neg_scores_context = torch.sum(h_context.unsqueeze(1) * neg_embeds_raw, dim=-1)\n",
        "                bpr_loss_context = -torch.log(torch.sigmoid(pos_scores_context.unsqueeze(1) - neg_scores_context) + 1e-8).mean()\n",
        "                losses['bpr_context'] = bpr_loss_context\n",
        "                \n",
        "                user_embeds_raw, _ = self.collab_embeddings(user_ids=user_ids, project=False)\n",
        "                pos_scores_user = torch.sum(user_embeds_raw * target_embeds_raw, dim=-1)\n",
        "                neg_scores_user = torch.sum(user_embeds_raw.unsqueeze(1) * neg_embeds_raw, dim=-1)\n",
        "                bpr_loss_user = -torch.log(torch.sigmoid(pos_scores_user.unsqueeze(1) - neg_scores_user) + 1e-8).mean()\n",
        "                losses['bpr_user'] = bpr_loss_user\n",
        "                losses['bpr'] = bpr_loss_context + bpr_loss_user\n",
        "        \n",
        "        return losses\n",
        "    \n",
        "    def compute_regularization_losses(self) -> Dict[str, torch.Tensor]:\n",
        "        collab_reg = self.collab_embeddings.regularization_loss()\n",
        "        return {'collab_regularization': collab_reg}\n",
        "\n",
        "print(\"StageAModel class defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metrics functions defined!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# METRICS\n",
        "# ============================================================================\n",
        "\n",
        "def hr_at_k_sampled(scores: torch.Tensor, targets: torch.Tensor, k: int) -> float:\n",
        "    \"\"\"Compute Hit@K for sampled candidate evaluation (SASRec-style).\"\"\"\n",
        "    topk_idx = scores.topk(k, dim=-1).indices\n",
        "    hits = (topk_idx == targets.unsqueeze(-1)).any(dim=-1).float()\n",
        "    return hits.mean().item()\n",
        "\n",
        "\n",
        "def ndcg_at_k_sampled(scores: torch.Tensor, targets: torch.Tensor, k: int) -> float:\n",
        "    \"\"\"Compute NDCG@K for sampled candidate evaluation (SASRec-style).\"\"\"\n",
        "    topk_idx = scores.topk(k, dim=-1).indices\n",
        "    hits = (topk_idx == targets.unsqueeze(-1))\n",
        "    \n",
        "    positions = torch.arange(1, k + 1, device=scores.device, dtype=torch.float32)\n",
        "    discounts = 1.0 / torch.log2(positions + 1.0)\n",
        "    \n",
        "    gains = (hits.float() * discounts.unsqueeze(0)).max(dim=-1).values\n",
        "    idcg = 1.0 / torch.log2(torch.tensor(2.0, device=scores.device))\n",
        "    ndcg = gains / idcg\n",
        "    \n",
        "    return ndcg.mean().item()\n",
        "\n",
        "\n",
        "def compute_sampled_metrics(\n",
        "    scores: torch.Tensor,\n",
        "    targets: torch.Tensor,\n",
        "    k_list: List[int] = [1, 5, 10]\n",
        ") -> Dict[str, float]:\n",
        "    \"\"\"Compute SASRec-style sampled metrics.\"\"\"\n",
        "    scores = scores.to(torch.float32)\n",
        "    targets = targets.to(torch.long)\n",
        "    metrics = {}\n",
        "    \n",
        "    for k in k_list:\n",
        "        metrics[f'hit@{k}'] = hr_at_k_sampled(scores, targets, k)\n",
        "        metrics[f'ndcg@{k}'] = ndcg_at_k_sampled(scores, targets, k)\n",
        "    \n",
        "    return metrics\n",
        "\n",
        "\n",
        "def print_metrics(metrics: Dict[str, float], prefix: str = \"\"):\n",
        "    \"\"\"Print metrics in a formatted way.\"\"\"\n",
        "    print(f\"\\n{prefix}Metrics:\")\n",
        "    print(\"-\" * 50)\n",
        "    for metric_name, value in sorted(metrics.items()):\n",
        "        print(f\"  {metric_name}: {value:.4f}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "print(\"Metrics functions defined!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1: Data Preprocessing\n",
        "\n",
        "Run this cell to preprocess your data. This will create train/val/test splits and save the processed data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading user sequences...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading sequences: 761756it [00:19, 39216.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading item metadata...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Loading metadata: 20318771it [02:47, 121026.48it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Truncating to 100000 sequences...\n",
            "  Truncated to 100000 user sequences\n",
            "Creating train/val/test splits...\n",
            "\n",
            "Remapping item IDs to compact range...\n",
            "  Found 389161 unique items in final dataset\n",
            "  Remapped 389161 items to new IDs (1-389161)\n",
            "  Updated item metadata: 389161 items\n",
            "\n",
            "Dataset Statistics:\n",
            "  Users: 100000\n",
            "  Items: 389161\n",
            "  Interactions: 1319558\n",
            "  Avg sequence length: 13.20\n",
            "  Train sequences: 100000\n",
            "  Val sequences: 100000\n",
            "  Test sequences: 100000\n",
            "\n",
            "Saving processed data to ./data/processed_notebook...\n",
            "Mappings saved to data/processed_notebook\n",
            "\n",
            "Preprocessing complete! Data saved to ./data/processed_notebook\n",
            "\n",
            "Dataset info:\n",
            "  num_users: 100000\n",
            "  num_items: 389162\n",
            "  num_train: 100000\n",
            "  num_val: 100000\n",
            "  num_test: 100000\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# DATA PREPROCESSING\n",
        "# ============================================================================\n",
        "\n",
        "# Create preprocessor\n",
        "preprocessor = DataPreprocessor(\n",
        "    user_sequences_path=CONFIG['data']['user_sequences_path'],\n",
        "    item_metadata_path=CONFIG['data'].get('item_metadata_path'),\n",
        "    min_sequence_length=CONFIG['data']['min_sequence_length'],\n",
        "    max_sequence_length=CONFIG['data']['max_sequence_length'],\n",
        "    train_ratio=CONFIG['data']['train_ratio'],\n",
        "    val_ratio=CONFIG['data']['val_ratio'],\n",
        "    seed=CONFIG['data']['seed'],\n",
        "    max_train_sequences=CONFIG['data'].get('max_train_sequences')\n",
        ")\n",
        "\n",
        "# Load and preprocess data\n",
        "train_data, val_data, test_data = preprocessor.load_and_preprocess()\n",
        "\n",
        "# Save processed data\n",
        "print(f\"\\nSaving processed data to {DATA_OUTPUT_DIR}...\")\n",
        "with open(Path(DATA_OUTPUT_DIR) / 'train_data.pkl', 'wb') as f:\n",
        "    pickle.dump(train_data, f)\n",
        "with open(Path(DATA_OUTPUT_DIR) / 'val_data.pkl', 'wb') as f:\n",
        "    pickle.dump(val_data, f)\n",
        "with open(Path(DATA_OUTPUT_DIR) / 'test_data.pkl', 'wb') as f:\n",
        "    pickle.dump(test_data, f)\n",
        "\n",
        "# Save mappings\n",
        "preprocessor.save_mappings(DATA_OUTPUT_DIR)\n",
        "\n",
        "# Save dataset info\n",
        "dataset_info = {\n",
        "    'num_users': len(preprocessor.user2id),\n",
        "    'num_items': len(preprocessor.item2id) + 1,  # +1 for padding\n",
        "    'num_train': len(train_data),\n",
        "    'num_val': len(val_data),\n",
        "    'num_test': len(test_data)\n",
        "}\n",
        "\n",
        "with open(Path(DATA_OUTPUT_DIR) / 'dataset_info.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset_info, f)\n",
        "\n",
        "print(f\"\\nPreprocessing complete! Data saved to {DATA_OUTPUT_DIR}\")\n",
        "print(\"\\nDataset info:\")\n",
        "for key, value in dataset_info.items():\n",
        "    print(f\"  {key}: {value}\")\n",
        "\n",
        "# Store for later use\n",
        "num_users = dataset_info['num_users']\n",
        "num_items = dataset_info['num_items']\n",
        "item_metadata = preprocessor.item_metadata\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 1.5: Load Preprocessed Data (Optional)\n",
        "\n",
        "If you've already preprocessed the data, you can load it directly from disk instead of running preprocessing again.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading preprocessed data from /space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/data/processed_notebook...\n",
            "\n",
            "Preprocessed data loaded successfully!\n",
            "  Users: 100000\n",
            "  Items: 389162\n",
            "  Train sequences: 100000\n",
            "  Val sequences: 100000\n",
            "  Test sequences: 100000\n",
            "  Item metadata: 389161 items\n",
            "\n",
            "Using data from: /space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/data/processed_notebook\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# LOAD PREPROCESSED DATA (OPTIONAL - SKIP PREPROCESSING IF DATA EXISTS)\n",
        "# ============================================================================\n",
        "\n",
        "# Path to preprocessed data\n",
        "PREPROCESSED_DATA_DIR = \"/space/mcdonald-syn01/1/projects/jsawant/llm_recommender_2/data/processed_notebook\"\n",
        "\n",
        "# Check if preprocessed data exists\n",
        "preprocessed_path = Path(PREPROCESSED_DATA_DIR)\n",
        "if preprocessed_path.exists() and (preprocessed_path / 'train_data.pkl').exists():\n",
        "    print(f\"Loading preprocessed data from {PREPROCESSED_DATA_DIR}...\")\n",
        "    \n",
        "    # Load processed data\n",
        "    with open(preprocessed_path / 'train_data.pkl', 'rb') as f:\n",
        "        train_data = pickle.load(f)\n",
        "    with open(preprocessed_path / 'val_data.pkl', 'rb') as f:\n",
        "        val_data = pickle.load(f)\n",
        "    with open(preprocessed_path / 'test_data.pkl', 'rb') as f:\n",
        "        test_data = pickle.load(f)\n",
        "    \n",
        "    # Load dataset info\n",
        "    with open(preprocessed_path / 'dataset_info.pkl', 'rb') as f:\n",
        "        dataset_info = pickle.load(f)\n",
        "    \n",
        "    # Load mappings\n",
        "    with open(preprocessed_path / 'item_metadata.pkl', 'rb') as f:\n",
        "        item_metadata = pickle.load(f)\n",
        "    \n",
        "    # Extract key info\n",
        "    num_users = dataset_info['num_users']\n",
        "    num_items = dataset_info['num_items']\n",
        "    \n",
        "    print(f\"\\nPreprocessed data loaded successfully!\")\n",
        "    print(f\"  Users: {num_users}\")\n",
        "    print(f\"  Items: {num_items}\")\n",
        "    print(f\"  Train sequences: {dataset_info['num_train']}\")\n",
        "    print(f\"  Val sequences: {dataset_info['num_val']}\")\n",
        "    print(f\"  Test sequences: {dataset_info['num_test']}\")\n",
        "    print(f\"  Item metadata: {len(item_metadata)} items\")\n",
        "    \n",
        "    # Update DATA_OUTPUT_DIR to match loaded data location\n",
        "    DATA_OUTPUT_DIR = str(preprocessed_path)\n",
        "    print(f\"\\nUsing data from: {DATA_OUTPUT_DIR}\")\n",
        "else:\n",
        "    print(f\"Preprocessed data not found at {PREPROCESSED_DATA_DIR}\")\n",
        "    print(\"Please run the preprocessing cell (Step 1) first, or update PREPROCESSED_DATA_DIR path.\")\n",
        "    print(\"Skipping data loading - you'll need to run preprocessing.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 2: Create Data Loaders\n",
        "\n",
        "Create PyTorch data loaders for training, validation, and testing.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CREATE DATA LOADERS\n",
        "# ============================================================================\n",
        "\n",
        "data_module = RecDataModule(\n",
        "    train_data=train_data,\n",
        "    val_data=val_data,\n",
        "    test_data=test_data,\n",
        "    item_metadata=item_metadata,\n",
        "    num_items=num_items,\n",
        "    tokenizer=None,  # No tokenizer needed for Stage A\n",
        "    batch_size=CONFIG['stage_a']['batch_size'],\n",
        "    num_workers=4,\n",
        "    negative_samples=CONFIG['stage_a']['collaborative']['negative_samples'],\n",
        "    max_seq_length=CONFIG['data']['max_sequence_length'],\n",
        "    max_text_length=None,\n",
        "    eval_seed=CONFIG['data']['seed']\n",
        ")\n",
        "\n",
        "train_loader = data_module.train_dataloader()\n",
        "val_loader = data_module.val_dataloader()\n",
        "test_loader = data_module.test_dataloader()\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 3: Initialize Model\n",
        "\n",
        "Create and initialize the Stage A model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Model parameters:\n",
            "  Total: 187,347,456\n",
            "  Trainable: 187,347,456\n",
            "\n",
            "Model and optimizer initialized!\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# INITIALIZE MODEL\n",
        "# ============================================================================\n",
        "\n",
        "model = StageAModel(\n",
        "    base_llm_name=CONFIG['model']['base_llm'],\n",
        "    num_users=num_users,\n",
        "    num_items=num_items,\n",
        "    embedding_dim=CONFIG['model']['embedding_dim'],\n",
        "    lambda_c=CONFIG['embeddings']['lambda_c'],\n",
        "    freeze_llm=CONFIG['model']['freeze_llm_stage_a'],\n",
        "    use_bpr_loss=CONFIG['stage_a']['collaborative'].get('use_bpr_loss', True),\n",
        "    random_init_llm=CONFIG['model'].get('random_init_stage_a_llm', False)\n",
        ")\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "print(f\"\\nModel parameters:\")\n",
        "print(f\"  Total: {total_params:,}\")\n",
        "print(f\"  Trainable: {trainable_params:,}\")\n",
        "\n",
        "# Create optimizer\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=float(CONFIG['stage_a']['learning_rate']),\n",
        "    weight_decay=float(CONFIG['stage_a']['weight_decay'])\n",
        ")\n",
        "\n",
        "print(\"\\nModel and optimizer initialized!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 4: Training\n",
        "\n",
        "Train the model. This includes training loop, evaluation, and checkpoint saving.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting training...\n",
            "Output directory: ./checkpoints/notebook_training\n",
            "\n",
            "============================================================\n",
            "Epoch 1/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  32%|      | 500/1563 [01:54<03:27,  5.13it/s, loss=20.3124, step=500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 500] Loss: 19.6449, Avg: 20.3124\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  64%|   | 1001/1563 [03:47<02:07,  4.39it/s, loss=19.9729, step=1000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 1000] Loss: 19.7887, Avg: 19.9729\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1:  96%|| 1500/1563 [05:40<00:16,  3.86it/s, loss=19.7268, step=1500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 1500] Loss: 18.5041, Avg: 19.7268\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 1: 100%|| 1563/1563 [05:55<00:00,  4.40it/s, loss=19.7268, step=1500]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 training metrics:\n",
            "  Total loss: 19.6979\n",
            "  Collaborative CE: 12.2699\n",
            "  BPR loss: 37.1399\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:36<00:00, 43.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.2062\n",
            "  hit@10: 0.5117\n",
            "  hit@20: 0.6152\n",
            "  hit@5: 0.4110\n",
            "  ndcg@1: 0.2062\n",
            "  ndcg@10: 0.3458\n",
            "  ndcg@20: 0.3719\n",
            "  ndcg@5: 0.3133\n",
            "--------------------------------------------------\n",
            "   New best model saved! Hit@10: 0.5117\n",
            "\n",
            "============================================================\n",
            "Epoch 2/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  28%|       | 437/1563 [01:51<04:01,  4.67it/s, loss=17.5857, step=2000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 2000] Loss: 17.7912, Avg: 17.5857\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  60%|    | 937/1563 [04:13<02:16,  4.59it/s, loss=17.4651, step=2500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 2500] Loss: 16.5026, Avg: 17.4651\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2:  92%|| 1437/1563 [06:28<00:27,  4.57it/s, loss=17.3506, step=3000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 3000] Loss: 16.9199, Avg: 17.3506\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 2: 100%|| 1563/1563 [07:02<00:00,  3.70it/s, loss=17.3506, step=3000]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 training metrics:\n",
            "  Total loss: 17.3251\n",
            "  Collaborative CE: 11.4308\n",
            "  BPR loss: 29.4713\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:35<00:00, 43.50it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 2 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.2283\n",
            "  hit@10: 0.5314\n",
            "  hit@20: 0.6364\n",
            "  hit@5: 0.4344\n",
            "  ndcg@1: 0.2283\n",
            "  ndcg@10: 0.3678\n",
            "  ndcg@20: 0.3944\n",
            "  ndcg@5: 0.3365\n",
            "--------------------------------------------------\n",
            "   New best model saved! Hit@10: 0.5314\n",
            "\n",
            "============================================================\n",
            "Epoch 3/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  24%|       | 375/1563 [01:38<04:59,  3.97it/s, loss=16.1474, step=3500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 3500] Loss: 16.0578, Avg: 16.1474\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  56%|    | 875/1563 [03:41<02:58,  3.85it/s, loss=16.1690, step=4000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 4000] Loss: 16.3867, Avg: 16.1690\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3:  88%| | 1375/1563 [05:51<00:44,  4.27it/s, loss=16.1723, step=4500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 4500] Loss: 16.7334, Avg: 16.1723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 3: 100%|| 1563/1563 [06:40<00:00,  3.90it/s, loss=16.1723, step=4500]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 training metrics:\n",
            "  Total loss: 16.1717\n",
            "  Collaborative CE: 10.9368\n",
            "  BPR loss: 26.1745\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:36<00:00, 43.35it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 3 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.2704\n",
            "  hit@10: 0.5793\n",
            "  hit@20: 0.6699\n",
            "  hit@5: 0.4884\n",
            "  ndcg@1: 0.2704\n",
            "  ndcg@10: 0.4151\n",
            "  ndcg@20: 0.4380\n",
            "  ndcg@5: 0.3857\n",
            "--------------------------------------------------\n",
            "   New best model saved! Hit@10: 0.5793\n",
            "\n",
            "============================================================\n",
            "Epoch 4/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  20%|        | 312/1563 [01:27<05:38,  3.70it/s, loss=14.3138, step=5000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 5000] Loss: 14.7591, Avg: 14.3138\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  52%|    | 811/1563 [03:48<03:07,  4.00it/s, loss=14.4627, step=5500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 5500] Loss: 14.7395, Avg: 14.4627\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4:  84%| | 1311/1563 [05:58<00:56,  4.46it/s, loss=14.5596, step=6000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 6000] Loss: 14.8482, Avg: 14.5596\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 4: 100%|| 1563/1563 [07:09<00:00,  3.64it/s, loss=14.5596, step=6000]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 training metrics:\n",
            "  Total loss: 14.5989\n",
            "  Collaborative CE: 10.0695\n",
            "  BPR loss: 22.6470\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:35<00:00, 43.54it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 4 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.3018\n",
            "  hit@10: 0.5942\n",
            "  hit@20: 0.6765\n",
            "  hit@5: 0.5089\n",
            "  ndcg@1: 0.3018\n",
            "  ndcg@10: 0.4393\n",
            "  ndcg@20: 0.4601\n",
            "  ndcg@5: 0.4116\n",
            "--------------------------------------------------\n",
            "   New best model saved! Hit@10: 0.5942\n",
            "\n",
            "============================================================\n",
            "Epoch 5/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  16%|        | 248/1563 [01:05<04:26,  4.93it/s, loss=12.6508, step=6500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 6500] Loss: 13.0353, Avg: 12.6508\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  48%|     | 749/1563 [03:16<03:31,  3.85it/s, loss=12.8542, step=7000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 7000] Loss: 13.3318, Avg: 12.8542\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5:  80%|  | 1248/1563 [05:28<01:05,  4.81it/s, loss=13.0008, step=7500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 7500] Loss: 13.2302, Avg: 13.0008\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 5: 100%|| 1563/1563 [06:48<00:00,  3.83it/s, loss=13.0008, step=7500]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 training metrics:\n",
            "  Total loss: 13.0808\n",
            "  Collaborative CE: 8.9399\n",
            "  BPR loss: 20.7047\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:35<00:00, 43.65it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 5 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.3153\n",
            "  hit@10: 0.5986\n",
            "  hit@20: 0.6788\n",
            "  hit@5: 0.5169\n",
            "  ndcg@1: 0.3153\n",
            "  ndcg@10: 0.4491\n",
            "  ndcg@20: 0.4694\n",
            "  ndcg@5: 0.4226\n",
            "--------------------------------------------------\n",
            "   New best model saved! Hit@10: 0.5986\n",
            "\n",
            "============================================================\n",
            "Epoch 6/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  12%|        | 186/1563 [00:51<07:31,  3.05it/s, loss=11.1309, step=8000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 8000] Loss: 11.1651, Avg: 11.1309\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  44%|     | 686/1563 [03:10<04:09,  3.52it/s, loss=11.3706, step=8500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 8500] Loss: 11.7324, Avg: 11.3706\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6:  76%|  | 1186/1563 [05:26<01:24,  4.44it/s, loss=11.5640, step=9000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 9000] Loss: 11.8580, Avg: 11.5640\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 6: 100%|| 1563/1563 [07:10<00:00,  3.63it/s, loss=11.5640, step=9000]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 training metrics:\n",
            "  Total loss: 11.6859\n",
            "  Collaborative CE: 7.7187\n",
            "  BPR loss: 19.8361\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:35<00:00, 43.47it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 6 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.3106\n",
            "  hit@10: 0.5893\n",
            "  hit@20: 0.6726\n",
            "  hit@5: 0.5090\n",
            "  ndcg@1: 0.3106\n",
            "  ndcg@10: 0.4421\n",
            "  ndcg@20: 0.4632\n",
            "  ndcg@5: 0.4161\n",
            "--------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Epoch 7/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:   8%|         | 122/1563 [00:33<05:52,  4.09it/s, loss=9.7813, step=9500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 9500] Loss: 9.8506, Avg: 9.7813\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  40%|      | 621/1563 [02:42<04:02,  3.89it/s, loss=10.0534, step=1e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 10000] Loss: 9.8392, Avg: 10.0534\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  40%|      | 623/1563 [03:01<1:05:27,  4.18s/it, loss=10.0534, step=1e+4]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Checkpoint saved to checkpoints/notebook_training/checkpoint-10000\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7:  72%|  | 1122/1563 [05:19<01:41,  4.36it/s, loss=10.2723, step=10500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 10500] Loss: 10.8323, Avg: 10.2723\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 7: 100%|| 1563/1563 [07:21<00:00,  3.54it/s, loss=10.2723, step=10500]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 training metrics:\n",
            "  Total loss: 10.4331\n",
            "  Collaborative CE: 6.5660\n",
            "  BPR loss: 19.3355\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:35<00:00, 43.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.3085\n",
            "  hit@10: 0.5818\n",
            "  hit@20: 0.6685\n",
            "  hit@5: 0.5010\n",
            "  ndcg@1: 0.3085\n",
            "  ndcg@10: 0.4369\n",
            "  ndcg@20: 0.4587\n",
            "  ndcg@5: 0.4108\n",
            "--------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Epoch 8/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:   4%|         | 60/1563 [00:17<07:01,  3.57it/s, loss=8.8379, step=11000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 11000] Loss: 9.2574, Avg: 8.8379\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  36%|      | 559/1563 [02:27<03:22,  4.95it/s, loss=8.9584, step=11500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 11500] Loss: 9.1848, Avg: 8.9584\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8:  68%|   | 1060/1563 [04:31<02:11,  3.82it/s, loss=9.1747, step=12000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 12000] Loss: 9.8955, Avg: 9.1747\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|| 1560/1563 [06:41<00:00,  5.52it/s, loss=9.3571, step=12500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 12500] Loss: 10.2042, Avg: 9.3571\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 8: 100%|| 1563/1563 [06:42<00:00,  3.88it/s, loss=9.3571, step=12500]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 training metrics:\n",
            "  Total loss: 9.3583\n",
            "  Collaborative CE: 5.5713\n",
            "  BPR loss: 18.9347\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:35<00:00, 43.57it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 8 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.3042\n",
            "  hit@10: 0.5755\n",
            "  hit@20: 0.6658\n",
            "  hit@5: 0.4933\n",
            "  ndcg@1: 0.3042\n",
            "  ndcg@10: 0.4310\n",
            "  ndcg@20: 0.4538\n",
            "  ndcg@5: 0.4044\n",
            "--------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Epoch 9/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  32%|      | 496/1563 [02:17<03:55,  4.53it/s, loss=8.0991, step=13000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 13000] Loss: 8.3694, Avg: 8.0991\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  64%|   | 996/1563 [04:35<02:05,  4.51it/s, loss=8.2997, step=13500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 13500] Loss: 8.3811, Avg: 8.2997\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9:  96%|| 1496/1563 [06:59<00:15,  4.29it/s, loss=8.4656, step=14000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 14000] Loss: 8.8146, Avg: 8.4656\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 9: 100%|| 1563/1563 [07:19<00:00,  3.56it/s, loss=8.4656, step=14000]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9 training metrics:\n",
            "  Total loss: 8.4877\n",
            "  Collaborative CE: 4.7766\n",
            "  BPR loss: 18.5555\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:35<00:00, 43.62it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 9 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.2901\n",
            "  hit@10: 0.5619\n",
            "  hit@20: 0.6580\n",
            "  hit@5: 0.4788\n",
            "  ndcg@1: 0.2901\n",
            "  ndcg@10: 0.4166\n",
            "  ndcg@20: 0.4408\n",
            "  ndcg@5: 0.3898\n",
            "--------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Epoch 10/10\n",
            "============================================================\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  28%|       | 434/1563 [01:58<05:01,  3.74it/s, loss=7.3778, step=14500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 14500] Loss: 7.3719, Avg: 7.3778\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  60%|    | 934/1563 [04:17<02:33,  4.09it/s, loss=7.5659, step=15000]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 15000] Loss: 8.0171, Avg: 7.5659\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10:  92%|| 1434/1563 [06:42<00:34,  3.74it/s, loss=7.7294, step=15500]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "[Step 15500] Loss: 7.8128, Avg: 7.7294\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Epoch 10: 100%|| 1563/1563 [07:21<00:00,  3.54it/s, loss=7.7294, step=15500]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 training metrics:\n",
            "  Total loss: 7.7677\n",
            "  Collaborative CE: 4.1322\n",
            "  BPR loss: 18.1777\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Evaluating: 100%|| 1563/1563 [00:35<00:00, 43.55it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 10 Validation Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.2834\n",
            "  hit@10: 0.5534\n",
            "  hit@20: 0.6494\n",
            "  hit@5: 0.4697\n",
            "  ndcg@1: 0.2834\n",
            "  ndcg@10: 0.4089\n",
            "  ndcg@20: 0.4331\n",
            "  ndcg@5: 0.3818\n",
            "--------------------------------------------------\n",
            "\n",
            "============================================================\n",
            "Training complete!\n",
            "Best Hit@10: 0.5986\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# TRAINING LOOP\n",
        "# ============================================================================\n",
        "\n",
        "# Training configuration\n",
        "loss_weights = CONFIG['stage_a']['loss_weights']\n",
        "max_grad_norm = CONFIG['stage_a']['max_grad_norm']\n",
        "mixed_precision = CONFIG['training']['mixed_precision']\n",
        "logging_steps = CONFIG['training']['logging_steps']\n",
        "eval_steps = CONFIG['training']['eval_steps']\n",
        "save_steps = CONFIG['training']['save_steps']\n",
        "\n",
        "# Setup mixed precision\n",
        "use_amp = mixed_precision in ['fp16', 'bf16']\n",
        "amp_dtype = torch.float16 if mixed_precision == 'fp16' else (\n",
        "    torch.bfloat16 if mixed_precision == 'bf16' else torch.float32\n",
        ")\n",
        "device_type = 'cuda' if 'cuda' in str(device) else 'cpu'\n",
        "scaler = GradScaler(device_type) if mixed_precision == 'fp16' and device_type == 'cuda' else None\n",
        "\n",
        "# Training state\n",
        "global_step = 0\n",
        "best_metric = 0.0\n",
        "epoch_history = []\n",
        "\n",
        "# Save config\n",
        "with open(Path(CHECKPOINT_DIR) / 'config.json', 'w') as f:\n",
        "    json.dump(CONFIG, f, indent=2)\n",
        "\n",
        "print(\"Starting training...\")\n",
        "print(f\"Output directory: {CHECKPOINT_DIR}\")\n",
        "\n",
        "for epoch in range(CONFIG['stage_a']['epochs']):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Epoch {epoch + 1}/{CONFIG['stage_a']['epochs']}\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Training\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    component_sums = {'collab_ce': 0.0, 'bpr': 0.0, 'regularization': 0.0}\n",
        "    component_counts = {k: 0 for k in component_sums.keys()}\n",
        "    \n",
        "    progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch + 1}\")\n",
        "    \n",
        "    for batch_idx, batch in enumerate(progress_bar):\n",
        "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
        "                for k, v in batch.items()}\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        with autocast(device_type=device_type, enabled=use_amp, dtype=amp_dtype):\n",
        "            is_autoregressive = batch.get('is_autoregressive', False)\n",
        "            collab_losses = model.compute_collaborative_loss(\n",
        "                user_ids=batch['user_ids'],\n",
        "                item_ids=batch['item_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                target_items=batch['target_item_ids'],\n",
        "                is_autoregressive=is_autoregressive,\n",
        "                negative_items=batch.get('negative_items')\n",
        "            )\n",
        "            \n",
        "            reg_losses = model.compute_regularization_losses()\n",
        "            \n",
        "            loss = 0.0\n",
        "            loss_components = {}\n",
        "            \n",
        "            if 'collaborative_ce' in collab_losses:\n",
        "                loss += loss_weights['collaborative'] * collab_losses['collaborative_ce']\n",
        "                loss_components['collab_ce'] = collab_losses['collaborative_ce'].item()\n",
        "            \n",
        "            if 'bpr' in collab_losses:\n",
        "                loss += loss_weights.get('cf_bpr', 1.0) * collab_losses['bpr']\n",
        "                loss_components['bpr'] = collab_losses['bpr'].item()\n",
        "            \n",
        "            reg_weight = loss_weights.get('regularization', 0.0)\n",
        "            if reg_weight > 0:\n",
        "                loss += reg_weight * reg_losses['collab_regularization']\n",
        "                loss_components['regularization'] = reg_losses['collab_regularization'].item()\n",
        "            else:\n",
        "                loss_components['regularization'] = reg_losses['collab_regularization'].item()\n",
        "        \n",
        "        # Backward pass\n",
        "        if scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            if max_grad_norm > 0:\n",
        "                scaler.unscale_(optimizer)\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            if max_grad_norm > 0:\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        \n",
        "        if 'collab_ce' in loss_components:\n",
        "            component_sums['collab_ce'] += loss_components['collab_ce']\n",
        "            component_counts['collab_ce'] += 1\n",
        "        if 'bpr' in loss_components:\n",
        "            component_sums['bpr'] += loss_components['bpr']\n",
        "            component_counts['bpr'] += 1\n",
        "        if 'regularization' in loss_components:\n",
        "            component_sums['regularization'] += loss_components['regularization']\n",
        "            component_counts['regularization'] += 1\n",
        "        \n",
        "        global_step += 1\n",
        "        \n",
        "        if global_step % logging_steps == 0:\n",
        "            avg_loss = total_loss / (batch_idx + 1)\n",
        "            print(f\"\\n[Step {global_step}] Loss: {loss.item():.4f}, Avg: {avg_loss:.4f}\")\n",
        "            progress_bar.set_postfix({'loss': f'{avg_loss:.4f}', 'step': global_step})\n",
        "        \n",
        "        if global_step % save_steps == 0:\n",
        "            checkpoint_path = Path(CHECKPOINT_DIR) / f\"checkpoint-{global_step}\"\n",
        "            checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'global_step': global_step,\n",
        "                'best_metric': best_metric\n",
        "            }, checkpoint_path / 'pytorch_model.pt')\n",
        "            torch.save({\n",
        "                'collab_embeddings': model.collab_embeddings.state_dict(),\n",
        "            }, checkpoint_path / 'embeddings.pt')\n",
        "            print(f\"Checkpoint saved to {checkpoint_path}\")\n",
        "    \n",
        "    # Compute average loss components\n",
        "    avg_components = {}\n",
        "    for key in component_sums:\n",
        "        if component_counts[key] > 0:\n",
        "            avg_components[key] = component_sums[key] / component_counts[key]\n",
        "    \n",
        "    train_metrics = {\n",
        "        'loss': total_loss / len(train_loader),\n",
        "        **avg_components\n",
        "    }\n",
        "    \n",
        "    print(f\"\\nEpoch {epoch + 1} training metrics:\")\n",
        "    print(f\"  Total loss: {train_metrics.get('loss', 0):.4f}\")\n",
        "    if 'collab_ce' in train_metrics:\n",
        "        print(f\"  Collaborative CE: {train_metrics['collab_ce']:.4f}\")\n",
        "    if 'bpr' in train_metrics:\n",
        "        print(f\"  BPR loss: {train_metrics['bpr']:.4f}\")\n",
        "    \n",
        "    # Evaluation\n",
        "    model.eval()\n",
        "    all_scores = []\n",
        "    all_target_indices = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
        "                    for k, v in batch.items()}\n",
        "            \n",
        "            pos_items = batch['target_item_ids']\n",
        "            neg_items = batch['negative_items']\n",
        "            \n",
        "            with autocast(device_type=device_type, enabled=use_amp, dtype=amp_dtype):\n",
        "                llm_output = model.forward_collaborative(\n",
        "                    user_ids=batch['user_ids'],\n",
        "                    item_ids=batch['item_ids'],\n",
        "                    attention_mask=batch['attention_mask']\n",
        "                )\n",
        "                \n",
        "                candidates = torch.cat([\n",
        "                    pos_items.unsqueeze(1),\n",
        "                    neg_items\n",
        "                ], dim=1)\n",
        "                \n",
        "                candidate_scores = model.collab_scoring_head(\n",
        "                    llm_output, \n",
        "                    candidate_items=candidates,\n",
        "                    use_fusion=True\n",
        "                )\n",
        "                \n",
        "                batch_target_idx = torch.zeros(\n",
        "                    candidate_scores.size(0),\n",
        "                    dtype=torch.long,\n",
        "                    device=candidate_scores.device\n",
        "                )\n",
        "                \n",
        "                all_scores.append(candidate_scores.cpu())\n",
        "                all_target_indices.append(batch_target_idx.cpu())\n",
        "    \n",
        "    if all_scores:\n",
        "        all_scores = torch.cat(all_scores, dim=0)\n",
        "        all_target_indices = torch.cat(all_target_indices, dim=0)\n",
        "        val_metrics = compute_sampled_metrics(all_scores, all_target_indices, k_list=[1, 5, 10, 20])\n",
        "        print_metrics(val_metrics, prefix=f\"Epoch {epoch + 1} Validation \")\n",
        "        \n",
        "        # Update best metric\n",
        "        if val_metrics['hit@10'] > best_metric:\n",
        "            best_metric = val_metrics['hit@10']\n",
        "            best_checkpoint_path = Path(CHECKPOINT_DIR) / 'best_model'\n",
        "            best_checkpoint_path.mkdir(parents=True, exist_ok=True)\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'global_step': global_step,\n",
        "                'best_metric': best_metric\n",
        "            }, best_checkpoint_path / 'pytorch_model.pt')\n",
        "            torch.save({\n",
        "                'collab_embeddings': model.collab_embeddings.state_dict(),\n",
        "            }, best_checkpoint_path / 'embeddings.pt')\n",
        "            print(f\"   New best model saved! Hit@10: {val_metrics['hit@10']:.4f}\")\n",
        "        \n",
        "        # Save epoch metrics\n",
        "        record = {\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"global_step\": float(global_step),\n",
        "        }\n",
        "        for key, value in train_metrics.items():\n",
        "            record[f\"train_{key}\"] = float(value)\n",
        "        for key, value in val_metrics.items():\n",
        "            record[f\"val_{key}\"] = float(value)\n",
        "        epoch_history.append(record)\n",
        "        \n",
        "        with open(Path(CHECKPOINT_DIR) / 'metrics.json', 'w') as f:\n",
        "            json.dump(epoch_history, f, indent=2)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"Training complete!\")\n",
        "print(f\"Best Hit@10: {best_metric:.4f}\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Step 5: Evaluation/Prediction\n",
        "\n",
        "Evaluate the trained model on test data. You can also load a previously saved checkpoint.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# EVALUATION ON TEST DATA\n",
        "# ============================================================================\n",
        "\n",
        "# Option 1: Use the model from training (already loaded)\n",
        "# Option 2: Load from checkpoint (uncomment to use)\n",
        "# checkpoint_path = Path(CHECKPOINT_DIR) / 'best_model'\n",
        "# checkpoint = torch.load(checkpoint_path / 'pytorch_model.pt', map_location='cpu', weights_only=False)\n",
        "# model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "# print(f\"Loaded checkpoint from {checkpoint_path}\")\n",
        "\n",
        "model.eval()\n",
        "all_scores = []\n",
        "all_target_indices = []\n",
        "\n",
        "use_amp = mixed_precision in ['fp16', 'bf16']\n",
        "amp_dtype = torch.float16 if mixed_precision == 'fp16' else (\n",
        "    torch.bfloat16 if mixed_precision == 'bf16' else torch.float32\n",
        ")\n",
        "device_type = 'cuda' if 'cuda' in str(device) else 'cpu'\n",
        "\n",
        "print(\"Evaluating on test data...\")\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Test evaluation\"):\n",
        "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
        "                for k, v in batch.items()}\n",
        "        \n",
        "        pos_items = batch['target_item_ids']\n",
        "        neg_items = batch['negative_items']\n",
        "        \n",
        "        with autocast(device_type=device_type, enabled=use_amp, dtype=amp_dtype):\n",
        "            llm_output = model.forward_collaborative(\n",
        "                user_ids=batch['user_ids'],\n",
        "                item_ids=batch['item_ids'],\n",
        "                attention_mask=batch['attention_mask']\n",
        "            )\n",
        "            \n",
        "            candidates = torch.cat([\n",
        "                pos_items.unsqueeze(1),\n",
        "                neg_items\n",
        "            ], dim=1)\n",
        "            \n",
        "            candidate_scores = model.collab_scoring_head(\n",
        "                llm_output, \n",
        "                candidate_items=candidates,\n",
        "                use_fusion=True\n",
        "            )\n",
        "            \n",
        "            batch_target_idx = torch.zeros(\n",
        "                candidate_scores.size(0),\n",
        "                dtype=torch.long,\n",
        "                device=candidate_scores.device\n",
        "            )\n",
        "            \n",
        "            all_scores.append(candidate_scores.cpu())\n",
        "            all_target_indices.append(batch_target_idx.cpu())\n",
        "\n",
        "if all_scores:\n",
        "    all_scores = torch.cat(all_scores, dim=0)\n",
        "    all_target_indices = torch.cat(all_target_indices, dim=0)\n",
        "    test_metrics = compute_sampled_metrics(all_scores, all_target_indices, k_list=[1, 5, 10, 20])\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"Test Results:\")\n",
        "    print(\"=\" * 60)\n",
        "    print_metrics(test_metrics, prefix=\"Test \")\n",
        "    \n",
        "    # Save test metrics\n",
        "    with open(Path(CHECKPOINT_DIR) / 'test_metrics.json', 'w') as f:\n",
        "        json.dump(test_metrics, f, indent=2)\n",
        "    print(f\"\\nTest metrics saved to {Path(CHECKPOINT_DIR) / 'test_metrics.json'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Load and Predict from Saved Checkpoint\n",
        "\n",
        "If you want to load a previously saved model and make predictions, use this cell.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded from /space/mcdonald-syn01/1/projects/jsawant/llm_recommender/checkpoints/stage_a_100_v10/best_model\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Precomputing negative samples: 0it [00:00, ?it/s]\n",
            "Precomputing negative samples: 100%|| 100000/100000 [06:56<00:00, 240.00it/s]\n",
            "Evaluating: 100%|| 3125/3125 [00:36<00:00, 84.81it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Test Metrics:\n",
            "--------------------------------------------------\n",
            "  hit@1: 0.2846\n",
            "  hit@10: 0.5577\n",
            "  hit@20: 0.6436\n",
            "  hit@5: 0.4781\n",
            "  ndcg@1: 0.2846\n",
            "  ndcg@10: 0.4127\n",
            "  ndcg@20: 0.4344\n",
            "  ndcg@5: 0.3870\n",
            "--------------------------------------------------\n",
            "This cell is for loading checkpoints. Uncomment and modify the code above to use it.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# LOAD CHECKPOINT AND PREDICT\n",
        "# ============================================================================\n",
        "\n",
        "# Uncomment and modify the path to load a specific checkpoint\n",
        "CHECKPOINT_TO_LOAD = \"/space/mcdonald-syn01/1/projects/jsawant/llm_recommender/checkpoints/stage_a_100_v10/best_model\"\n",
        "\n",
        "# Load data\n",
        "with open(Path(DATA_OUTPUT_DIR) / 'dataset_info.pkl', 'rb') as f:\n",
        "    dataset_info = pickle.load(f)\n",
        "with open(Path(DATA_OUTPUT_DIR) / 'test_data.pkl', 'rb') as f:\n",
        "    test_data = pickle.load(f)\n",
        "with open(Path(DATA_OUTPUT_DIR) / 'item_metadata.pkl', 'rb') as f:\n",
        "    item_metadata = pickle.load(f)\n",
        "\n",
        "num_users = dataset_info['num_users']\n",
        "num_items = dataset_info['num_items']\n",
        "\n",
        "# Load config from checkpoint or use CONFIG\n",
        "try:\n",
        "    with open(Path(CHECKPOINT_TO_LOAD).parent / 'config.json', 'r') as f:\n",
        "        loaded_config = json.load(f)\n",
        "    CONFIG = loaded_config\n",
        "except:\n",
        "    print(\"Using current CONFIG\")\n",
        "\n",
        "# Create model\n",
        "model = StageAModel(\n",
        "    base_llm_name=CONFIG['model']['base_llm'],\n",
        "    num_users=num_users,\n",
        "    num_items=num_items,\n",
        "    embedding_dim=CONFIG['model']['embedding_dim'],\n",
        "    lambda_c=CONFIG['embeddings']['lambda_c'],\n",
        "    freeze_llm=CONFIG['model']['freeze_llm_stage_a'],\n",
        "    use_bpr_loss=CONFIG['stage_a']['collaborative'].get('use_bpr_loss', True),\n",
        "    random_init_llm=CONFIG['model'].get('random_init_stage_a_llm', False)\n",
        ")\n",
        "\n",
        "# Load checkpoint\n",
        "checkpoint = torch.load(\n",
        "    Path(CHECKPOINT_TO_LOAD) / 'pytorch_model.pt',\n",
        "    map_location='cpu',\n",
        "    weights_only=False\n",
        ")\n",
        "model.load_state_dict(checkpoint['model_state_dict'], strict=False)\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "print(f\"Model loaded from {CHECKPOINT_TO_LOAD}\")\n",
        "\n",
        "# Create test data loader\n",
        "data_module = RecDataModule(\n",
        "    train_data={},\n",
        "    val_data={},\n",
        "    test_data=test_data,\n",
        "    item_metadata=item_metadata,\n",
        "    num_items=num_items,\n",
        "    tokenizer=None,\n",
        "    batch_size=32,\n",
        "    num_workers=4,\n",
        "    negative_samples=100,\n",
        "    max_seq_length=CONFIG['data']['max_sequence_length'],\n",
        "    max_text_length=None,\n",
        "    eval_seed=CONFIG['data']['seed']\n",
        ")\n",
        "test_loader = data_module.test_dataloader()\n",
        "\n",
        "# Evaluate\n",
        "all_scores = []\n",
        "all_target_indices = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "        batch = {k: v.to(device) if isinstance(v, torch.Tensor) else v \n",
        "                for k, v in batch.items()}\n",
        "        \n",
        "        pos_items = batch['target_item_ids']\n",
        "        neg_items = batch['negative_items']\n",
        "        \n",
        "        with autocast(device_type=device_type, enabled=use_amp, dtype=amp_dtype):\n",
        "            llm_output = model.forward_collaborative(\n",
        "                user_ids=batch['user_ids'],\n",
        "                item_ids=batch['item_ids'],\n",
        "                attention_mask=batch['attention_mask']\n",
        "            )\n",
        "            \n",
        "            candidates = torch.cat([\n",
        "                pos_items.unsqueeze(1),\n",
        "                neg_items\n",
        "            ], dim=1)\n",
        "            \n",
        "            candidate_scores = model.collab_scoring_head(\n",
        "                llm_output, \n",
        "                candidate_items=candidates,\n",
        "                use_fusion=True\n",
        "            )\n",
        "            \n",
        "            batch_target_idx = torch.zeros(\n",
        "                candidate_scores.size(0),\n",
        "                dtype=torch.long,\n",
        "                device=candidate_scores.device\n",
        "            )\n",
        "            \n",
        "            all_scores.append(candidate_scores.cpu())\n",
        "            all_target_indices.append(batch_target_idx.cpu())\n",
        "\n",
        "if all_scores:\n",
        "    all_scores = torch.cat(all_scores, dim=0)\n",
        "    all_target_indices = torch.cat(all_target_indices, dim=0)\n",
        "    test_metrics = compute_sampled_metrics(all_scores, all_target_indices, k_list=[1, 5, 10, 20])\n",
        "    print_metrics(test_metrics, prefix=\"Test \")\n",
        "\n",
        "print(\"This cell is for loading checkpoints. Uncomment and modify the code above to use it.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "jay2",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
